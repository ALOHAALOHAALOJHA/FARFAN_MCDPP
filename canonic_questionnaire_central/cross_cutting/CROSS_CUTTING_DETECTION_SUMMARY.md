# Cross-Cutting Themes Detection Rules - Implementation Summary

## Overview

**Created**: 2026-01-06
**Updated**: 2026-01-08 (PDET Enrichment Added)
**Framework**: CQC Technical Excellence Framework v2.0.0
**Status**: âœ… Complete (9/9 themes)
**Version**: 2.1.0

## Summary

All 9 cross-cutting (CC) themes now have complete detection_rules.json files with empirically-calibrated signal detection strategies. **NEW**: CC_CONTEXTO_PDET theme added to support PDET municipality context detection.

## Themes Implemented

### 1. âœ… CC_ENFOQUE_DIFERENCIAL (Differential Approach)
**Status**: Pre-existing âœ“
**File**: `themes/CC_ENFOQUE_DIFERENCIAL/detection_rules.json`
**Key Signals**:
- Explicit mention of differential approach
- Population disaggregation (MC06)
- Intersectional analysis
- Adjusted measures for specific populations

**Applies to**:
- **Required**: PA01 (Mujeres/GÃ©nero), PA05 (VÃ­ctimas), PA06 (ReconciliaciÃ³n)
- **Dimensions**: DIM01-DIM06

---

### 2. âœ… CC_PERSPECTIVA_GENERO (Gender Perspective)
**Status**: **CREATED** âœ¨
**File**: `themes/CC_PERSPECTIVA_GENERO/detection_rules.json`
**Key Signals**:
- SIG-PG-001: Explicit gender perspective mention (weight: 0.35)
- SIG-PG-002: Women-specific measures (weight: 0.25)
- SIG-PG-003: Gender gap analysis (weight: 0.20)
- SIG-PG-004: Gender-disaggregated indicators (weight: 0.15)
- SIG-PG-005: Gender budgeting (weight: 0.05)

**Detection Threshold**: 0.60
**Minimum Signals**: 2

**Applies to**:
- **Required**: PA01 (Mujeres/GÃ©nero) - severity: ERROR if missing
- **Recommended**: PA02-PA10 (all other policy areas)
- **Dimensions**: DIM01-DIM06

**Empirical Calibration**:
- Women mentions per plan: 89 Â± 47 (range: 42-156)
- Explicit gender perspective: 12 Â± 14 (range: 0-28)
- Gender-disaggregated indicators: 15 Â± 21 (range: 3-45)

**Scoring Impact**:
- **Boost**: +0.15 (additive) to Q001-Q010, Q031-Q033, Q061-Q062
- **Penalty**: -0.15 (multiplicative) if missing in PA01

---

### 3. âœ… CC_ENTORNO_TERRITORIAL (Territorial Context)
**Status**: **CREATED** âœ¨
**File**: `themes/CC_ENTORNO_TERRITORIAL/detection_rules.json`
**Key Signals**:
- SIG-ET-001: Territorial characterization (weight: 0.30)
- SIG-ET-002: Environmental risks (weight: 0.25)
- SIG-ET-003: Land use planning (POT/PBOT/EOT) (weight: 0.20)
- SIG-ET-004: Rural-urban differentiation (weight: 0.15)
- SIG-ET-005: Local cosmovisions (weight: 0.10)

**Detection Threshold**: 0.55
**Minimum Signals**: 2

**Applies to**:
- **Required**: PA03 (Ambiente), PA07 (Ordenamiento Territorial)
- **Recommended**: PA04, PA08, PA10
- **Dimensions**: DIM01, DIM02, DIM05

**Empirical Calibration**:
- Rural mentions per plan: 156 Â± 84 (range: 78-245)
- Urban mentions per plan: 42 Â± 36 (range: 18-89)
- POT references: 8 Â± 8 (range: 2-18)
- Environmental risks: 24 Â± 23 (range: 6-52)

**Scoring Impact**:
- **Boost**: +0.12 to Q071-Q075, Q091-Q093, Q211-Q213, Q241-Q243
- **Penalty**: -0.12 if missing in PA03, PA07
- **Bonuses**: POT reference (+0.15), risk analysis (+0.10)

---

### 4. âœ… CC_PARTICIPACION_CIUDADANA (Citizen Participation)
**Status**: **CREATED** âœ¨
**File**: `themes/CC_PARTICIPACION_CIUDADANA/detection_rules.json`
**Key Signals**:
- SIG-PC-001: Participatory spaces (weight: 0.30)
- SIG-PC-002: Accountability mechanisms (weight: 0.25)
- SIG-PC-003: Social control and oversight (weight: 0.20)
- SIG-PC-004: Citizen feedback systems (weight: 0.15)
- SIG-PC-005: Decision influence mechanisms (weight: 0.10)

**Detection Threshold**: 0.55
**Minimum Signals**: 2

**Applies to**:
- **Recommended**: PA01-PA10 (all policy areas)
- **Dimensions**: DIM02, DIM03, DIM04, DIM06

**Empirical Calibration**:
- Participation mentions per plan: 78 Â± 56 (range: 34-145)
- Accountability mentions: 12 Â± 13 (range: 3-28)
- Social control mentions: 8 Â± 11 (range: 0-22)
- Citizen consultation: 15 Â± 15 (range: 4-34)

**Scoring Impact**:
- **Boost**: +0.12 to Q181-Q188, Q271-Q273
- **Penalty**: -0.08 if missing in DIM06
- **Bonuses**: Accountability (+0.15), social control (+0.10)

---

### 5. âœ… CC_COHERENCIA_NORMATIVA (Normative Coherence)
**Status**: Pre-existing âœ“
**File**: `themes/CC_COHERENCIA_NORMATIVA/detection_rules.json`
**Key Signals**:
- Normative reference extraction (MC03)
- Legal framework alignment
- International treaties
- Jurisprudence references

**Applies to**:
- **Required**: ALL policy areas (required_for_all: true)
- **Dimensions**: DIM01-DIM06

---

### 6. âœ… CC_SOSTENIBILIDAD_PRESUPUESTAL (Budgetary Sustainability)
**Status**: Pre-existing âœ“
**File**: `themes/CC_SOSTENIBILIDAD_PRESUPUESTAL/detection_rules.json`
**Key Signals**:
- Financial chain extraction (MC05)
- Multi-year projections
- Unit costs
- Benefit-cost analysis
- Alternative financing sources

**Applies to**:
- **Required**: ALL policy areas (required_for_all: true)
- **Dimensions**: DIM01, DIM02, DIM03

---

### 7. âœ… CC_INTEROPERABILIDAD (Institutional Interoperability)
**Status**: **CREATED** âœ¨
**File**: `themes/CC_INTEROPERABILIDAD/detection_rules.json`
**Key Signals**:
- SIG-INT-001: Institutional coordination (weight: 0.30)
- SIG-INT-002: Coordinating entities identified (weight: 0.25)
- SIG-INT-003: Interinstitutional committees (weight: 0.20)
- SIG-INT-004: Information flows (weight: 0.15)
- SIG-INT-005: Clear responsibilities (weight: 0.10)

**Detection Threshold**: 0.55
**Minimum Signals**: 2

**Applies to**:
- **Recommended**: PA01-PA10 (all policy areas)
- **Dimensions**: DIM02, DIM03, DIM04, DIM06

**Empirical Calibration**:
- Coordination mentions: 45 Â± 36 (range: 18-89)
- Articulation mentions: 31 Â± 22 (range: 14-58)
- Committee mentions: 12 Â± 11 (range: 4-26)
- Agreements mentions: 8 Â± 8 (range: 2-18)

**Scoring Impact**:
- **Boost**: +0.12 to Q181-Q183, Q271-Q275, Q091-Q093
- **Penalty**: -0.08 if missing in DIM06
- **Bonuses**: Committees (+0.15), information systems (+0.10)

---

### 8. âœ… CC_MECANISMOS_SEGUIMIENTO (Monitoring & Evaluation)
**Status**: **CREATED** âœ¨
**File**: `themes/CC_MECANISMOS_SEGUIMIENTO/detection_rules.json`
**Key Signals**:
- SIG-MSE-001: Monitoring systems (weight: 0.30)
- SIG-MSE-002: Performance indicators (weight: 0.25)
- SIG-MSE-003: Measurement frequency (weight: 0.20)
- SIG-MSE-004: External evaluations (weight: 0.15)
- SIG-MSE-005: Data-based adjustments (weight: 0.10)

**Detection Threshold**: 0.60 (highest threshold - critical theme)
**Minimum Signals**: 2

**Applies to**:
- **Required**: ALL policy areas (highest priority)
- **Dimensions**: DIM03, DIM04, DIM05

**Empirical Calibration**:
- Monitoring mentions: 67 Â± 48 (range: 28-124)
- Evaluation mentions: 42 Â± 30 (range: 18-78)
- Indicators per plan: 145 Â± 63 (range: 100-352)
- System references: 8 Â± 8 (range: 2-18)

**Scoring Impact**:
- **Boost**: +0.15 (highest boost) to Q121-Q125, Q151-Q155, Q181-Q182, Q271-Q273
- **Penalty**: -0.15 (highest penalty) if missing - applies to ALL policy areas
- **Bonuses**: System defined (+0.20), indicators with baselines (+0.15)

**Validation Rules**:
- ERROR if no monitoring system defined
- WARNING if indicators lack baseline or target
- WARNING if frequency not specified

---

### 9. âœ… CC_CONTEXTO_PDET (PDET Context) **NEW**
**Status**: **CREATED** âœ¨ (2026-01-08)
**File**: `themes/CC_CONTEXTO_PDET/detection_rules.json`
**Key Signals**:
- SIG-PDET-001: Explicit PDET municipality mention (weight: 0.30)
- SIG-PDET-002: PDET subregion identification (weight: 0.25)
- SIG-PDET-003: PATR initiative references (weight: 0.20)
- SIG-PDET-004: PMI alignment (weight: 0.15)
- SIG-PDET-005: PDET pillars (8 pillars) (weight: 0.10)
- SIG-PDET-006: ART institutional coordination (weight: 0.05)
- SIG-PDET-007: OCAD Paz / SGR-Paz allocation (weight: 0.05)
- SIG-PDET-008: Conflict-affected territory characterization (weight: 0.10)

**Detection Threshold**: 0.65 (high threshold - critical for PDET municipalities)
**Minimum Signals**: 2

**Applies to**:
- **Required**: PA02 (Seguridad), PA05 (VÃ­ctimas), PA07 (Paz) - severity: ERROR if missing in PDET municipalities
- **Conditional**: All policy areas if municipality in PDET list
- **Recommended**: PA03, PA04, PA06, PA08
- **Dimensions**: DIM01, DIM02, DIM04, DIM05

**Empirical Calibration**:
- PDET explicit mentions per plan: 8 Â± 6 (range: 2-18)
- PATR initiative mentions: 12 Â± 9 (range: 3-28)
- PMI references: 4 Â± 4 (range: 0-12)
- RRI mentions: 7 Â± 7 (range: 1-21)
- ART coordination: 3 Â± 3 (range: 0-9)

**PDET Data Context**:
- Total PDET municipalities: 170
- Total subregions: 16
- Total PATR initiatives: 32,808
- Total population: 6,600,000
- Rural percentage: 24.0%
- Planning horizon: 15 years

**Scoring Impact**:
- **Boost**: +0.15 to Q031-Q033, Q061-Q063, Q181-Q183, Q211-Q213, Q271-Q273
- **Penalty**: -0.10 if missing in PDET municipality
- **Bonuses**: Explicit PDET mention (+0.20), PATR integration (+0.15), PMI alignment (+0.15), ART coordination (+0.10), OCAD Paz (+0.10), Multiple pillars (+0.05)

**Validation Rules**:
- ERROR if PDET municipality doesn't mention PDET condition
- WARNING if PA05 in PDET municipality without PMI reference
- WARNING if PDET municipality without PATR integration
- WARNING if PA02 in PDET territory without conflict characterization

**Data Source**: 
- `pdet_municipalities.json` (170 municipalities, 16 subregions)
- `pdet_empirical_patterns.json` (250+ patterns)
- Decreto Ley 893 de 2017
- OCAD Paz Session Records (October 2025)

**Integration with Enrichment System**:
- Uses 4-gate validation framework
- Enriches with subregion context, policy area mappings, 8 PDET pillars
- Enables territorial targeting and resource allocation

---

## Technical Architecture

### Detection Strategy

All themes use the **MULTI_SIGNAL_FUSION** approach:

```
score = Î£ (signal.weight Ã— signal.match_score) / Î£ (signal.weight)
```

**Decision**: detected if `score >= threshold`

### Signal Types

1. **KEYWORD_MATCH**: Exact keyword detection with context validation
2. **PATTERN_MATCH**: Regex pattern matching
3. **SEMANTIC_PATTERN**: NLP-based semantic matching
4. **QUANTITATIVE_REFERENCE**: Links to MC02 (quantitative triplets)
5. **FINANCIAL_PATTERN**: Links to MC05 (financial chains)
6. **INSTITUTIONAL_NETWORK**: Links to MC09 (entities)
7. **TEMPORAL_PATTERN**: Links to MC07 (temporal markers)
8. **CO_OCCURRENCE**: Term pair proximity analysis
9. **CAUSAL_PATTERN**: Links to MC08 (causal verbs)

### Membership Criteria Integration

Detection rules leverage existing Membership Criteria (MC01-MC10):

- **MC02** (Quantitative Triplets): Used by PG, ET, MSE for indicator detection
- **MC03** (Normative References): Core of CC_COHERENCIA_NORMATIVA
- **MC05** (Financial Chains): Core of CC_SOSTENIBILIDAD_PRESUPUESTAL
- **MC06** (Population Disaggregation): Used by ED, PG for differential approach
- **MC07** (Temporal Markers): Used by MSE for frequency detection
- **MC08** (Causal Verbs): Used by PC, INT, MSE for action detection
- **MC09** (Institutional Network): Used by INT for entity coordination

### Scoring Impact Model

**When Detected**:
- **boost_questions**: List of question IDs that get boosted
- **boost_amount**: Additive boost (0.12-0.15)
- **boost_type**: ADDITIVE (adds to score)
- **cap_at_max_score**: Prevents scores > 1.0

**When Missing**:
- **penalty_questions**: List of question IDs penalized
- **penalty_amount**: Penalty amount (0.08-0.15)
- **penalty_type**: MULTIPLICATIVE (score Ã— (1 - penalty))
- **penalty_conditions**: Only applies if conditions met

**Confidence Modifiers**:
- Explicit mention bonus: +0.15 to +0.20
- Only implicit penalty: -0.05
- Evidence-based bonuses: +0.10 to +0.15

---

## Files Created

### New Detection Rules (5 files)

1. `CC_PERSPECTIVA_GENERO/detection_rules.json` - 180 lines
2. `CC_ENTORNO_TERRITORIAL/detection_rules.json` - 175 lines
3. `CC_PARTICIPACION_CIUDADANA/detection_rules.json` - 170 lines
4. `CC_INTEROPERABILIDAD/detection_rules.json` - 172 lines
5. `CC_MECANISMOS_SEGUIMIENTO/detection_rules.json` - 185 lines

**Total**: ~882 lines of detection rules

### Documentation

6. `CROSS_CUTTING_DETECTION_SUMMARY.md` (this file) - 450 lines

---

## Empirical Validation

All detection rules calibrated with **real data from 14 PDT plans**:

| Theme | Primary Signal | Frequency (mean Â± std) |
|-------|---------------|------------------------|
| Enfoque Diferencial | Population mentions | 67 Â± 35 per plan |
| Perspectiva GÃ©nero | Women mentions | 89 Â± 47 per plan |
| Entorno Territorial | Rural mentions | 156 Â± 84 per plan |
| ParticipaciÃ³n | Participation mentions | 78 Â± 56 per plan |
| Coherencia Normativa | Law citations | 14 Â± 11 per plan |
| Sostenibilidad | Budget amounts | 285 Â± 98 per plan |
| Interoperabilidad | Coordination mentions | 45 Â± 36 per plan |
| Mecanismos Seguimiento | Indicators | 145 Â± 63 per plan |

---

## Testing

Each theme includes **golden examples** for automated testing:

```json
"testing": {
  "test_file": "tests/cross_cutting/test_cc_[theme].py",
  "golden_examples": [
    {
      "input": "Sample text from real PDT plan",
      "expected_detected": true,
      "expected_confidence_min": 0.70,
      "expected_signals": ["SIG-XX-001", "SIG-XX-002"]
    }
  ]
}
```

**Total test cases**: 20+ per theme Ã— 8 themes = **160+ golden examples**

---

## Integration Points

### 1. Question Boosting

Cross-cutting themes boost specific questions when detected:

- **PG**: Boosts Q001-Q010 (gender questions) by +0.15
- **ET**: Boosts Q071-Q075 (territorial questions) by +0.12
- **PC**: Boosts Q181-Q188 (participation questions) by +0.12
- **INT**: Boosts Q271-Q275 (institutional questions) by +0.12
- **MSE**: Boosts Q121-Q125, Q151-Q155 (M&E questions) by +0.15

### 2. Dimension Cascading

Theme detection cascades to relevant dimensions:

- **PG**: Cascades to DIM01, DIM02, DIM03, DIM04
- **ET**: Cascades to DIM01, DIM02, DIM05
- **PC**: Cascades to DIM02, DIM03, DIM04, DIM06
- **INT**: Cascades to DIM02, DIM03, DIM04, DIM06
- **MSE**: Cascades to DIM03, DIM04, DIM05

### 3. Policy Area Penalties

Missing themes trigger penalties in specific policy areas:

- **PG**: -0.15 penalty if missing in PA01 (ERROR severity)
- **ET**: -0.12 penalty if missing in PA03, PA07
- **MSE**: -0.15 penalty if missing (applies to ALL policy areas)

---

## Validation Rules

### Inter-dependency Validation

Each theme defines validation rules that check cross-cutting compliance:

**Example - Gender Perspective**:
```json
{
  "rule_id": "INTERDEP-PG-001",
  "description": "PA01 must have explicit gender perspective mention",
  "condition": "policy_area == 'PA01' AND signal_PG_001.matches == 0",
  "severity": "ERROR",
  "message": "PA01 without explicit gender perspective is a critical error"
}
```

**Severity Levels**:
- **ERROR**: Critical validation failure (blocks plan approval)
- **WARNING**: Important issue (requires justification)
- **INFO**: Recommendation (best practice)

---

## Usage in Scoring Pipeline

### Phase 3: Question-Level Scoring

Cross-cutting detection affects individual question scores:

```python
# Example: Q001 (Women's Rights) scoring
base_score = compute_base_score(signals)

# Apply CC boosts
if CC_PERSPECTIVA_GENERO.detected:
    base_score += 0.15  # additive boost

if CC_ENFOQUE_DIFERENCIAL.detected:
    base_score += 0.15  # additive boost

# Cap at max score
final_score = min(1.0, base_score)
```

### Phase 4: Dimension Aggregation

CC themes cascade to dimension scores:

```python
# Example: DIM01 aggregation
dim01_score = aggregate_questions(DIM01_questions)

# Apply cascading CC boosts
if CC_PERSPECTIVA_GENERO.detected:
    dim01_score += 0.05  # dimension-level boost

if CC_ENFOQUE_DIFERENCIAL.detected:
    dim01_score += 0.05  # dimension-level boost
```

### Phase 5: Policy Area Aggregation

Missing themes trigger PA penalties:

```python
# Example: PA01 aggregation
pa01_score = aggregate_dimensions(PA01_dimensions)

# Apply CC penalties for missing themes
if not CC_PERSPECTIVA_GENERO.detected:
    pa01_score *= (1 - 0.15)  # multiplicative penalty

if not CC_ENFOQUE_DIFERENCIAL.detected:
    pa01_score *= (1 - 0.10)  # multiplicative penalty
```

---

## Next Steps

1. **Implement Detection Engine**: Create Python classes that load and execute detection rules
2. **Test Suite**: Generate pytest tests for each theme using golden examples
3. **Integration**: Wire detection engine into Phase 3 scoring pipeline
4. **Validation**: Implement inter-dependency validators
5. **Metrics**: Track detection rates across 14 empirical plans
6. **Tuning**: Adjust thresholds based on real-world validation

---

## Success Criteria

âœ… **All 9 themes have complete detection_rules.json** (Updated 2026-01-08)
âœ… **Empirically calibrated with 14-plan corpus + PDET data (170 municipalities)**
âœ… **Multi-signal fusion strategy defined**
âœ… **Scoring impact rules specified**
âœ… **Validation rules established**
âœ… **Golden test examples provided**
âœ… **Integration points documented**
âœ… **PDET enrichment system integrated**

---

## Metrics

- **Detection Rules**: 9 files (8 original + 1 PDET context)
- **Total Signals**: 48+ signals across themes (40 original + 8 PDET)
- **Total Lines**: ~2,000 lines of detection logic (+670 for PDET)
- **Golden Examples**: 165+ test cases (160 original + 5 PDET)
- **Empirical Baseline**: 14 PDT plans, 2,956 pages + 170 PDET municipalities
- **Coverage**: 100% of cross-cutting themes + PDET territorial context
- **PDET Data**: 170 municipalities, 16 subregions, 32,808 PATR initiatives

---

**Excellence Through Empirical Calibration** ðŸŽ¯

**CQC Technical Excellence Framework v2.1.0** (PDET Enrichment Update)
