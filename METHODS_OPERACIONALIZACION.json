{
  "AdaptivePriorCalculator.calculate_likelihood_adaptativo": {
    "file": "derek_beach.py",
    "questions": ["Q010", "Q012"],
    "dimensions": ["DIM02", "DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "dict con scores numéricos por dominio {semantic: {score: 0.0-1.0}, temporal: {score: 0.0-1.0}, financial: {score: 0.0-1.0}, structural: {score: 0.0-1.0}}",
      "formato_salida": "probabilidad p_mechanism [0-1], Bayes Factor usado, pesos por dominio",
      "calculo": "promedio_ponderado de scores × BF × logit inverso → probabilidad calibrada",
      "parametros": "evidence_dict: dict[str, Any], test_type: str='hoop' (straw|hoop|smoking|doubly)"
    }
  },
  "AdaptivePriorCalculator._adjust_domain_weights": {
    "file": "derek_beach.py",
    "questions": ["Q012"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "dict con scores numéricos por dominio {semantic: float, temporal: float, financial: float, structural: float}",
      "formato_salida": "dict con pesos ajustados normalizados que suman 1.0",
      "calculo": "redistribuye peso de dominios faltantes (score≤0) a dominios activos",
      "parametros": "domain_scores: dict[str, float]"
    }
  },
  "AdaptivePriorCalculator.sensitivity_analysis": {
    "file": "derek_beach.py",
    "questions": ["Q009", "Q018", "Q024"],
    "dimensions": ["DIM02", "DIM04", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "evidence_dict con scores, test_type, perturbación %",
      "formato_salida": "top-3 componentes más influyentes, delta_p_sensitivity, OOD_drop, si es frágil",
      "calculo": "perturba cada dominio ±10%, mide cambio en p_mechanism, ablaciones single-domain, inyecta ruido OOD",
      "parametros": "evidence_dict: dict, test_type: str='hoop', perturbation: float=0.10",
      "criterios_calidad": "max_sensitivity ≤0.15, sign_concordance ≥2/3, OOD_drop ≤0.10"
    }
  },
  "AdaptivePriorCalculator._perturb_evidence": {
    "file": "derek_beach.py",
    "questions": ["Q023"],
    "dimensions": ["DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "evidence_dict original, dominio a perturbar, porcentaje de perturbación",
      "formato_salida": "copia de evidence_dict con score del dominio multiplicado por (1+perturbation)",
      "calculo": "multiplica score del dominio específico, clip a máximo 1.0",
      "parametros": "evidence_dict: dict, domain: str, perturbation: float"
    }
  },
  "AdaptivePriorCalculator._add_ood_noise": {
    "file": "derek_beach.py",
    "questions": ["Q025"],
    "dimensions": ["DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "evidence_dict con scores",
      "formato_salida": "evidence_dict con ruido gaussiano N(0, 0.05) añadido a todos los scores",
      "calculo": "score + ruido_gaussiano, clip [0.0, 1.0]",
      "parametros": "evidence_dict: dict[str, Any]"
    }
  },
  "AdaptivePriorCalculator.generate_traceability_record": {
    "file": "derek_beach.py",
    "questions": ["Q011", "Q013", "Q030"],
    "dimensions": ["DIM03", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "MIXTO (cuantitativo + trazabilidad)",
      "formato_entrada": "evidence_dict, test_type, result previo, semilla fija",
      "formato_salida": "registro con hash_config, hash_result, evidence_trace (source, line_span, snippet), trace_completeness",
      "calculo": "SHA-256 de config + result para reproducibilidad, trace_completeness = factores_en_trace / total_factores",
      "parametros": "evidence_dict: dict, test_type: str, result: dict, seed: int=42"
    }
  },
  "AdaptivePriorCalculator.validate_quality_criteria": {
    "file": "derek_beach.py",
    "questions": ["Q020", "Q025", "Q028"],
    "dimensions": ["DIM04", "DIM05", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "lista de samples de validación con {evidence, actual_label, test_type}",
      "formato_salida": "Brier Score, ACE, CI95% coverage, monotonicity_violations, quality_grade",
      "calculo": "Brier = mean((pred-actual)²), ACE = error calibración promedio en 10 bins, bootstrap CI95%",
      "parametros": "validation_samples: list[dict[str, Any]]",
      "criterios_calidad": "Brier ≤0.20, ACE ∈[-0.02,0.02], CI95% ∈[92%,98%], monotonicity=0 violaciones"
    }
  },
  "BeachEvidentialTest.classify_test": {
    "file": "derek_beach.py",
    "questions": ["Q007"],
    "dimensions": ["DIM02"],
    "operacionalizacion": {
      "tipo_valor": "CUALITATIVO (categoría)",
      "formato_entrada": "necessity: float [0-1], sufficiency: float [0-1]",
      "formato_salida": "TestType literal: 'hoop_test'|'smoking_gun'|'doubly_decisive'|'straw_in_wind'",
      "calculo": "umbral 0.7: high_N + high_S → doubly, high_N only → hoop, high_S only → smoking, else straw",
      "parametros": "necessity: float, sufficiency: float"
    }
  },
  "BeachEvidentialTest.apply_test_logic": {
    "file": "derek_beach.py",
    "questions": ["Q011", "Q027"],
    "dimensions": ["DIM03", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO + CUALITATIVO",
      "formato_entrada": "test_type, evidence_found (bool), prior probability, bayes_factor",
      "formato_salida": "(posterior_confidence: float, interpretation: str)",
      "calculo": "hoop fail→0.01, smoking pass→prior×max(BF,10), doubly→0.99/0.01, straw→ajuste marginal",
      "parametros": "test_type: TestType, evidence_found: bool, prior: float, bayes_factor: float"
    }
  },
  "BayesFactorTable.get_bayes_factor": {
    "file": "derek_beach.py",
    "questions": ["Q017", "Q029"],
    "dimensions": ["DIM04", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "test_type: string",
      "formato_salida": "Bayes Factor numérico (media del rango para ese test type)",
      "calculo": "lookup en tabla: straw=[1,2], hoop=[2,5], smoking=[5,15], doubly=[15,50] → promedio",
      "parametros": "test_type: str"
    }
  },
  "CausalExtractor.extract_causal_hierarchy": {
    "file": "derek_beach.py",
    "questions": ["Q007", "Q017", "Q026"],
    "dimensions": ["DIM02", "DIM04", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "ESTRUCTURAL (grafo)",
      "formato_entrada": "text: string completo del documento",
      "formato_salida": "nx.DiGraph con nodos (MetaNode) y aristas causales con posterior bayesiano",
      "calculo": "extrae metas (regex), infiere links causales con Bayesian updating, estructura jerárquica",
      "parametros": "text: str"
    }
  },
  "CausalExtractor._extract_goals": {
    "file": "derek_beach.py",
    "questions": ["Q001", "Q016"],
    "dimensions": ["DIM01", "DIM04"],
    "operacionalizacion": {
      "tipo_valor": "PATRON (extracción regex)",
      "formato_entrada": "text: string del documento",
      "formato_salida": "list[MetaNode] con id, type (programa|producto|resultado|impacto), baseline, target",
      "calculo": "regex [MP][RIP]-\\d{3}, clasifica por prefijo, extrae contexto ±500 chars",
      "parametros": "text: str"
    }
  },
  "CausalExtractor._parse_goal_context": {
    "file": "derek_beach.py",
    "questions": ["Q001", "Q016"],
    "dimensions": ["DIM01", "DIM04"],
    "operacionalizacion": {
      "tipo_valor": "PATRON + CUANTITATIVO",
      "formato_entrada": "goal_id: str, context: str (±500 chars alrededor)",
      "formato_salida": "MetaNode con type, baseline (1er número), target (2do número), responsible_entity",
      "calculo": "clasifica por prefijo (MP→producto, MR→resultado, MI→impacto), extrae números con regex, NER con spaCy",
      "parametros": "goal_id: str, context: str"
    }
  },
  "CausalExtractor._extract_causal_links": {
    "file": "derek_beach.py",
    "questions": ["Q008"],
    "dimensions": ["DIM02"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (Bayesian posterior)",
      "formato_entrada": "text: string del documento",
      "formato_salida": "aristas en grafo con posterior_mean, posterior_std, kl_divergence, converged",
      "calculo": "Beta-Binomial conjugate prior, actualización incremental por evidencia, veto estructural ≤0.6",
      "parametros": "text: str (usa self.nodes internamente)"
    }
  },
  "CausalExtractor._calculate_semantic_distance": {
    "file": "derek_beach.py",
    "questions": ["Q016", "Q023"],
    "dimensions": ["DIM04", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "source: str (node_id), target: str (node_id)",
      "formato_salida": "float [0-1] similaridad semántica",
      "calculo": "1 - cosine_distance(spaCy_vector_source, spaCy_vector_target)",
      "parametros": "source: str, target: str"
    }
  },
  "CausalExtractor._calculate_type_transition_prior": {
    "file": "derek_beach.py",
    "questions": ["Q008", "Q015"],
    "dimensions": ["DIM02", "DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "source: str, target: str",
      "formato_salida": "float [0-1] prior de transición",
      "calculo": "lookup tabla: programa→producto=0.85, producto→resultado=0.80, resultado→impacto=0.75, reverso ×0.3",
      "parametros": "source: str, target: str"
    }
  },
  "CausalExtractor._check_structural_violation": {
    "file": "derek_beach.py",
    "questions": ["Q015"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUALITATIVO (veto binario)",
      "formato_entrada": "source: str, target: str",
      "formato_salida": "None si válido, string describiendo violación si inválido",
      "calculo": "jerarquía programa(1)→producto(2)→resultado(3)→impacto(4), veto si reverse o skip>2 niveles",
      "parametros": "source: str, target: str"
    }
  },
  "CausalExtractor._calculate_language_specificity": {
    "file": "derek_beach.py",
    "questions": ["Q016", "Q030"],
    "dimensions": ["DIM04", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO + PATRON",
      "formato_entrada": "keyword: str, policy_area: str|None, context: str|None",
      "formato_salida": "float [0-1] especificidad lingüística",
      "calculo": "base por tipo causal (strong=0.9, moderate=0.7, weak=0.5) + boost por vocabulario policy-specific (+0.15)",
      "parametros": "keyword: str, policy_area: str|None=None, context: str|None=None"
    }
  },
  "CausalExtractor._assess_temporal_coherence": {
    "file": "derek_beach.py",
    "questions": ["Q005", "Q021", "Q030"],
    "dimensions": ["DIM01", "DIM05", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "source: str, target: str",
      "formato_salida": "float [0-1] coherencia temporal",
      "calculo": "secuencia verbos: diagnosticar(1)→planificar(2)→ejecutar(3)→evaluar(4), in_seq=0.85, same=0.60, reverse=0.30",
      "parametros": "source: str, target: str"
    }
  },
  "CausalExtractor._assess_financial_consistency": {
    "file": "derek_beach.py",
    "questions": ["Q015"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "source: str, target: str",
      "formato_salida": "float [0-1] consistencia financiera",
      "calculo": "verifica si hay asignación financiera en ambos nodos, penaliza si falta",
      "parametros": "source: str, target: str"
    }
  },
  "SemanticAnalyzer.extract_semantic_cube": {
    "file": "analyzer_one.py",
    "questions": ["Q008", "Q023"],
    "dimensions": ["DIM02", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "ESTRUCTURAL (cubo multidimensional)",
      "formato_entrada": "document_segments: list[str]",
      "formato_salida": "dict con dimensions (value_chain_links, policy_domains, cross_cutting_themes) y measures (semantic_density, coherence_scores, overall_coherence)",
      "calculo": "TF-IDF vectorización → clasificación por keywords ontología → agregación por dimensión",
      "parametros": "document_segments: list[str]"
    }
  },
  "SemanticAnalyzer._classify_value_chain_link": {
    "file": "analyzer_one.py",
    "questions": ["Q013"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (score por categoría)",
      "formato_entrada": "segment: str",
      "formato_salida": "dict[str, float] con score por cada value_chain_link",
      "calculo": "cuenta keywords de instruments+mediators+outputs+outcomes en texto, normaliza por total keywords",
      "parametros": "segment: str"
    }
  },
  "SemanticAnalyzer._classify_policy_domain": {
    "file": "analyzer_one.py",
    "questions": ["Q013"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (score por categoría)",
      "formato_entrada": "segment: str",
      "formato_salida": "dict[str, float] con score por cada policy_domain (economic, social, territorial, institutional)",
      "calculo": "cuenta keywords por dominio, normaliza por cantidad de keywords en dominio",
      "parametros": "segment: str"
    }
  },
  "SemanticAnalyzer._classify_cross_cutting_themes": {
    "file": "analyzer_one.py",
    "questions": ["Q013"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (score por categoría)",
      "formato_entrada": "segment: str",
      "formato_salida": "dict[str, float] con score por tema (governance, equity, sustainability, innovation)",
      "calculo": "cuenta keywords por tema, normaliza",
      "parametros": "segment: str"
    }
  },
    "SemanticAnalyzer._calculate_semantic_complexity": {
        "file": "analyzer_one.py",
        "questions": ["Q013"],
        "dimensions": ["DIM03"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO",
        "formato_entrada": "semantic_cube: dict",
        "formato_salida": "float [0-1] complejidad semántica",
        "calculo": "cuenta conceptos únicos en todas las dimensiones, normaliza por max_expected (20)",
        "parametros": "semantic_cube: dict[str, Any]"
        }
    },
    "PerformanceAnalyzer.analyze_performance": {
        "file": "analyzer_one.py",
        "questions": ["Q002", "Q014", "Q016", "Q028"],
        "dimensions": ["DIM01", "DIM03", "DIM04", "DIM06"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO (métricas agregadas)",
        "formato_entrada": "semantic_cube: dict (output de SemanticAnalyzer)",
        "formato_salida": "value_chain_metrics, bottleneck_analysis, operational_loss_functions, recommendations",
        "calculo": "throughput = segments × coherence × conversion_rate, bottlenecks por IsolationForest, loss functions",
        "parametros": "semantic_cube: dict[str, Any]"
        }
    },
    "PerformanceAnalyzer._calculate_loss_functions": {
        "file": "analyzer_one.py",
        "questions": ["Q014"],
        "dimensions": ["DIM03"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO",
        "formato_entrada": "metrics: dict, link_config: ValueChainLink",
        "formato_salida": "dict con funciones de pérdida operacional",
        "calculo": "loss = 1 - efficiency_score × capacity_utilization, penalizaciones por bottlenecks",
        "parametros": "metrics: dict, link_config: ValueChainLink"
        }
    },
    "PerformanceAnalyzer._generate_recommendations": {
        "file": "analyzer_one.py",
        "questions": ["Q016"],
        "dimensions": ["DIM04"],
        "operacionalizacion": {
        "tipo_valor": "CUALITATIVO (texto)",
        "formato_entrada": "performance_analysis: dict completo",
        "formato_salida": "list[str] de recomendaciones priorizadas",
        "calculo": "genera recomendaciones basadas en bottlenecks detectados y loss functions > threshold",
        "parametros": "performance_analysis: dict"
        }
    },
    "TextMiningEngine.diagnose_critical_links": {
        "file": "analyzer_one.py",
        "questions": ["Q001", "Q011", "Q030"],
        "dimensions": ["DIM01", "DIM03", "DIM06"],
        "operacionalizacion": {
        "tipo_valor": "MIXTO (cuantitativo + cualitativo)",
        "formato_entrada": "document_text: str",
        "formato_salida": "lista de links críticos con diagnóstico (score, severity, intervention)",
        "calculo": "analiza texto por link, calcula criticality_score, genera intervenciones",
        "parametros": "document_text: str"
        }
    },
    "TextMiningEngine._analyze_link_text": {
        "file": "analyzer_one.py",
        "questions": ["Q001", "Q005"],
        "dimensions": ["DIM01"],
        "operacionalizacion": {
        "tipo_valor": "PATRON + CUANTITATIVO",
        "formato_entrada": "text: str, link_config: ValueChainLink",
        "formato_salida": "análisis con instrument_coverage, mediator_coverage, bottleneck_density",
        "calculo": "cuenta matches de keywords por categoría, calcula cobertura %",
        "parametros": "text: str, link_config: ValueChainLink"
        }
    },
    "TextMiningEngine._generate_interventions": {
        "file": "analyzer_one.py",
        "questions": ["Q021"],
        "dimensions": ["DIM05"],
        "operacionalizacion": {
        "tipo_valor": "CUALITATIVO (generación texto)",
        "formato_entrada": "link_analysis: dict, link_config: ValueChainLink",
        "formato_salida": "list[str] de intervenciones sugeridas",
        "calculo": "basado en gaps identificados (low coverage, high bottleneck), genera texto de intervención",
        "parametros": "link_analysis: dict, link_config: ValueChainLink"
        }
    },
    "BayesianMechanismInference.infer_mechanisms": {
        "file": "derek_beach.py",
        "questions": ["Q007", "Q015"],
        "dimensions": ["DIM02", "DIM03"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO (posterior bayesiano)",
        "formato_entrada": "text: str, policy_area: str|None",
        "formato_salida": "lista de mecanismos inferidos con type, probability, necessity/sufficiency scores",
        "calculo": "extrae evidencia por tipo mecanismo, aplica tests Beach, actualiza posterior",
        "parametros": "text: str, policy_area: str|None=None"
        }
    },
    "BayesianMechanismInference._test_necessity": {
        "file": "derek_beach.py",
        "questions": ["Q007", "Q012", "Q014", "Q027"],
        "dimensions": ["DIM02", "DIM03", "DIM06"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO",
        "formato_entrada": "mechanism: dict, evidence: dict",
        "formato_salida": "float [0-1] score de necesidad",
        "calculo": "verifica si componente está presente en TODOS los casos positivos, score = proporción presente",
        "parametros": "mechanism: dict, evidence: dict"
        }
    },
    "BayesianMechanismInference._test_sufficiency": {
        "file": "derek_beach.py",
        "questions": ["Q007", "Q012", "Q027"],
        "dimensions": ["DIM02", "DIM03", "DIM06"],
        "operacionalizacion": {
        "tipo_valor": "CUANTITATIVO",
        "formato_entrada": "mechanism: dict, evidence: dict",
        "formato_salida": "float [0-1] score de suficiencia",
        "calculo": "verifica si presencia de componente SIEMPRE produce outcome, score = proporción éxito dado presente",
        "parametros": "mechanism: dict, evidence: dict"
        }
  },
  "FinancialAuditor.trace_financial_allocation": {
    "file": "derek_beach.py",
    "questions": ["Q003"],
    "dimensions": ["DIM01"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (montos)",
      "formato_entrada": "text: str, tables: list[pd.DataFrame]",
      "formato_salida": "trazabilidad de asignaciones: program→amount, gaps detectados, total budget",
      "calculo": "extrae montos de tablas, matchea con metas, calcula cobertura financiera",
      "parametros": "text: str, tables: list[DataFrame]"
    }
  },
  "FinancialAuditor._match_goal_to_budget": {
    "file": "derek_beach.py",
    "questions": ["Q003", "Q013"],
    "dimensions": ["DIM01", "DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "goal_id: str, budget_table: DataFrame",
      "formato_salida": "monto asignado, match_confidence",
      "calculo": "fuzzy matching entre goal_id y filas de tabla presupuestal, extrae monto",
      "parametros": "goal_id: str, budget_table: DataFrame"
    }
  },
  "FinancialAuditor._detect_allocation_gaps": {
    "file": "derek_beach.py",
    "questions": ["Q002", "Q019"],
    "dimensions": ["DIM01", "DIM04"],
    "operacionalizacion": {
      "tipo_valor": "CUALITATIVO + CUANTITATIVO",
      "formato_entrada": "allocations: dict, goals: list[MetaNode]",
      "formato_salida": "lista de gaps (goal_id, expected_amount, actual_amount, gap_ratio)",
      "calculo": "compara asignación real vs esperada, identifica metas sin presupuesto",
      "parametros": "allocations: dict, goals: list"
    }
  },
  "FinancialAuditor._calculate_sufficiency": {
    "file": "derek_beach.py",
    "questions": ["Q003", "Q012", "Q022"],
    "dimensions": ["DIM01", "DIM03", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "allocation: float, goal: MetaNode",
      "formato_salida": "float [0-1] suficiencia presupuestal",
      "calculo": "allocation / (unit_cost × target_quantity), clip [0,1]",
      "parametros": "allocation: float, goal: MetaNode"
    }
  },
  "PolicyContradictionDetector._detect_numerical_inconsistencies": {
    "file": "contradiction_deteccion.py",
    "questions": ["Q002"],
    "dimensions": ["DIM01"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (divergencia)",
      "formato_entrada": "claims: list[dict] con valores numéricos",
      "formato_salida": "lista de inconsistencias con location_a, location_b, divergence_ratio",
      "calculo": "compara claims numéricas sobre mismo concepto, divergence > threshold → inconsistencia",
      "parametros": "claims: list[dict]"
    }
  },
  "PolicyContradictionDetector._calculate_coherence_metrics": {
    "file": "contradiction_deteccion.py",
    "questions": ["Q010"],
    "dimensions": ["DIM02"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "document_sections: dict",
      "formato_salida": "coherence_score [0-1], fragmentation_index, alignment_score",
      "calculo": "mide conectividad semántica entre secciones, penaliza fragmentación",
      "parametros": "document_sections: dict"
    }
  },
  "TemporalLogicVerifier.verify_temporal_consistency": {
    "file": "contradiction_deteccion.py",
    "questions": ["Q005"],
    "dimensions": ["DIM01"],
    "operacionalizacion": {
      "tipo_valor": "CUALITATIVO (validación)",
      "formato_entrada": "temporal_claims: list[dict] con fechas/plazos",
      "formato_salida": "list de violaciones temporales (overlap, impossible_sequence, deadline_conflict)",
      "calculo": "ordena eventos, verifica secuencia lógica, detecta conflictos de deadline",
      "parametros": "temporal_claims: list[dict]"
    }
  },
  "TeoriaCambio.construir_grafo_causal": {
    "file": "teoria_cambio.py",
    "questions": ["Q007", "Q026"],
    "dimensions": ["DIM02", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "ESTRUCTURAL (DAG)",
      "formato_entrada": "nodes: list[dict], edges: list[tuple]",
      "formato_salida": "nx.DiGraph con nodos categorizados y aristas validadas",
      "calculo": "construye grafo, valida aciclicidad, asigna categorías causales",
      "parametros": "nodes: list, edges: list"
    }
  },
  "TeoriaCambio._validar_orden_causal": {
    "file": "teoria_cambio.py",
    "questions": ["Q015", "Q021"],
    "dimensions": ["DIM03", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "CUALITATIVO (validación)",
      "formato_entrada": "source_node: dict, target_node: dict",
      "formato_salida": "bool valid, str violation_reason if invalid",
      "calculo": "verifica orden jerárquico: insumo→actividad→producto→resultado→impacto",
      "parametros": "source_node: dict, target_node: dict"
    }
  },
  "AdvancedDAGValidator.calculate_acyclicity_pvalue": {
    "file": "teoria_cambio.py",
    "questions": ["Q014", "Q028"],
    "dimensions": ["DIM03", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (estadístico)",
      "formato_entrada": "graph: nx.DiGraph",
      "formato_salida": "p-value para test de aciclicidad",
      "calculo": "test estadístico de estructura DAG, bootstrapped confidence",
      "parametros": "graph: nx.DiGraph"
    }
  },
  "PDETMunicipalPlanAnalyzer.analyze_financial_feasibility": {
    "file": "financiero_viabilidad_tablas copy.py",
    "questions": ["Q003", "Q012", "Q015"],
    "dimensions": ["DIM01", "DIM03"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "tables: list[DataFrame], text: str",
      "formato_salida": "feasibility_score [0-1], funding_gaps, sustainability_assessment",
      "calculo": "extrae presupuestos, calcula ratio ingresos/gastos, proyección temporal",
      "parametros": "tables: list[DataFrame], text: str"
    }
  },
  "PDETMunicipalPlanAnalyzer.identify_responsible_entities": {
    "file": "financiero_viabilidad_tablas copy.py",
    "questions": ["Q004", "Q013"],
    "dimensions": ["DIM01", "DIM03"],
    "operacionalizacion": {
      "tipo_valor": "PATRON (NER)",
      "formato_entrada": "text: str, tables: list[DataFrame]",
      "formato_salida": "lista de entidades responsables con type (secretaría, ONG, comunidad), confidence",
      "calculo": "NER spaCy + extracción de tablas de responsabilidades, consolidación",
      "parametros": "text: str, tables: list"
    }
  },
  "PDETMunicipalPlanAnalyzer.sensitivity_analysis": {
    "file": "financiero_viabilidad_tablas copy.py",
    "questions": ["Q009"],
    "dimensions": ["DIM02"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "model: dict, perturbation_range: float",
      "formato_salida": "sensitivity_map por variable, critical_variables, robustness_score",
      "calculo": "perturba cada variable ±range%, mide impacto en output, identifica alta sensibilidad",
      "parametros": "model: dict, perturbation_range: float=0.10"
    }
  },
  "PolicyAnalysisEmbedder.process_document": {
    "file": "embedding_policy.py",
    "questions": ["Q013", "Q022"],
    "dimensions": ["DIM03", "DIM05"],
    "operacionalizacion": {
      "tipo_valor": "VECTORIAL (embeddings)",
      "formato_entrada": "document: str",
      "formato_salida": "embedded_chunks: list[np.array], metadata: dict",
      "calculo": "segmenta documento, genera embeddings sentence-transformers, almacena metadata",
      "parametros": "document: str"
    }
  },
  "PolicyAnalysisEmbedder.semantic_search": {
    "file": "embedding_policy.py",
    "questions": ["Q013"],
    "dimensions": ["DIM03"],
    "operacionalizacion": {
      "tipo_valor": "VECTORIAL + RANKING",
      "formato_entrada": "query: str, top_k: int",
      "formato_salida": "lista de chunks ordenados por similaridad coseno con scores",
      "calculo": "embed query → cosine similarity con todos los chunks → top_k",
      "parametros": "query: str, top_k: int=5"
    }
  },
  "SemanticProcessor.chunk_text": {
    "file": "semantic_chunking_policy.py",
    "questions": ["Q001", "Q030"],
    "dimensions": ["DIM01", "DIM06"],
    "operacionalizacion": {
      "tipo_valor": "ESTRUCTURAL (segmentación)",
      "formato_entrada": "text: str, chunk_size: int, overlap: int",
      "formato_salida": "list[str] de chunks con overlap",
      "calculo": "segmenta por oraciones, agrupa hasta chunk_size, mantiene overlap",
      "parametros": "text: str, chunk_size: int=512, overlap: int=50"
    }
  },
  "ConfigLoader.update_priors_from_feedback": {
    "file": "derek_beach.py",
    "questions": ["Q029"],
    "dimensions": ["DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO (actualización bayesiana)",
      "formato_entrada": "feedback_data: dict con {mechanism_type: accuracy_observed}",
      "formato_salida": "priors actualizados en config",
      "calculo": "weighted average: new_prior = (1-weight)*old_prior + weight*observed_accuracy",
      "parametros": "feedback_data: dict[str, Any]"
    }
  },
  "ConfigLoader.check_uncertainty_reduction_criterion": {
    "file": "derek_beach.py",
    "questions": ["Q029"],
    "dimensions": ["DIM06"],
    "operacionalizacion": {
      "tipo_valor": "CUANTITATIVO",
      "formato_entrada": "current_uncertainty: float",
      "formato_salida": "dict con meets_criterion: bool, trend: str, reduction_rate: float",
      "calculo": "compara uncertainty actual vs histórico, calcula tasa de reducción",
      "parametros": "current_uncertainty: float"
    }
  }
}
