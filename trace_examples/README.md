# Trace Examples

This directory contains example trace files demonstrating the operation tracing system for audit trails.

## Overview

The trace system captures mathematical operations during calibration and scoring, recording:
- Operation name (e.g., `np.mean`, `aggregate_scores`)
- Input values
- Output values
- Stack trace showing code path
- Timestamp

## Files

### example_traces.json
Example traces generated by `create_trace_example()` function showing typical operations.

### calibration_trace_example.json
Example of a complete calibration run with full operation traces.

### determinism_trace_example.json
Example demonstrating deterministic execution with identical inputs producing identical traces.

## Usage

```python
from src.cross_cutting_infrastrucuture.contractual.dura_lex.audit_trail import TraceGenerator

# Enable tracing during operations
with TraceGenerator(enabled=True) as tracer:
    result = perform_calibration()
    tracer.trace_operation("calibration", {"inputs": data}, result)
    
    # Get traces for manifest
    traces = tracer.get_traces()
```

## Trace Format

Each trace entry contains:

```json
{
  "operation": "string",
  "inputs": {
    "param1": "value1",
    "param2": "value2"
  },
  "output": "result_value",
  "stack_trace": [
    "file.py:line in function_name",
    "..."
  ],
  "timestamp": "ISO-8601 UTC timestamp"
}
```

## Integration

Traces are automatically included in VerificationManifest when generated during calibration.
They provide reproducibility verification and debugging information.
