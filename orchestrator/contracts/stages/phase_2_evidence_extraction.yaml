# Phase 2: Evidence Extraction Contract
# ============================================================================
# This is the most complex phase - NLP-based evidence extraction

stage: phase_2_evidence_extraction

contract:
  inputs:
    required:
      - name: parsed_document
        schema:
          type: object
          properties:
            document_id: { type: string }
            sections: { type: array, items: { type: object } }
            tables: { type: array, items: { type: object } }
            full_text: { type: string, minLength: 1000 }
        source: phase_1_document_ingestion
        
      - name: canonical_questionnaire
        schema:
          type: object
          properties:
            micro_questions: { type: array, minItems: 300, maxItems: 300 }
            version: { type: string, pattern: "^\\d+\\.\\d+\\.\\d+$" }
        source: phase_0_bootstrap

    optional:
      - name: pattern_override
        schema: { type: object }
        default: null

  outputs:
    guaranteed:
      - name: evidence_package
        schema:
          type: object
          properties:
            document_id: { type: string }
            extractions:
              type: array
              minItems: 300
              items:
                type: object
                properties:
                  question_id: { type: string, pattern: "^Q\\d{3}$" }
                  evidence_found: { type: boolean }
                  matches: { type: array }
                  confidence: { type: number, minimum: 0, maximum: 1 }
                  patterns_matched: { type: array }
        destination: phase_3_scoring

  invariants:
    - "len(output.extractions) == 300"
    - "all(e.question_id matches 'Q\\d{3}' for e in output.extractions)"
    - "output.document_id == input.parsed_document.document_id"
    - "no duplicate question_ids in output.extractions"

  idempotency:
    key: "${document_id}-phase2-${questionnaire_version}"
    strategy: skip_if_exists

  retry_policy:
    max_attempts: 2
    backoff_strategy: exponential
    backoff_base_seconds: 60
    retryable_errors:
      - "NLP_MODEL_TIMEOUT"
      - "EMBEDDING_SERVICE_ERROR"
    non_retryable_errors:
      - "DOCUMENT_STRUCTURE_ERROR"
      - "PATTERN_SYNTAX_ERROR"

  timeout_seconds: 1800  # 30 minutes

  compensating_action:
    description: "Remove partial extraction artifacts"
    steps:
      - action: delete_file
        target: "artifacts/evidence/${document_id}_*.json"

observability:
  metrics:
    - name: evidence_extraction_duration
      type: histogram
      labels: [document_id, policy_area]
    - name: pattern_match_count
      type: counter
      labels: [question_id, pattern_id]
    - name: extraction_confidence_distribution
      type: histogram
      labels: [dimension_id]
      
  logs:
    correlation_id: true
    structured: true
    fields:
      - run_id
      - document_id
      - question_id
      - patterns_searched
      - matches_found
      
  traces:
    enabled: true
    span_name: "phase2_extract_${dimension_id}"
