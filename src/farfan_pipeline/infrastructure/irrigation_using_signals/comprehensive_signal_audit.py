"""
Comprehensive Signal Irrigation Ecosystem Audit

Executable Python script that performs complete technical audit with:
1. Wiring Verification - Complete data flow tracing
2. Principle Implementation Assessment - SCOPE COHERENCE, SYNCHRONIZATION, UTILITY
3. Production-Ready Code Fixes - Missing interfaces, disconnected components
4. Architecture Visualizations - Sankey, state machine, heatmap
5. Quantitative Metrics - Coverage, precision, latency, value-add

Usage:
    python comprehensive_signal_audit.py

Author: F.A.R.F.A.N Pipeline Audit System
Date: 2025-01-15
"""

from __future__ import annotations

import json
import re
import time
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

try:
    import structlog
    logger = structlog.get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)

from orchestration.factory import load_questionnaire, create_signal_registry
from cross_cutting_infrastructure.irrigation_using_signals.SISAS.signal_registry import (
    QuestionnaireSignalRegistry,
)
from cross_cutting_infrastructure.irrigation_using_signals.SISAS.signal_consumption import (
    SignalConsumptionProof,
    QuestionnaireAccessAudit,
    AccessLevel,
    get_access_audit,
)
from cross_cutting_infrastructure.irrigation_using_signals.SISAS.signal_context_scoper import (
    filter_patterns_by_context,
    create_document_context,
)
from cross_cutting_infrastructure.irrigation_using_signals.SISAS.signal_consumption_integration import (
    ConsumptionTracker,
    create_consumption_tracker,
    inject_consumption_tracking,
)
from cross_cutting_infrastructure.irrigation_using_signals.SISAS.signal_evidence_extractor import (
    extract_structured_evidence,
)
from cross_cutting_infrastructure.irrigation_using_signals.audit_signal_irrigation import (
    WiringAuditor,
    ScopeCoherenceAuditor,
    SynchronizationAuditor,
    UtilityAuditor,
    SignalIrrigationAuditor,
)


@dataclass
class ComprehensiveAuditResults:
    """Complete audit results with all metrics and visualizations."""
    
    wiring_gaps: list[dict[str, Any]] = field(default_factory=list)
    scope_violations: list[dict[str, Any]] = field(default_factory=list)
    synchronization_issues: list[dict[str, Any]] = field(default_factory=list)
    utilization_metrics: dict[str, Any] = field(default_factory=dict)
    coverage_metrics: dict[str, Any] = field(default_factory=dict)
    precision_metrics: dict[str, Any] = field(default_factory=dict)
    latency_metrics: dict[str, Any] = field(default_factory=dict)
    access_audit_report: dict[str, Any] = field(default_factory=dict)
    
    # Flow trace data
    signal_flow_trace: list[dict[str, Any]] = field(default_factory=list)
    
    # Visualization data
    sankey_data: dict[str, Any] | None = None
    state_machine_data: dict[str, Any] | None = None
    heatmap_data: dict[str, Any] | None = None


class ComprehensiveSignalAuditor:
    """Comprehensive auditor with full flow tracing and metric generation."""
    
    def __init__(self, questionnaire_path: Path | None = None):
        self.questionnaire_path = questionnaire_path
        self.questionnaire = None
        self.signal_registry: QuestionnaireSignalRegistry | None = None
        self.results = ComprehensiveAuditResults()
        self.flow_trace: list[dict[str, Any]] = []
    
    def run_comprehensive_audit(self) -> ComprehensiveAuditResults:
        """Run complete comprehensive audit."""
        logger.info("comprehensive_signal_audit_started")
        
        # Initialize components
        self._initialize_components()
        
        if not self.questionnaire or not self.signal_registry:
            logger.error("audit_failed_initialization")
            return self.results
        
        # 1. Wiring Verification
        logger.info("audit_phase_wiring_verification")
        wiring_auditor = WiringAuditor(self.questionnaire, self.signal_registry)
        wiring_gaps = wiring_auditor.audit_wiring()
        self.results.wiring_gaps = [
            {
                "source_component": g.source_component,
                "target_component": g.target_component,
                "missing_interface": g.missing_interface,
                "severity": g.severity,
                "description": g.description,
                "fix_suggestion": g.fix_suggestion,
            }
            for g in wiring_gaps
        ]
        
        # 2. Scope Coherence Audit
        logger.info("audit_phase_scope_coherence")
        scope_auditor = ScopeCoherenceAuditor(self.questionnaire, self.signal_registry)
        scope_violations = scope_auditor.audit_scope_coherence()
        self.results.scope_violations = [
            {
                "violation_type": v.violation_type,
                "question_id": v.question_id,
                "policy_area": v.policy_area,
                "accessed_pattern_id": v.accessed_pattern_id,
                "violation_details": v.violation_details,
                "expected_scope": v.expected_scope,
                "actual_scope": v.actual_scope,
            }
            for v in scope_violations
        ]
        self.results.access_audit_report = get_access_audit().get_utilization_report()
        
        # 3. Trace Complete Data Flow
        logger.info("audit_phase_data_flow_trace")
        self._trace_complete_data_flow()
        
        # 4. Synchronization Audit
        logger.info("audit_phase_synchronization")
        sync_auditor = SynchronizationAuditor()
        # Use flow trace data for synchronization analysis
        sync_issues = sync_auditor.audit_synchronization(self.flow_trace)
        self.results.synchronization_issues = [
            {
                "phase_id": issue.phase_id,
                "executor_id": issue.executor_id,
                "issue_type": issue.issue_type,
                "description": issue.description,
                "injection_time": issue.injection_time,
                "consumption_time": issue.consumption_time,
                "phase_state": issue.phase_state,
            }
            for issue in sync_issues
        ]
        
        # 5. Utility Audit
        logger.info("audit_phase_utility")
        utility_auditor = UtilityAuditor(self.signal_registry)
        utilization_metrics = utility_auditor.audit_utility(self.flow_trace)
        self.results.utilization_metrics = {
            "total_patterns_injected": utilization_metrics.total_patterns_injected,
            "patterns_consumed": utilization_metrics.patterns_consumed,
            "patterns_produced_evidence": utilization_metrics.patterns_produced_evidence,
            "waste_ratio": utilization_metrics.waste_ratio,
            "proof_chains_complete": utilization_metrics.proof_chains_complete,
            "proof_chains_incomplete": utilization_metrics.proof_chains_incomplete,
            "avg_latency_ms": utilization_metrics.avg_latency_ms,
        }
        
        # 6. Calculate Quantitative Metrics
        logger.info("audit_phase_quantitative_metrics")
        self._calculate_quantitative_metrics()
        
        # 7. Generate Visualizations
        logger.info("audit_phase_visualizations")
        self._generate_visualizations()
        
        logger.info("comprehensive_signal_audit_completed")
        return self.results
    
    def _initialize_components(self) -> None:
        """Initialize questionnaire and signal registry."""
        try:
            from canonic_phases.Phase_zero.phase0_10_00_paths import PROJECT_ROOT
            
            if self.questionnaire_path is None:
                # Default questionnaire path
                self.questionnaire_path = (
                    PROJECT_ROOT / "canonic_questionnaire_central" / "questionnaire_monolith.json"
                )
            
            if not self.questionnaire_path.exists():
                logger.error("questionnaire_not_found", path=str(self.questionnaire_path))
                return
            
            # Load questionnaire
            self.questionnaire = load_questionnaire(self.questionnaire_path)
            
            # Create signal registry
            self.signal_registry = create_signal_registry(self.questionnaire)
            
            logger.info(
                "components_initialized",
                questionnaire_sha256=self.questionnaire.sha256[:16] + "...",
            )
        except Exception as e:
            logger.error("initialization_failed", error=str(e), exc_info=True)
            raise
    
    def _trace_complete_data_flow(self) -> None:
        """Trace complete data flow from questionnaire to pattern matching."""
        logger.info("tracing_complete_data_flow")
        
        blocks = self.questionnaire.data.get("blocks", {})
        questions = blocks.get("micro_questions", [])
        
        # Sample first 10 questions for comprehensive tracing
        sample_questions = questions[:10]
        
        for question in sample_questions:
            q_id = question.get("question_id", "")
            pa_id = question.get("policy_area_id", "")
            
            if not q_id or not pa_id:
                continue
            
            trace_entry = {
                "question_id": q_id,
                "policy_area": pa_id,
                "timestamp": time.time(),
                "flow_steps": [],
            }
            
            try:
                # Step 1: Registry retrieval
                step1_start = time.time()
                signals = self.signal_registry.get_micro_answering_signals(q_id)
                step1_duration = (time.time() - step1_start) * 1000
                
                trace_entry["flow_steps"].append({
                    "step": "registry_retrieval",
                    "duration_ms": step1_duration,
                    "patterns_retrieved": len(signals.question_patterns.get(q_id, [])),
                })
                
                # Step 2: Create consumption tracker
                tracker = create_consumption_tracker("TEST_EXECUTOR", q_id, pa_id)
                injection_time = time.time()
                
                trace_entry["flow_steps"].append({
                    "step": "tracker_creation",
                    "timestamp": injection_time,
                })
                
                # Step 3: Extract patterns and simulate matching
                patterns = signals.question_patterns.get(q_id, [])
                patterns_injected = len(patterns)
                
                trace_entry["flow_steps"].append({
                    "step": "pattern_injection",
                    "patterns_injected": patterns_injected,
                })
                
                # Step 4: Simulate pattern matching with test text
                test_text = "Este documento contiene informaciÃ³n sobre indicadores, fuentes oficiales y cobertura territorial."
                
                signal_node = {
                    "id": q_id,
                    "expected_elements": signals.expected_elements.get(q_id, []),
                    "patterns": [{"pattern": p.pattern, "id": p.id, "category": p.category} for p in patterns],
                    "validations": {},
                }
                
                step4_start = time.time()
                evidence_result = extract_structured_evidence(
                    text=test_text,
                    signal_node=signal_node,
                    document_context=None,
                    consumption_tracker=tracker,
                )
                step4_duration = (time.time() - step4_start) * 1000
                
                # Step 5: Record consumption
                consumption_time = time.time()
                summary = tracker.get_consumption_summary()
                
                trace_entry["flow_steps"].append({
                    "step": "pattern_matching",
                    "duration_ms": step4_duration,
                    "patterns_matched": summary["match_count"],
                    "evidence_produced": summary["evidence_count"],
                    "latency_ms": (consumption_time - injection_time) * 1000,
                })
                
                trace_entry["injection_time"] = injection_time
                trace_entry["consumption_time"] = consumption_time
                trace_entry["signal_pack"] = {
                    "question_id": q_id,
                    "patterns_count": patterns_injected,
                }
                trace_entry["pattern_matches"] = [
                    {
                        "pattern_id": "SIMULATED",
                        "produced_evidence": True,
                        "timestamp": consumption_time,
                    }
                ]
                
                self.flow_trace.append(trace_entry)
                self.results.signal_flow_trace.append(trace_entry)
                
            except Exception as e:
                logger.warning(
                    "flow_trace_failed",
                    question_id=q_id,
                    error=str(e),
                )
                trace_entry["flow_steps"].append({
                    "step": "error",
                    "error": str(e),
                })
    
    def _calculate_quantitative_metrics(self) -> None:
        """Calculate comprehensive quantitative metrics."""
        if not self.questionnaire or not self.signal_registry:
            return
        
        blocks = self.questionnaire.data.get("blocks", {})
        questions = blocks.get("micro_questions", [])
        
        # Coverage: % of questionnaire patterns actually extracted
        total_patterns_in_questionnaire = 0
        patterns_extracted = 0
        
        for question in questions[:50]:  # Sample for performance
            q_id = question.get("question_id", "")
            if not q_id:
                continue
            
            patterns_raw = question.get("patterns", [])
            total_patterns_in_questionnaire += len(patterns_raw)
            
            try:
                signals = self.signal_registry.get_micro_answering_signals(q_id)
                extracted = signals.question_patterns.get(q_id, [])
                patterns_extracted += len(extracted)
            except Exception:
                continue
        
        coverage = 0.0
        if total_patterns_in_questionnaire > 0:
            coverage = patterns_extracted / total_patterns_in_questionnaire
        
        self.results.coverage_metrics = {
            "pattern_extraction_coverage": coverage,
            "total_patterns_in_questionnaire": total_patterns_in_questionnaire,
            "patterns_extracted": patterns_extracted,
        }
        
        # Precision: Calculate from flow trace
        total_matches = sum(len(trace.get("pattern_matches", [])) for trace in self.flow_trace)
        total_injected = sum(
            trace.get("signal_pack", {}).get("patterns_count", 0) for trace in self.flow_trace
        )
        
        false_positive_rate = 0.0  # Would need ground truth for actual calculation
        true_positive_rate = 0.0
        
        if total_injected > 0:
            true_positive_rate = total_matches / total_injected
        
        self.results.precision_metrics = {
            "false_positive_rate": false_positive_rate,
            "true_positive_rate": true_positive_rate,
            "total_patterns_matched": total_matches,
            "total_patterns_injected": total_injected,
        }
        
        # Latency: From flow trace
        latencies = []
        for trace in self.flow_trace:
            inj_time = trace.get("injection_time")
            cons_time = trace.get("consumption_time")
            if inj_time and cons_time:
                latencies.append((cons_time - inj_time) * 1000)
        
        avg_latency = sum(latencies) / len(latencies) if latencies else 0.0
        
        self.results.latency_metrics = {
            "avg_injection_to_consumption_ms": avg_latency,
            "min_latency_ms": min(latencies) if latencies else 0.0,
            "max_latency_ms": max(latencies) if latencies else 0.0,
            "latency_samples": len(latencies),
        }
    
    def _generate_visualizations(self) -> None:
        """Generate all visualizations."""
        from cross_cutting_infrastructure.irrigation_using_signals.visualization_generator import (
            SankeyDiagramGenerator,
            StateMachineGenerator,
            HeatmapGenerator,
        )
        
        # Generate Sankey diagram
        sankey = SankeyDiagramGenerator()
        
        # Add nodes and links from flow trace
        for trace in self.flow_trace:
            q_id = trace.get("question_id", "")
            pa_id = trace.get("policy_area", "")
            
            # Questionnaire -> Registry
            sankey.add_link("questionnaire", "signal_registry", 1)
            
            # Registry -> Executor
            patterns_count = trace.get("signal_pack", {}).get("patterns_count", 0)
            sankey.add_link("signal_registry", f"executor_{q_id}", patterns_count)
            
            # Executor -> Pattern Matching
            matches_count = len(trace.get("pattern_matches", []))
            sankey.add_link(f"executor_{q_id}", "pattern_matching", matches_count)
            
            # Pattern Matching -> Evidence
            evidence_count = sum(
                step.get("evidence_produced", 0)
                for step in trace.get("flow_steps", [])
                if step.get("step") == "pattern_matching"
            )
            sankey.add_link("pattern_matching", "evidence", evidence_count)
        
        self.results.sankey_data = sankey.to_d3_json()
        
        # Generate state machine
        state_machine = StateMachineGenerator()
        
        state_machine.add_state("idle", "Idle", "initial")
        state_machine.add_state("loading_questionnaire", "Loading Questionnaire", "normal")
        state_machine.add_state("extracting_signals", "Extracting Signals", "normal")
        state_machine.add_state("phase_executing", "Phase Executing", "normal")
        state_machine.add_state("signal_injecting", "Signal Injecting", "normal")
        state_machine.add_state("pattern_matching", "Pattern Matching", "normal")
        state_machine.add_state("evidence_assembling", "Evidence Assembling", "normal")
        state_machine.add_state("validating", "Validating", "normal")
        state_machine.add_state("complete", "Complete", "final")
        state_machine.add_state("error", "Error", "final")
        
        state_machine.add_transition("idle", "loading_questionnaire", "Start Pipeline")
        state_machine.add_transition("loading_questionnaire", "extracting_signals", "Questionnaire Loaded")
        state_machine.add_transition("extracting_signals", "phase_executing", "Signals Extracted")
        state_machine.add_transition("phase_executing", "signal_injecting", "Phase Started")
        state_machine.add_transition("signal_injecting", "pattern_matching", "Signals Injected")
        state_machine.add_transition("pattern_matching", "evidence_assembling", "Patterns Matched")
        state_machine.add_transition("evidence_assembling", "validating", "Evidence Assembled")
        state_machine.add_transition("validating", "complete", "Validation Passed")
        state_machine.add_transition("validating", "error", "Validation Failed")
        
        self.results.state_machine_data = state_machine.to_cytoscape_json()
        
        # Generate heatmap
        heatmap = HeatmapGenerator()
        
        for trace in self.flow_trace:
            pa_id = trace.get("policy_area", "UNKNOWN")
            phase = "Phase_2"  # Micro answering phase
            
            # Utilization ratio
            patterns_injected = trace.get("signal_pack", {}).get("patterns_count", 0)
            patterns_matched = len(trace.get("pattern_matches", []))
            
            utilization = patterns_matched / patterns_injected if patterns_injected > 0 else 0.0
            heatmap.add_data_point(phase, pa_id, utilization)
        
        self.results.heatmap_data = heatmap.to_d3_json()
    
    def generate_report(self, output_dir: Path) -> Path:
        """Generate comprehensive audit report with all data."""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Main report
        report_path = output_dir / f"comprehensive_signal_audit_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            "audit_timestamp": datetime.now(timezone.utc).isoformat(),
            "questionnaire_sha256": self.questionnaire.sha256[:16] + "..." if self.questionnaire else None,
            "wiring_gaps": self.results.wiring_gaps,
            "scope_violations": self.results.scope_violations,
            "synchronization_issues": self.results.synchronization_issues,
            "utilization_metrics": self.results.utilization_metrics,
            "coverage_metrics": self.results.coverage_metrics,
            "precision_metrics": self.results.precision_metrics,
            "latency_metrics": self.results.latency_metrics,
            "access_audit_report": self.results.access_audit_report,
            "signal_flow_trace": self.results.signal_flow_trace[:5],  # Sample first 5
            "visualizations": {
                "sankey": self.results.sankey_data is not None,
                "state_machine": self.results.state_machine_data is not None,
                "heatmap": self.results.heatmap_data is not None,
            },
        }
        
        report_path.write_text(json.dumps(report, indent=2))
        logger.info("comprehensive_report_generated", output_path=str(report_path))
        
        # Save visualization data separately
        viz_dir = output_dir / "visualizations"
        viz_dir.mkdir(parents=True, exist_ok=True)
        
        if self.results.sankey_data:
            (viz_dir / "sankey_diagram.json").write_text(
                json.dumps(self.results.sankey_data, indent=2)
            )
        
        if self.results.state_machine_data:
            (viz_dir / "state_machine.json").write_text(
                json.dumps(self.results.state_machine_data, indent=2)
            )
        
        if self.results.heatmap_data:
            (viz_dir / "heatmap.json").write_text(
                json.dumps(self.results.heatmap_data, indent=2)
            )
        
        return report_path


def main() -> None:
    """Main entry point for comprehensive audit."""
    from canonic_phases.Phase_zero.phase0_10_00_paths import PROJECT_ROOT
    
    output_dir = PROJECT_ROOT / "artifacts" / "comprehensive_signal_audit"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    auditor = ComprehensiveSignalAuditor()
    results = auditor.run_comprehensive_audit()
    
    report_path = auditor.generate_report(output_dir)
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE SIGNAL IRRIGATION AUDIT COMPLETE")
    print("=" * 80 + "\n")
    print(f"Wiring Gaps: {len(results.wiring_gaps)}")
    print(f"  - Critical: {sum(1 for g in results.wiring_gaps if g['severity'] == 'CRITICAL')}")
    print(f"  - High: {sum(1 for g in results.wiring_gaps if g['severity'] == 'HIGH')}")
    print(f"\nScope Violations: {len(results.scope_violations)}")
    print(f"Synchronization Issues: {len(results.synchronization_issues)}")
    print(f"\nCoverage Metrics:")
    print(f"  - Pattern Extraction Coverage: {results.coverage_metrics.get('pattern_extraction_coverage', 0.0):.1%}")
    print(f"  - Patterns Extracted: {results.coverage_metrics.get('patterns_extracted', 0)}")
    print(f"\nUtilization Metrics:")
    print(f"  - Waste Ratio: {results.utilization_metrics.get('waste_ratio', 0.0):.1%}")
    print(f"  - Patterns Consumed: {results.utilization_metrics.get('patterns_consumed', 0)}")
    print(f"  - Avg Latency: {results.utilization_metrics.get('avg_latency_ms', 0.0):.2f} ms")
    print(f"\nReport saved to: {report_path}")
    print(f"Visualizations saved to: {output_dir / 'visualizations'}")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()

