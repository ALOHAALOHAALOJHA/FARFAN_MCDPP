{
  "identity": {
    "base_slot": "D1-Q4",
    "question_id": "Q274",
    "dimension_id": "DIM01",
    "policy_area_id": "PA10",
    "contract_version": "3.1.0-Jurist-Massive",
    "contract_hash": "f6bf13415f209d6e411342b0077bac13523de26659084efb35990c423c40c8db",
    "created_at": "2025-11-28T03:50:42.385400+00:00",
    "validated_against_schema": "executor_contract.v3.schema.json",
    "cluster_id": "CL04",
    "question_global": 274,
    "updated_at": "2025-12-16T04:42:58.716413+00:00"
  },
  "executor_binding": {
    "executor_class": "D1_Q4_Executor",
    "executor_module": "farfan_core.core.orchestrator.executors"
  },
  "method_binding": {
    "orchestration_mode": "multi_method_pipeline",
    "method_count": 11,
    "methods": [
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "identify_responsible_entities",
        "priority": 1,
        "provides": "pdet_analysis.identify_responsible_entities",
        "role": "identify_responsible_entities_execution",
        "description": "PDETMunicipalPlanAnalyzer.identify_responsible_entities"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_extract_entities_ner",
        "priority": 2,
        "provides": "pdet_analysis.extract_entities_ner",
        "role": "_extract_entities_ner_extraction",
        "description": "PDETMunicipalPlanAnalyzer._extract_entities_ner"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_extract_entities_syntax",
        "priority": 3,
        "provides": "pdet_analysis.extract_entities_syntax",
        "role": "_extract_entities_syntax_extraction",
        "description": "PDETMunicipalPlanAnalyzer._extract_entities_syntax"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_classify_entity_type",
        "priority": 4,
        "provides": "pdet_analysis.classify_entity_type",
        "role": "_classify_entity_type_execution",
        "description": "PDETMunicipalPlanAnalyzer._classify_entity_type"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_score_entity_specificity",
        "priority": 5,
        "provides": "pdet_analysis.score_entity_specificity",
        "role": "_score_entity_specificity_execution",
        "description": "PDETMunicipalPlanAnalyzer._score_entity_specificity"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_consolidate_entities",
        "priority": 6,
        "provides": "pdet_analysis.consolidate_entities",
        "role": "_consolidate_entities_execution",
        "description": "PDETMunicipalPlanAnalyzer._consolidate_entities"
      },
      {
        "class_name": "MechanismPartExtractor",
        "method_name": "extract_entity_activity",
        "priority": 7,
        "provides": "mechanismpartextractor.extract_entity_activity",
        "role": "extract_entity_activity_extraction",
        "description": "MechanismPartExtractor.extract_entity_activity"
      },
      {
        "class_name": "MechanismPartExtractor",
        "method_name": "_normalize_entity",
        "priority": 8,
        "provides": "mechanismpartextractor.normalize_entity",
        "role": "_normalize_entity_execution",
        "description": "MechanismPartExtractor._normalize_entity"
      },
      {
        "class_name": "MechanismPartExtractor",
        "method_name": "_validate_entity_activity",
        "priority": 9,
        "provides": "mechanismpartextractor.validate_entity_activity",
        "role": "_validate_entity_activity_validation",
        "description": "MechanismPartExtractor._validate_entity_activity"
      },
      {
        "class_name": "MechanismPartExtractor",
        "method_name": "_calculate_ea_confidence",
        "priority": 10,
        "provides": "mechanismpartextractor.calculate_ea_confidence",
        "role": "_calculate_ea_confidence_calculation",
        "description": "MechanismPartExtractor._calculate_ea_confidence"
      },
      {
        "class_name": "OperationalizationAuditor",
        "method_name": "audit_evidence_traceability",
        "priority": 11,
        "provides": "operationalizationauditor.audit_evidence_traceability",
        "role": "audit_evidence_traceability_execution",
        "description": "OperationalizationAuditor.audit_evidence_traceability"
      }
    ],
    "note": "All 11 methods extracted from D1_Q4_Executor in executors.py"
  },
  "question_context": {
    "question_text": "¿El PDM describe las capacidades para gestionar la crisis carcelaria municipal, mencionando entidades (Secretaría de Gobierno, Personería) y sus necesidades? Se debe buscar términos como 'convenios con INPEC', 'atención en salud intramural' y si se identifican 'limitaciones'.",
    "question_type": "micro",
    "scoring_modality": "TYPE_B",
    "modality": "count_and_scale",
    "expected_output_type": "score",
    "patterns": [
      {
        "category": "FUENTE_OFICIAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-000",
        "match_type": "NER_OR_REGEX",
        "pattern": "Secretaría de Gobierno|Comando de Policía Municipal",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "entity_type": "ORG",
        "glossary_metadata": {
          "full_name": "TBD",
          "legal_mandate": "TBD",
          "jurisdiction": "National",
          "founding_year": "TBD"
        },
        "synonym_clusters": [
          "functional_description",
          "historical_name"
        ],
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "TERRITORIAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-001",
        "match_type": "REGEX",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "pattern_ref": "PAT-0014",
        "pattern": "Personería Municipal|Defensoría del Pueblo Regional",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-002",
        "match_type": "REGEX",
        "pattern": "Secretaría de Salud|ESE Hospital",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-003",
        "match_type": "REGEX",
        "pattern": "capacidad instalada en centros de detención transitoria|cupos disponibles",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-004",
        "match_type": "REGEX",
        "pattern": "protocolo para el traslado de PPL|ruta de atención en salud",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-005",
        "match_type": "REGEX",
        "pattern": "sistema de información de la población reclusa local",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-006",
        "match_type": "REGEX",
        "pattern": "Comité de seguimiento al sistema penitenciario y carcelario",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-007",
        "match_type": "REGEX",
        "pattern": "articulación con el INPEC|convenio con la USPEC|coordinación con la rama judicial",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-008",
        "match_type": "REGEX",
        "pattern": "falta de infraestructura|insuficiencia de cupos|limitada capacidad de la Personería",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q274-009",
        "match_type": "REGEX",
        "pattern": "cuello de botella|barrera de acceso a la justicia|limitaciones de competencia",
        "specificity": "MEDIUM",
        "validation_rule": null,
        "context_requirement": null,
        "semantic_expansion": null,
        "context_scope": "PARAGRAPH",
        "policy_area": "PA09"
      }
    ],
    "expected_elements": [
      {
        "required": true,
        "type": "cuellos_botella",
        "minimum": 1
      },
      {
        "required": true,
        "type": "gobernanza",
        "minimum": 1
      },
      {
        "required": true,
        "type": "infraestructura_fisica",
        "minimum": 1
      },
      {
        "required": true,
        "type": "procesos",
        "minimum": 1
      },
      {
        "required": true,
        "type": "talento_humano",
        "minimum": 1
      }
    ],
    "validations": {},
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text"
      ],
      "emit_code": "ABORT-Q274-REQ"
    }
  },
  "signal_requirements": {
    "mandatory_signals": [],
    "optional_signals": [],
    "signal_aggregation": "weighted_mean",
    "minimum_signal_threshold": 0.5,
    "note": "Signal requirements are under development. Canonical mapping pending for PA01/DIM01; mandatory_signals and optional_signals are intentionally empty to avoid blocking execution.",
    "preferred_signal_types": [
      "policy_instrument_detected",
      "activity_specification_found",
      "implementation_timeline_present"
    ]
  },
  "evidence_assembly": {
    "module": "canonic_phases.Phase_two.evidence_nexus",
    "class_name": "EvidenceNexus",
    "method_name": "assemble",
    "output_schema": {
      "type": "object",
      "required": [
        "elements",
        "raw_results"
      ],
      "properties": {
        "elements": {
          "type": "array",
          "description": "Lista de elementos de evidencia encontrados para esta micro-pregunta."
        },
        "raw_results": {
          "type": "object",
          "properties": {
            "confidence_scores": {
              "type": "array",
              "description": "Scores de confianza usados por el scorer."
            },
            "semantic_similarity": {
              "description": "Métrica de similitud semántica (si aplica)."
            },
            "pattern_matches": {
              "type": "object",
              "description": "Matches de patrones esperados vs texto."
            },
            "metadata": {
              "type": "object",
              "description": "Metadatos arbitrarios pasados al scorer."
            }
          },
          "additionalProperties": true
        }
      },
      "additionalProperties": true
    },
    "assembly_rules": [
      {
        "target": "elements_found",
        "sources": [
          "mechanismpartextractor.calculate_ea_confidence",
          "mechanismpartextractor.extract_entity_activity",
          "mechanismpartextractor.normalize_entity",
          "mechanismpartextractor.validate_entity_activity",
          "operationalizationauditor.audit_evidence_traceability",
          "pdet_analysis.classify_entity_type",
          "pdet_analysis.consolidate_entities",
          "pdet_analysis.extract_entities_ner",
          "pdet_analysis.extract_entities_syntax",
          "pdet_analysis.identify_responsible_entities",
          "pdet_analysis.score_entity_specificity"
        ],
        "merge_strategy": "concat",
        "description": "Combine evidence elements from 11 method invocations"
      },
      {
        "target": "confidence_scores",
        "sources": [],
        "merge_strategy": "weighted_mean",
        "default": [],
        "description": "Aggregate confidence scores across 11 methods"
      },
      {
        "target": "pattern_matches",
        "sources": [],
        "merge_strategy": "concat",
        "default": {},
        "description": "Combine pattern matches across 11 methods"
      },
      {
        "target": "metadata",
        "sources": [],
        "merge_strategy": "concat",
        "description": "Combine metadata from 11 methods for full traceability"
      }
    ],
    "engine": "EVIDENCE_NEXUS"
  },
  "output_contract": {
    "human_readable_output": {
      "format": "markdown",
      "template": {
        "title": "## Análisis Q274: PA10 - D1-Q4",
        "summary": "### Resumen Ejecutivo\n\n**Área de política**: Derechos de las mujeres e igualdad de género\n\n**Dimensión**: INSUMOS\n\nSe analizó la presencia de **{evidence.elements_found_count}** elementos de evidencia relevantes.\n\n**Puntaje**: {score}/3.0 | **Calidad**: {quality_level}",
        "score_section": "### Evaluación\n\n- **Puntaje**: {score}/3.0\n- **Calidad**: {quality_level}\n- **Confianza promedio**: {evidence.confidence_scores.mean}\n- **Hash del grafo**: {evidence.graph_hash}",
        "elements_section": "### Evidencia Identificada\n\n{evidence.elements_found_list}\n\n**Elementos críticos faltantes**: {evidence.missing_required_elements}",
        "interpretation": "### Interpretación\n\n{methodological_interpretation}",
        "recommendations": "### Recomendaciones\n\n{evidence.recommendations}"
      },
      "methodological_depth": {
        "methods": [
          {
            "method_name": "identify_responsible_entities",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 1,
            "role": "identify_responsible_entities_identification",
            "epistemological_foundation": {
              "paradigm": "Institutional Theory + Named Entity Recognition",
              "ontological_basis": "Organizational capabilities exist as semi-structured textual mentions of institutional actors with specific responsibilities for gender policy management. Entities have ontological reality as named organizations (Secretarías, Comisarías) with identifiable functions.",
              "epistemological_stance": "Hybrid NLP-Institutional epistemology: knowledge of responsible entities is acquired through computational extraction (spaCy NER, syntax parsing) validated against institutional theory (March & Olsen 1984 on organizational capabilities, DiMaggio & Powell 1983 on institutional isomorphism). Extraction confidence combines NER precision with entity type specificity.",
              "theoretical_framework": [
                "March & Olsen (1984) - Logic of appropriateness: institutional actors have defined roles and responsibilities",
                "DiMaggio & Powell (1983) - Institutional isomorphism: gender policy entities follow normative structures (Secretarías, Comisarías)",
                "Lample et al. (2016) - Neural NER with BiLSTM-CRF for entity boundary detection",
                "Nadeau & Sekine (2007) - Fine-grained entity typing for organizational classification",
                "Colombian Law 1257/2008 - Legal framework mandating gender policy institutional structures",
                "Colombian Decree 111/1996 - Fiscal responsibility requiring entity specification in public plans"
              ],
              "justification": "Identifying responsible entities requires combining computational linguistics (NER) with institutional theory to distinguish mere mentions from actual responsible actors. This dual approach ensures both computational precision and domain-grounded validation."
            },
            "technical_approach": {
              "method_type": "hybrid_ner_institutional_analysis",
              "algorithm": "Parallel NER + Syntax Extraction → Entity Type Classification → Specificity Scoring → Consolidation",
              "input_types": [
                "preprocessed_document: Dict[str, Any]",
                "patterns: List[PatternConfig]"
              ],
              "output_types": [
                "entities: List[Dict[str, Any]] with fields {name, type, specificity_score, confidence, sentence_id, context}"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Launch parallel extraction via _extract_entities_ner (spaCy BiLSTM-CRF on ORG/PER labels) and _extract_entities_syntax (dependency parsing for 'Secretaría de...', 'Comisaría...', 'equipo...' patterns)",
                  "algorithms": [
                    "spaCy es_core_news_lg (F1=0.89 on ORG entities)",
                    "Stanford Dependency Parser with nsubj/dobj relations"
                  ],
                  "complexity": "O(n×m) where n=sentences, m=avg_tokens/sentence"
                },
                {
                  "step": 2,
                  "description": "Classify entity type via _classify_entity_type: map extracted mentions to taxonomy {Secretaría Especializada, Comisaría, Equipo Técnico, Genérico} using lexical matching + WordNet hyponymy",
                  "algorithms": [
                    "Regex matching for institutional prefixes",
                    "spaCy similarity for ambiguous cases"
                  ],
                  "complexity": "O(e) where e=extracted_entities"
                },
                {
                  "step": 3,
                  "description": "Score entity specificity via _score_entity_specificity: assign score based on name granularity (0.0=generic like 'entidad competente', 1.0=full name like 'Secretaría de la Mujer y Equidad de Género')",
                  "algorithms": [
                    "Token count heuristic: score = min(1.0, token_count/5)",
                    "Keyword bonuses: +0.2 if contains 'Mujer', 'Género', 'Equidad'"
                  ],
                  "complexity": "O(e)"
                },
                {
                  "step": 4,
                  "description": "Consolidate entities via _consolidate_entities: deduplicate using fuzzy string matching (Levenshtein distance ≤2) + coreference resolution for pronouns/abbreviations",
                  "algorithms": [
                    "RapidFuzz Levenshtein with threshold=0.85",
                    "spaCy neuralcoref for pronoun resolution"
                  ],
                  "complexity": "O(e²) for pairwise comparison"
                },
                {
                  "step": 5,
                  "description": "Return consolidated list sorted by specificity_score DESC, filtered to entities with type != 'Genérico' and specificity ≥ 0.5"
                }
              ],
              "assumptions": [
                "Document preprocessing has sentence segmentation and tokenization",
                "spaCy model es_core_news_lg is loaded",
                "Patterns include at least one organizational entity pattern (e.g., PAT-Q004-000 for 'Secretaría')"
              ],
              "limitations": [
                "NER precision limited by spaCy model performance (F1≈0.89 on Spanish ORG entities)",
                "Syntax parsing fails on malformed sentences (typically <5% of corpus)",
                "Abbreviations without full form in context may be missed (e.g., 'SM' for 'Secretaría de la Mujer' requires prior expansion)"
              ],
              "complexity": "O(n×m + e²) where n=sentences, m=tokens, e=entities extracted (typically e << n×m, so dominated by NER phase)"
            },
            "output_interpretation": {
              "output_structure": {
                "entities": [
                  {
                    "name": "Secretaría de la Mujer y Equidad de Género",
                    "type": "Secretaría Especializada",
                    "specificity_score": 1.0,
                    "confidence": 0.92,
                    "sentence_id": 45,
                    "context": "La Secretaría de la Mujer y Equidad de Género será responsable de...",
                    "extraction_method": "ner",
                    "normalized_form": "secretaria_mujer_equidad_genero"
                  }
                ],
                "metadata": {
                  "total_entities": 7,
                  "by_type": {
                    "Secretaría Especializada": 2,
                    "Comisaría": 3,
                    "Equipo Técnico": 2
                  },
                  "avg_confidence": 0.87,
                  "avg_specificity": 0.78
                }
              },
              "interpretation_guide": {
                "high_specificity_entity": "≥0.75 AND type='Secretaría Especializada': Entity has full institutional name with gender policy focus. Actionable for accountability tracking.",
                "medium_specificity_entity": "0.50-0.74 OR type='Comisaría': Entity name partially specified or generic role (e.g., 'Comisaría de Familia'). May require manual validation for uniqueness.",
                "low_specificity_entity": "<0.50: Generic mention (e.g., 'entidad responsable'). Insufficient for operationalization; flag as data gap."
              },
              "actionable_insights": [
                "If 0 entities with specificity≥0.75: Flag as CRITICAL GAP - plan lacks identifiable responsible institutions for gender policy",
                "If entities found but all type='Genérico': Flag as VAGUE ACCOUNTABILITY - plan mentions responsibility without naming actors",
                "If Secretaría Especializada found: Extract for entity-activity linkage in downstream MechanismPartExtractor analysis",
                "If Comisaría found: Cross-validate with 'ruta de atención' patterns (PAT-Q004-003) to confirm violence response capacity"
              ]
            }
          },
          {
            "method_name": "_extract_entities_ner",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 2,
            "role": "_extract_entities_ner_extraction",
            "epistemological_foundation": {
              "paradigm": "Neural Named Entity Recognition (BiLSTM-CRF)",
              "ontological_basis": "Entities exist as contiguous token sequences with organization (ORG) or person (PER) semantic labels. Entity boundaries and types are latent variables inferred from contextual word embeddings and transition probabilities.",
              "epistemological_stance": "Supervised learning epistemology: entity knowledge is induced from annotated corpora (CoNLL-2002/2003 Spanish NER, AnCora-ES) via maximum likelihood estimation of BiLSTM-CRF parameters. Confidence reflects model posterior P(tag_sequence|sentence).",
              "theoretical_framework": [
                "Lample et al. (2016) - Neural Architectures for Named Entity Recognition: BiLSTM-CRF achieves state-of-the-art F1=0.90 on CoNLL-2003",
                "Akbik et al. (2018) - Contextual String Embeddings for Sequence Labeling: Flair embeddings capture character-level context",
                "Ratinov & Roth (2009) - Design Challenges and Misconceptions in NER: IOB2 tagging scheme for entity boundary detection",
                "Tjong Kim Sang & De Meulder (2003) - Introduction to CoNLL-2003 Shared Task: evaluation protocol for NER precision/recall",
                "Carreras et al. (2003) - AnCora-ES corpus: 500k Spanish tokens annotated with NER labels",
                "spaCy v3.5+ es_core_news_lg: transformer-based model with F1=0.89 on ORG entities in Spanish administrative text"
              ],
              "justification": "NER via deep learning is the gold standard for entity extraction in unstructured text. BiLSTM-CRF models entity boundary detection as sequence labeling with contextual embeddings, superior to rule-based approaches for recall and generalization."
            },
            "technical_approach": {
              "method_type": "deep_learning_sequence_labeling",
              "algorithm": "spaCy BiLSTM-CRF with IOB2 tagging scheme",
              "input_types": [
                "text: str (document text)",
                "patterns: List[PatternConfig] (unused by NER but required by contract)"
              ],
              "output_types": [
                "entities: List[Dict] with {text, label, start_char, end_char, confidence}"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Run PDETMunicipalPlanAnalyzer._extract_entities_ner using contract-scoped inputs and produce intermediate artifacts"
                },
                {
                  "step": 2,
                  "description": "Normalize artifacts into evidence candidates with confidence estimates"
                },
                {
                  "step": 3,
                  "description": "Emit structured outputs for downstream evidence fusion and validation"
                }
              ],
              "assumptions": [
                "spaCy model es_core_news_lg is installed and loaded (requires 310MB download)",
                "Text is valid UTF-8 Spanish; model trained on news/admin domains",
                "Entity mentions are explicitly named (e.g., 'Secretaría de la Mujer'); pronouns/abbreviations without antecedents will be missed"
              ],
              "limitations": [
                "False negatives on rare entity names not in training corpus (e.g., newly created municipal agencies)",
                "False positives on ambiguous organization names (e.g., 'Justicia' as abstract concept vs. 'Secretaría de Justicia')",
                "No cross-sentence entity linking; separate mentions of same entity treated independently",
                "Confidence scores poorly calibrated (typical for neural NER); require Platt scaling for probabilistic interpretation"
              ],
              "complexity": "O(n×d²) where n=tokens, d=embedding_dim (768 for transformer). Transformer self-attention is quadratic in sequence length; spaCy chunks long documents to max_length=512 tokens."
            },
            "output_interpretation": {
              "output_structure": {
                "entities": [
                  {
                    "text": "Secretaría de la Mujer",
                    "label": "ORG",
                    "start_char": 123,
                    "end_char": 145,
                    "confidence": 0.91,
                    "sentence_id": 7
                  },
                  {
                    "text": "Comisaría de Familia",
                    "label": "ORG",
                    "start_char": 456,
                    "end_char": 476,
                    "confidence": 0.87,
                    "sentence_id": 12
                  }
                ]
              },
              "interpretation_guide": {
                "high_confidence_entity": "≥0.85 (ORG): Model is highly certain of entity boundary and organization label. Typically occurs for well-known institutions like 'DANE', 'Secretaría de Hacienda'.",
                "medium_confidence_entity": "0.70-0.84 (ORG): Likely correct but may have boundary errors (e.g., 'Secretaría' vs. 'Secretaría de la Mujer'). Cross-validate with syntax-based extraction.",
                "low_confidence_entity": "<0.70: High uncertainty. May be false positive (e.g., 'Justicia' as abstract noun). Discard unless confirmed by syntax extraction.",
                "person_entity": "PER label: Individual officials (e.g., 'la Secretaria Ana Gómez'). Useful for identifying human resources but lower priority than organizational entities for D1-Q4."
              },
              "actionable_insights": [
                "If NER extracts 0 ORG entities: Likely document has no explicit institutional mentions → flag as CRITICAL GAP",
                "If NER confidence < 0.70 for all entities: Document may use atypical language → fallback to syntax-based extraction",
                "Cross-reference NER entities with patterns PAT-Q004-000 ('Secretaría') and PAT-Q004-001 ('Comisaría') for validation",
                "High-confidence ORG entities (≥0.85) can skip syntax validation → direct input to _classify_entity_type"
              ]
            }
          },
          {
            "method_name": "_extract_entities_syntax",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 3,
            "role": "_extract_entities_syntax_extraction",
            "epistemological_foundation": {
              "paradigm": "Dependency Grammar + Pattern Matching",
              "ontological_basis": "Entities are syntactic constituents identifiable by dependency relations (nsubj, dobj, nmod) and phrase structure patterns (NP → Det + Noun + PP). Entity mentions have compositional semantics: 'Secretaría [de la Mujer]' where bracketed PP specifies entity type.",
              "epistemological_stance": "Rule-based linguistic epistemology: entity knowledge is derived from syntactic structure via dependency parsing (Nivre 2005 transition-based parsing) and pattern matching over parse trees. Confidence is deterministic based on pattern match completeness and syntactic coherence.",
              "theoretical_framework": [
                "Nivre (2005) - Pseudo-Projective Dependency Parsing: arc-standard transition system for non-projective Spanish syntax",
                "De Marneffe & Manning (2008) - Stanford Dependencies: Universal Dependencies v2 for cross-lingual parsing",
                "Mel'čuk (1988) - Dependency Syntax: Theory and Practice: head-dependent relations encode semantic predicate-argument structure",
                "Hearst (1992) - Automatic Acquisition of Hyponyms: lexico-syntactic patterns ('X such as Y', 'X including Y') for entity extraction",
                "Socher et al. (2013) - Recursive Deep Models for Semantic Compositionality: parse tree structure provides compositional semantics",
                "spaCy Dependency Parser: transition-based with arc-eager algorithm, 92% labeled attachment score (LAS) on Spanish UD corpus"
              ],
              "justification": "Syntax-based extraction complements NER by capturing entities NER misses due to vocabulary gaps. Dependency parsing provides head-modifier structure (e.g., 'Secretaría' as head, 'de la Mujer' as nmod) essential for entity boundary detection and type classification."
            },
            "technical_approach": {
              "method_type": "rule_based_dependency_parsing",
              "algorithm": "Dependency Parsing + Pattern Matching over nsubj/dobj/nmod relations",
              "input_types": [
                "text: str",
                "patterns: List[PatternConfig] with regex field"
              ],
              "output_types": [
                "entities: List[Dict] with {text, head_token, dependency_path, pattern_id, confidence}"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Parse text with spaCy: doc = nlp(text). Extracts dependency tree with head/child relations (nsubj, dobj, nmod, etc.)",
                  "parser_details": "Transition-based arc-eager parser with 92% LAS on UD_Spanish-AnCora"
                },
                {
                  "step": 2,
                  "description": "For each pattern in patterns: compile regex pattern.regex into re.Pattern. Search for matches in doc.text.",
                  "example_patterns": [
                    "'Secretaría\\s+de\\s+(la\\s+)?\\w+'",
                    "'Comisaría\\s+de\\s+Familia'",
                    "'equipo\\s+psicosocial'"
                  ]
                },
                {
                  "step": 3,
                  "description": "For each regex match: locate matching tokens in doc via character offsets. Find syntactic head via dependency tree traversal: head = token while token.dep_ in {'nmod', 'amod', 'det'}: token = token.head.",
                  "rationale": "Extract full NP span including modifiers: 'Secretaría de la Mujer y Equidad de Género' has head='Secretaría', children={'de', 'la', 'Mujer', 'y', 'Equidad', 'de', 'Género'} via nmod/conj relations"
                },
                {
                  "step": 4,
                  "description": "Compute entity span: start from head, traverse children recursively to collect all nmod/amod/det/conj dependents. Entity text = span from leftmost to rightmost dependent token.",
                  "complexity_substep": "O(t) where t=tokens in subtree; typically t<15 for entity NPs"
                },
                {
                  "step": 5,
                  "description": "Assign confidence based on pattern specificity: confidence = 0.95 if pattern_id in {'PAT-Q004-000', 'PAT-Q004-001'} (Secretaría/Comisaría - high specificity), else 0.80 for generic patterns (capacidad instalada, equipo)",
                  "justification": "Deterministic confidence: pattern-based extraction has 100% precision on matched patterns but lower recall than NER"
                },
                {
                  "step": 6,
                  "description": "Deduplicate with NER results: if entity span overlaps with NER entity ≥80% (Jaccard similarity), keep NER version (higher confidence from learned model)"
                }
              ],
              "assumptions": [
                "Patterns cover canonical entity mention structures (noun + prepositional phrase)",
                "Dependency parser has ≥90% LAS; errors in attachment may cause incorrect entity boundaries",
                "Entity mentions are contiguous spans; coordination ('Secretaría X y Comisaría Y') handled via conj dependency"
              ],
              "limitations": [
                "Recall limited to pattern coverage; novel entity types not matching patterns will be missed",
                "Coordination ambiguity: 'Secretaría de X y Y' may parse as two entities or one entity with coordinated modifier",
                "Prepositional phrase attachment ambiguity: 'Secretaría de la Mujer en el municipio' - is 'en el municipio' part of entity name?",
                "No semantic validation; extracts syntactically valid but semantically nonsensical entities (e.g., 'Secretaría de Problemas')"
              ],
              "complexity": "O(n×p×t) where n=tokens, p=patterns, t=avg_subtree_size. Typically t<15, p<10, so effective O(n)."
            },
            "output_interpretation": {
              "output_structure": {
                "entities": [
                  {
                    "text": "Secretaría de la Mujer y Equidad de Género",
                    "head_token": "Secretaría",
                    "dependency_path": "nsubj ← será",
                    "pattern_id": "PAT-Q004-000",
                    "confidence": 0.95,
                    "sentence_id": 7
                  }
                ]
              },
              "interpretation_guide": {
                "high_confidence_syntax_entity": "confidence=0.95 (pattern PAT-Q004-000/001): Pattern-matched Secretaría or Comisaría. Deterministic extraction with high precision. Use for validation of NER results.",
                "medium_confidence_syntax_entity": "confidence=0.80 (pattern PAT-Q004-002/003): Generic patterns like 'equipo psicosocial' or 'capacidad instalada'. May be descriptive phrases rather than entity names. Validate with entity type classification.",
                "syntax_ner_agreement": "Entity extracted by both syntax and NER with ≥80% overlap: HIGH CONFIDENCE (geometric mean of individual confidences). Strong evidence of valid entity mention.",
                "syntax_only_entity": "Extracted by syntax but not NER: Possible NER false negative (out-of-vocabulary entity name) or syntax false positive (descriptive phrase misclassified as entity). Prioritize for manual review."
              },
              "actionable_insights": [
                "Syntax extraction recall = syntax_entities / (syntax_entities + ner_only_entities). If recall < 0.5: patterns may be too restrictive → expand pattern set",
                "If syntax extracts 0 entities AND NER extracts 0 entities: CRITICAL GAP confirmed by two independent methods → high confidence absence of entity mentions",
                "Entities with dependency_path containing 'nsubj' or 'dobj' are likely main clause actors (high importance for responsibility attribution)",
                "Entities in subordinate clauses (dependency_path with 'acl', 'advcl') are contextual mentions (lower priority unless no main clause entities found)"
              ]
            }
          },
          {
            "method_name": "_classify_entity_type",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 4,
            "role": "_classify_entity_type_classification",
            "epistemological_foundation": {
              "paradigm": "Fine-Grained Entity Typing + Institutional Taxonomy",
              "ontological_basis": "Gender policy entities belong to a hierarchical taxonomy with institutional types: {Secretaría Especializada, Secretaría General, Comisaría, Equipo Técnico, Genérico}. Type membership is determined by lexical features (head noun, modifiers) and institutional domain knowledge (Colombian administrative structure per Law 489/1998).",
              "epistemological_stance": "Hybrid rule-based + distributional semantics: entity types are inferred through (1) lexical matching against canonical type labels (deterministic rules), (2) WordNet hyponymy for ambiguous cases (IS-A hierarchy), (3) spaCy word embeddings for semantic similarity when exact match fails. Classification confidence combines rule match strength with semantic distance.",
              "theoretical_framework": [
                "Ling & Weld (2012) - Fine-Grained Entity Recognition: entity types form hierarchical taxonomy (e.g., Organization → Government Agency → Gender Policy Office)",
                "Yosef et al. (2012) - HYENA: Hierarchical Type Classification: exploit taxonomy structure for multi-label classification",
                "Fellbaum (1998) - WordNet: An Electronic Lexical Database: hyponymy relations (IS-A) provide taxonomic backbone",
                "Navigli & Ponzetto (2012) - BabelNet: multilingual semantic network integrating WordNet + Wikipedia for Spanish entity typing",
                "Colombian Law 489/1998 - Administrative Structure: defines institutional hierarchy (Secretarías, Direcciones, Comisarías)",
                "Colombian Law 1257/2008 - Violence Against Women: mandates specialized gender policy offices (Secretaría de la Mujer)"
              ],
              "justification": "Entity type classification is critical for determining institutional accountability. Fine-grained types (Secretaría Especializada vs. Genérico) distinguish entities with specific gender policy mandate from generic administrative mentions."
            },
            "technical_approach": {
              "method_type": "hybrid_rule_based_semantic_classification",
              "algorithm": "Lexical Rule Matching → WordNet Hyponymy → Embedding Similarity",
              "input_types": [
                "entity: Dict with {text, head_token, ...}"
              ],
              "output_types": [
                "entity_type: str from taxonomy {Secretaría Especializada, Secretaría General, Comisaría, Equipo Técnico, Genérico}",
                "type_confidence: float [0,1]"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Extract head noun: head = entity['head_token'] or entity['text'].split()[0]. Normalize: head_normalized = head.lower().strip('.,;:')",
                  "example": "'Secretaría de la Mujer' → head='secretaría'"
                },
                {
                  "step": 2,
                  "description": "Rule-based classification via lexical matching: IF head_normalized in {'secretaría', 'secretaria'}: IF any(keyword in entity['text'].lower() for keyword in ['mujer', 'género', 'equidad de género']): type = 'Secretaría Especializada', confidence = 1.0 ELSE: type = 'Secretaría General', confidence = 0.90 ELIF head_normalized in {'comisaría', 'comisaria'}: type = 'Comisaría', confidence = 0.95 ELIF head_normalized in {'equipo', 'grupo', 'unidad'}: type = 'Equipo Técnico', confidence = 0.85 ELSE: type = 'Genérico', confidence = 0.50 (fallback to semantic matching in step 3)",
                  "justification": "Deterministic rules for canonical institutional types achieve 100% precision on well-formed entity names"
                },
                {
                  "step": 3,
                  "description": "Semantic fallback for type='Genérico': Compute spaCy embedding similarity between head_normalized and prototype types. prototypes = {'secretaría', 'comisaría', 'equipo', 'oficina', 'dirección'} similarities = [nlp(head_normalized).similarity(nlp(proto)) for proto in prototypes] best_match = argmax(similarities) IF max(similarities) ≥ 0.70: type = map_prototype_to_type(best_match), confidence = max(similarities) ELSE: type = 'Genérico', confidence = max(similarities)",
                  "rationale": "Word embeddings capture semantic relatedness for out-of-vocabulary entity types (e.g., 'dependencia' → 0.72 similarity to 'secretaría')"
                },
                {
                  "step": 4,
                  "description": "Validate type with entity context: IF type='Secretaría Especializada' AND 'responsible' or 'encargada' in entity['context']: confidence *= 1.1 (boost for explicit responsibility language). Cap confidence at 1.0."
                }
              ],
              "assumptions": [
                "Entity head noun is accurate (depends on NER/syntax quality)",
                "Colombian institutional taxonomy generalizes to all municipalities",
                "spaCy embeddings trained on administrative text (es_core_news_lg includes government corpus)"
              ],
              "limitations": [
                "Novel entity types not in taxonomy (e.g., 'Observatorio de Género') classified as Genérico unless semantic similarity ≥0.70",
                "Ambiguous modifiers: 'Secretaría de Planeación' has 'secretaría' head but not gender-specialized → classified as Secretaría General",
                "Embedding similarity unreliable for rare words (<100 corpus occurrences); may yield arbitrary similarities"
              ],
              "complexity": "O(e×p) where e=entities, p=prototypes (typically p=5). Embedding similarity is O(d) for d=embedding_dim (300 in es_core_news_lg)."
            },
            "output_interpretation": {
              "output_structure": {
                "entity_type": "Secretaría Especializada",
                "type_confidence": 1.0,
                "type_rationale": "Lexical match: head='secretaría' + keyword='mujer' → Secretaría Especializada"
              },
              "interpretation_guide": {
                "Secretaría Especializada (conf=1.0)": "Entity explicitly mentions gender focus ('Mujer', 'Género', 'Equidad'). Highest accountability priority for D1-Q4. Expected institutional capacity: dedicated staff, budget line, strategic plan.",
                "Secretaría General (conf≥0.90)": "Generic secretariat without gender specialization. May have gender responsibilities as secondary mandate. Moderate accountability priority.",
                "Comisaría (conf≥0.95)": "Family welfare office (Comisaría de Familia) typically handles violence response. High priority for 'ruta de atención' validation (PAT-Q004-003).",
                "Equipo Técnico (conf≥0.85)": "Technical team or working group. Operational capacity but lower institutional permanence than Secretaría/Comisaría. Verify if formal structure or ad-hoc.",
                "Genérico (conf<0.70)": "Unclassified entity type. May be false positive from NER/syntax extraction or novel entity type. Manual review recommended."
              },
              "actionable_insights": [
                "If 0 entities typed as 'Secretaría Especializada': Flag as STRUCTURAL GAP - no dedicated gender policy office identified",
                "If entities typed as 'Secretaría General' mention gender responsibilities: Flag as INSTITUTIONAL WEAKNESS - gender policy housed in non-specialized office (lower priority, shared resources)",
                "Comisaría entities should be cross-referenced with 'violencia' or 'atención' keywords to confirm violence response capacity",
                "High proportion of Genérico (>50%): Low entity typing accuracy → improve NER/syntax extraction quality or expand type taxonomy"
              ]
            }
          },
          {
            "method_name": "_score_entity_specificity",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 5,
            "role": "_score_entity_specificity",
            "epistemological_foundation": {
              "paradigm": "Lexical Semantics + Information Content Theory",
              "ontological_basis": "Entity specificity is a scalar property reflecting granularity of institutional naming. Specific entities ('Secretaría de la Mujer y Equidad de Género del Municipio de Bogotá') provide more information (higher entropy) than generic entities ('la entidad competente'). Specificity correlates with operationalizability: specific names enable accountability tracking.",
              "epistemological_stance": "Information-theoretic epistemology: specificity is measured as inverse semantic generality. Generic terms ('entidad', 'organismo') have high corpus frequency and low information content (Shannon 1948). Specific terms have low frequency and high information. Knowledge of entity identity increases monotonically with specificity score.",
              "theoretical_framework": [
                "Cruse (1986) - Lexical Semantics: specificity as hyponymy depth in semantic taxonomy ('Secretaría de la Mujer' is hyponym of 'Secretaría' is hyponym of 'entidad')",
                "Resnik (1995) - Using Information Content to Evaluate Semantic Similarity: specificity = -log P(term|corpus) where P is corpus frequency",
                "Rosch (1978) - Principles of Categorization: basic-level categories balance informativeness and cognitive economy; specificity measures deviation from basic level",
                "Zipf (1949) - Human Behavior and Principle of Least Effort: inverse correlation between term frequency and information content",
                "Murphy (2002) - The Big Book of Concepts: conceptual specificity as number of distinguishing features (Secretaría de la Mujer: +government +municipal +gender_focus)"
              ],
              "justification": "Specificity scoring operationalizes the vagueness-precision spectrum in entity mentions. High specificity enables verification (can check if 'Secretaría de la Mujer' exists in municipal org chart), low specificity is unverifiable ('la entidad que corresponda')."
            },
            "technical_approach": {
              "method_type": "heuristic_information_content_scoring",
              "algorithm": "Token count + Keyword bonuses + Generic term penalties",
              "input_types": [
                "entity: Dict with {text, type, ...}"
              ],
              "output_types": [
                "specificity_score: float [0,1] where 0=maximally generic, 1=maximally specific"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Tokenize entity name: tokens = entity['text'].split(). Filter stopwords: tokens_filtered = [t for t in tokens if t.lower() not in {'de', 'la', 'el', 'y', 'del'}]",
                  "rationale": "Content words carry specificity; function words are structural"
                },
                {
                  "step": 2,
                  "description": "Base score from token count: base_score = min(1.0, len(tokens_filtered) / 5.0). Rationale: 5+ content tokens indicate high specificity (e.g., 'Secretaría de la Mujer y Equidad de Género' = 5 content tokens).",
                  "examples": [
                    "'entidad competente' = 2 tokens -> 0.40",
                    "'Secretaría de la Mujer' = 2 content tokens ('Secretaría', 'Mujer') -> 0.40",
                    "'Secretaría de la Mujer y Equidad de Género' = 4 content tokens -> 0.80"
                  ]
                },
                {
                  "step": 3,
                  "description": "Keyword bonuses: IF any(keyword in entity['text'].lower() for keyword in ['mujer', 'género', 'equidad', 'violencia']): base_score += 0.15 (gender-specific terminology increases specificity). IF entity name includes municipality: base_score += 0.10 ('del Municipio de X').",
                  "justification": "Domain-specific keywords and geographic qualifiers enhance entity identifiability"
                },
                {
                  "step": 4,
                  "description": "Generic term penalties: IF any(generic in entity['text'].lower() for generic in ['entidad', 'organismo', 'competente', 'responsable', 'respectiva', 'correspondiente']): base_score *= 0.30 (severe penalty for vague language).",
                  "rationale": "Generic terms like 'entidad competente' are placeholders with near-zero operationalizability"
                },
                {
                  "step": 5,
                  "description": "Type-based adjustment: IF entity['type'] == 'Secretaría Especializada': base_score = max(base_score, 0.75) (specialized secretariats have inherent specificity even with short names). IF entity['type'] == 'Genérico': base_score = min(base_score, 0.40)."
                },
                {
                  "step": 6,
                  "description": "Normalize: specificity_score = min(1.0, max(0.0, base_score)). Return score."
                }
              ],
              "assumptions": [
                "Token count correlates with information content (longer names are more specific)",
                "Generic terms {'entidad', 'organismo'} are universally vague across Colombian administrative contexts",
                "Gender keywords {'mujer', 'género'} indicate domain-specific focus, enhancing specificity"
              ],
              "limitations": [
                "Token count heuristic is crude; 'Secretaría A B C D E' (5 tokens of nonsense) scores high but is not operationalizable",
                "Misses acronyms: 'SM' (Secretaría de la Mujer) has 1 token, low score, but high specificity if acronym is resolved",
                "Cultural variation: 'Comisaría de Familia' is maximally specific in Colombian context (Law 294/1996 definition) but token count = 2 → moderate score",
                "No corpus frequency grounding; ideally score = -log P(entity_name|corpus) but requires large annotated corpus"
              ],
              "complexity": "O(t) where t=tokens in entity name (typically t<10)."
            },
            "output_interpretation": {
              "output_structure": {
                "specificity_score": 0.85,
                "score_components": {
                  "base_token_score": 0.6,
                  "keyword_bonus": 0.15,
                  "geographic_bonus": 0.1,
                  "generic_penalty": 0.0,
                  "type_adjustment": 0.0
                }
              },
              "interpretation_guide": {
                "high_specificity (≥0.75)": "Entity name is operationalizable: includes institutional type + domain focus + potential geographic qualifier. Examples: 'Secretaría de la Mujer y Equidad de Género', 'Comisaría de Familia Central'. Can be used for direct accountability attribution and verification against municipal org chart.",
                "medium_specificity (0.50-0.74)": "Entity name is partially specific: includes institutional type but lacks domain focus or geographic qualifier. Examples: 'Secretaría de Planeación', 'Comisaría de Familia'. Requires additional context to disambiguate (multiple Comisarías may exist).",
                "low_specificity (<0.50)": "Entity name is generic or vague. Examples: 'la entidad competente', 'el organismo responsable', 'la dependencia correspondiente'. NOT operationalizable for accountability tracking. Flag as data quality issue."
              },
              "actionable_insights": [
                "Filter entities to specificity ≥0.50 for downstream analysis; discard low-specificity mentions as noise",
                "If avg(specificity_scores) < 0.60 across all entities: Flag document as VAGUE on institutional accountability",
                "High-specificity entities (≥0.75) are candidates for automatic entity-activity linkage (MechanismPartExtractor)",
                "Low-specificity entities with type='Secretaría Especializada' are CONTRADICTIONS (specialized office should have specific name) → flag for manual review"
              ]
            }
          },
          {
            "method_name": "_consolidate_entities",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 6,
            "role": "_consolidate_entities",
            "epistemological_foundation": {
              "paradigm": "Entity Resolution + Coreference Resolution",
              "ontological_basis": "Multiple textual mentions may refer to the same real-world entity due to variation (full name vs. abbreviation vs. pronoun). Entity identity is an equivalence class over mentions: 'Secretaría de la Mujer' ≡ 'la Secretaría' ≡ 'SM' ≡ 'dicha entidad' when coreference chains link them. Consolidation recovers this equivalence.",
              "epistemological_stance": "Unified entity assumption: parsimony principle favors minimal entity set explaining all mentions (Occam's razor). Consolidation uses fuzzy string matching (edit distance) + coreference resolution (pronoun → antecedent) + semantic similarity (embeddings) to cluster mentions. Confidence in entity identity = similarity score (Levenshtein, embedding cosine).",
              "theoretical_framework": [
                "Shen et al. (2015) - Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions: entity resolution as clustering problem",
                "Ratinov & Roth (2009) - Learning to Link Entities with Knowledge Base: disambiguation via context similarity",
                "Banko & Etzioni (2008) - The Tradeoffs Between Open and Traditional Relation Extraction: coreference for entity normalization",
                "Levenshtein (1966) - Binary codes capable of correcting deletions, insertions: edit distance for string similarity",
                "Clark & Manning (2016) - Deep Reinforcement Learning for Mention-Ranking Coreference Models: neural coreference for pronouns",
                "spaCy neuralcoref (Hugging Face 2019): rule-based + neural coreference for Spanish pronouns ('ella' → 'Secretaría')"
              ],
              "justification": "Entity consolidation is essential to avoid double-counting: 'Secretaría de la Mujer' mentioned 10 times should yield 1 unique entity, not 10. Consolidation also resolves abbreviations and pronouns, recovering full entity identity from partial mentions."
            },
            "technical_approach": {
              "method_type": "clustering_fuzzy_matching_coreference",
              "algorithm": "Hierarchical Clustering via Levenshtein Distance + Coreference Chain Merging",
              "input_types": [
                "entities: List[Dict] from NER + syntax extraction"
              ],
              "output_types": [
                "consolidated_entities: List[Dict] with canonical name, mention_count, confidence"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Compute pairwise string similarity: For each entity pair (e1, e2): similarity(e1, e2) = 1 - (Levenshtein(e1.text, e2.text) / max(len(e1.text), len(e2.text))). Use RapidFuzz library for O(n×m) Levenshtein.",
                  "threshold": "similarity ≥ 0.85 indicates likely same entity (e.g., 'Secretaría de la Mujer' vs. 'Secretaría Mujer')"
                },
                {
                  "step": 2,
                  "description": "Build similarity graph: nodes=entities, edges where similarity ≥ 0.85. Connected components = entity clusters (same entity ID).",
                  "algorithm": "Union-Find disjoint set with O(n×α(n)) where α is inverse Ackermann (effectively O(n))"
                },
                {
                  "step": 3,
                  "description": "Coreference resolution: Run spaCy neuralcoref on document: coref_chains = doc._.coref_clusters. For each chain: IF chain contains entity mention AND pronoun/abbreviation: Add pronoun/abbreviation to entity's cluster.",
                  "example": "'La Secretaría de la Mujer coordinará... Ella tendrá...' → coref_chain(['Secretaría de la Mujer', 'Ella']) → merge 'Ella' into Secretaría cluster"
                },
                {
                  "step": 4,
                  "description": "Select canonical name per cluster: canonical = entity with max(specificity_score) in cluster. Rationale: most specific name is most informative ('Secretaría de la Mujer y Equidad de Género' > 'Secretaría' > 'ella')."
                },
                {
                  "step": 5,
                  "description": "Aggregate confidence: cluster_confidence = geometric_mean([e.confidence for e in cluster]). Geometric mean penalizes low-confidence mentions more than arithmetic mean.",
                  "formula": "confidence = (∏ conf_i)^(1/n) for n mentions"
                },
                {
                  "step": 6,
                  "description": "Return consolidated entities: List of {canonical_name, type, specificity_score, confidence, mention_count, sentence_ids=[...]}. Sort by specificity_score DESC."
                }
              ],
              "assumptions": [
                "Entities with Levenshtein similarity ≥0.85 refer to same entity (assumes typos/abbreviations, not distinct entities with similar names)",
                "Coreference chains are accurate (spaCy neuralcoref has ~70% F1 on Spanish; errors propagate as false merges)",
                "Most specific name is correct canonical form (fails if most specific mention is a typo)"
              ],
              "limitations": [
                "False merges: 'Secretaría de Hacienda' vs. 'Secretaría de Educación' have 0.70 similarity → not merged, but 'Secretaría de la Mujer' vs. 'Secretaría Mujer' have 0.87 similarity → merged (correct)",
                "False non-merges: acronyms without expansion ('SM' for 'Secretaría de la Mujer') have low string similarity → not merged unless coreference resolves",
                "Coreference errors: 'ella' may refer to 'municipalidad' not 'Secretaría' → incorrect merge",
                "No cross-document entity resolution; each document analyzed independently"
              ],
              "complexity": "O(e² × max_len) for e entities with Levenshtein, plus O(n) for coreference. Typically e<50, so manageable."
            },
            "output_interpretation": {
              "output_structure": {
                "consolidated_entities": [
                  {
                    "canonical_name": "Secretaría de la Mujer y Equidad de Género",
                    "type": "Secretaría Especializada",
                    "specificity_score": 0.95,
                    "confidence": 0.89,
                    "mention_count": 7,
                    "sentence_ids": [
                      5,
                      12,
                      18,
                      23,
                      45,
                      67,
                      89
                    ],
                    "alternate_mentions": [
                      "Secretaría Mujer",
                      "la Secretaría",
                      "ella"
                    ]
                  }
                ]
              },
              "interpretation_guide": {
                "high_mention_count (≥5)": "Entity is central to document (mentioned frequently). High confidence in entity importance for gender policy management.",
                "medium_mention_count (2-4)": "Entity mentioned multiple times but not central. May be supporting actor or contextual mention.",
                "single_mention (=1)": "Entity mentioned once. Lower confidence in centrality; may be incidental reference or data quality issue (extraction error).",
                "confidence_drop_after_consolidation": "If consolidated confidence < 0.70 but individual mention confidences were ≥0.85: consolidation merged dissimilar entities (false merge) → manual review."
              },
              "actionable_insights": [
                "Entities with mention_count ≥3 AND type='Secretaría Especializada' are HIGH PRIORITY for accountability tracking",
                "If consolidated entity set reduces from N NER/syntax extractions to <N/2 consolidated entities: Good consolidation (removed duplicates). If ≥N×0.9: Poor consolidation (failed to merge variants) → adjust similarity threshold.",
                "Canonical names with specificity ≥0.75 can be exported to entity knowledge base for cross-document linking",
                "Alternate mentions list enables search query expansion: search for any of {canonical, alternates} to retrieve all entity mentions"
              ]
            }
          },
          {
            "method_name": "extract_entity_activity",
            "class_name": "MechanismPartExtractor",
            "priority": 7,
            "role": "extract_entity_activity_extraction",
            "epistemological_foundation": {
              "paradigm": "Frame Semantics + Semantic Role Labeling (SRL)",
              "ontological_basis": "Entity-activity pairs constitute institutional mechanisms: Entity (agent) performs Activity (predicate) to achieve policy outcomes. Activities are semantic frames (FrameNet: Coordinating, Implementing, Evaluating) with entities filling Agent roles. Mechanism parts exist as <Entity, Activity> tuples extracted from predicate-argument structures.",
              "epistemological_stance": "Compositional semantics: sentence meaning decomposes into predicates (verbs/nominalizations) and arguments (subject/object/modifiers). Entity-activity linkage is epistemologically grounded in SRL: identify activity frame, assign entity to Agent role via dependency path (nsubj, agent). Confidence derived from syntactic distance (shorter path = higher confidence).",
              "theoretical_framework": [
                "Baker et al. (1998) - FrameNet: A Corpus-Based Approach to Semantic Analysis: semantic frames capture event structure (Agent, Action, Patient)",
                "Palmer et al. (2005) - Proposition Bank: PropBank annotation scheme for predicate-argument structure (ARG0=Agent, ARG1=Patient)",
                "Gildea & Jurafsky (2002) - Automatic Labeling of Semantic Roles: SRL via syntactic features and lexical semantics",
                "Punyakanok et al. (2008) - The Importance of Syntactic Parsing for SRL: dependency paths encode semantic relations",
                "Fernández et al. (2010) - FrameNet en español: Spanish FrameNet with frames for institutional actions (Administrar, Coordinar, Supervisar)",
                "Carreras & Màrquez (2005) - Introduction to CoNLL-2005 Shared Task: SRL evaluation on F1 metric (state-of-art ~0.85)"
              ],
              "justification": "Entity-activity extraction operationalizes 'capacidades institucionales' (D1-Q4). Capacity = Entity + Activity: knowing WHO (Secretaría) does WHAT (coordinar política de género) enables accountability and mechanism tracing."
            },
            "technical_approach": {
              "method_type": "semantic_role_labeling_dependency_paths",
              "algorithm": "Verb Extraction → Agent Identification via nsubj → Activity Normalization → Entity-Activity Pairing",
              "input_types": [
                "consolidated_entities: List[Dict]",
                "preprocessed_document: Dict with dependency parses"
              ],
              "output_types": [
                "entity_activity_pairs: List[Dict] with {entity, activity, confidence, sentence_id, frame}"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Extract activity predicates: For each sentence, identify verbs (POS=VERB) and nominalizations (POS=NOUN with 'ción'/'miento' suffix). Filter to institutional activity lexicon: {coordinar, implementar, gestionar, supervisar, evaluar, administrar, liderar, ejecutar, formular, monitorear}.",
                  "lexicon_source": "Manual curation + Colombian Law 489/1998 (administrative functions)"
                },
                {
                  "step": 2,
                  "description": "Identify agent entities: For each activity predicate p, traverse dependency tree to find nsubj (nominal subject) or agent (passive agent) dependent. Match nsubj token span against consolidated_entities via character offset overlap ≥70%.",
                  "example": "'La Secretaría coordinará la política' → nsubj(coordinará, Secretaría) → pair (Secretaría, coordinar)"
                },
                {
                  "step": 3,
                  "description": "Extract activity objects (Patient role): For activity predicate p, find dobj (direct object) or nmod (nominal modifier with 'de'). Extract object text as activity specification.",
                  "example": "'coordinará la política de género' → activity='coordinar política de género'"
                },
                {
                  "step": 4,
                  "description": "Normalize activity via _normalize_entity: lemmatize verb (coordinará → coordinar), standardize object nouns (políticas → política). Map to canonical activity labels: {Coordinación de Política, Implementación de Programas, Gestión de Recursos, etc.}."
                },
                {
                  "step": 5,
                  "description": "Validate pair via _validate_entity_activity: Check entity type compatible with activity (Secretaría ✓ coordinar, Comisaría ✓ atender, but Comisaría ✗ formular presupuesto). Use domain ontology of entity-activity compatibility.",
                  "ontology": "Secretaría: {coordinar, formular, supervisar}, Comisaría: {atender, proteger, derivar}, Equipo: {apoyar, asesorar}"
                },
                {
                  "step": 6,
                  "description": "Calculate confidence via _calculate_ea_confidence: Base confidence = entity.confidence × syntactic_distance_penalty. syntactic_distance_penalty = 1.0 / (1 + dependency_path_length). Apply validation bonus: +0.10 if entity-activity pair validates.",
                  "rationale": "Shorter dependency paths = higher certainty of semantic relation"
                }
              ],
              "assumptions": [
                "Institutional activities are expressed via verbs or nominalizations in predicate position",
                "Entity-activity relation encoded in nsubj dependency (subject = agent)",
                "Activity lexicon covers ≥80% of institutional functions in Colombian municipal plans"
              ],
              "limitations": [
                "Passive constructions without 'por' agent phrase miss entity-activity link ('la política será coordinada' → no agent)",
                "Coordination ambiguity: 'La Secretaría y la Comisaría coordinarán' → both entities linked to activity, but unclear if joint or separate responsibility",
                "Implicit activities: 'La Secretaría es responsable de...' has no verb → activity inferred from 'responsable' + object, lower confidence",
                "Activity specificity varies: 'coordinar' is vague, 'coordinar política de género con enfoque interseccional' is specific, but both extracted identically"
              ],
              "complexity": "O(s×v×e) where s=sentences, v=verbs/sentence (avg 3-5), e=entities (avg 5-10). Typically O(n) for n=document_length."
            },
            "output_interpretation": {
              "output_structure": {
                "entity_activity_pairs": [
                  {
                    "entity": "Secretaría de la Mujer y Equidad de Género",
                    "activity": "Coordinar política de igualdad de género",
                    "activity_canonical": "Coordinación de Política",
                    "confidence": 0.87,
                    "sentence_id": 45,
                    "frame": "Coordinating",
                    "dependency_path": "nsubj(coordinar, Secretaría) → dobj(coordinar, política)"
                  }
                ]
              },
              "interpretation_guide": {
                "high_confidence_pair (≥0.80)": "Entity clearly identified as agent of activity via direct syntactic relation (nsubj). Pair is operationalizable: can verify if entity performs activity in practice. Priority for mechanism tracing.",
                "medium_confidence_pair (0.60-0.79)": "Entity-activity link inferred from longer dependency path or implicit predicate. Likely correct but may require context for validation. Use for secondary mechanism analysis.",
                "low_confidence_pair (<0.60)": "Weak syntactic evidence for entity-activity relation. May be coincidental co-occurrence rather than semantic relation. Discard unless validated by domain expert.",
                "canonical_activity": "Normalized activity label enables cross-document comparison: 'coordinar', 'coordina', 'coordinación' all map to 'Coordinación de Política'."
              },
              "actionable_insights": [
                "Entities with 0 activity pairs: Flag as PASSIVE MENTION - entity named but no responsibilities specified → low operationalizability",
                "Entities with ≥3 distinct activity pairs: Flag as MULTI-FUNCTIONAL ACTOR - central to policy implementation → high priority for capacity assessment",
                "Activity='Coordinación de Política' is STRATEGIC function (planning level), Activity='Atención de Casos' is OPERATIONAL (service delivery). Balance indicates institutional maturity.",
                "If dominant activity_canonical='Implementación de Programas' but entity type='Comisaría': MISALIGNMENT - Comisarías typically handle cases not programs → validate plan coherence"
              ]
            }
          },
          {
            "method_name": "_normalize_entity",
            "class_name": "MechanismPartExtractor",
            "priority": 8,
            "role": "_normalize_entity",
            "epistemological_foundation": {
              "paradigm": "Canonical Form Normalization",
              "ontological_basis": "Normalized forms enable identity across surface variation: 'coordinará', 'coordinaba', 'coordinación' all reduce to canonical 'coordinar'. Canonical forms are abstractions preserving semantic core while discarding inflectional/orthographic noise.",
              "epistemological_stance": "Morphological analysis: word forms decompose into lemma + inflection. Lemma carries semantic content, inflection is syntactic. Normalization recovers lemma via rule-based stemming (Porter algorithm) or lexicon lookup (spaCy lemmatizer). Confidence = 1.0 for lexicon match, 0.90 for stemming.",
              "theoretical_framework": [
                "Porter (1980) - Stemming Algorithm: suffix-stripping rules for English (adapted to Spanish: -ción → -r, -miento → -r)",
                "Krovetz (1993) - Viewing Morphology as an Inference Process: lemmatization as morphological inference from surface form",
                "spaCy lemmatizer: rule-based + exception dictionary for Spanish irregular verbs (ser/fué → ser)"
              ],
              "justification": "Normalization enables aggregation: count all mentions of 'coordinar' regardless of tense/aspect."
            },
            "technical_approach": {
              "method_type": "lemmatization_canonical_mapping",
              "algorithm": "spaCy Lemmatization + Canonical Activity Mapping",
              "input_types": [
                "activity_text: str (raw activity phrase)"
              ],
              "output_types": [
                "canonical_activity: str (normalized label)"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Lemmatize verb: verb_lemma = nlp(verb)[0].lemma_. spaCy uses rule-based lemmatization with exception dictionary."
                },
                {
                  "step": 2,
                  "description": "Lemmatize object nouns: for each noun in activity_text, apply lemmatization (políticas → política)."
                },
                {
                  "step": 3,
                  "description": "Map to canonical labels via lookup table: {'coordinar política': 'Coordinación de Política', 'implementar programa': 'Implementación de Programas', ...}. Lookup table manually curated from Colombian administrative lexicon (Law 489/1998)."
                }
              ],
              "complexity": "O(t) where t=tokens in activity phrase (typically <10)."
            },
            "output_interpretation": {
              "output_structure": {
                "canonical_activity": "Coordinación de Política"
              },
              "interpretation_guide": {
                "canonical_label": "Enables cross-document aggregation of activity mentions."
              }
            }
          },
          {
            "method_name": "_validate_entity_activity",
            "class_name": "MechanismPartExtractor",
            "priority": 9,
            "role": "_validate_entity_activity_validation",
            "epistemological_foundation": {
              "paradigm": "Ontological Compatibility Checking",
              "ontological_basis": "Entity-activity pairs must satisfy domain constraints: Secretarías perform strategic functions (coordinar, formular), Comisarías perform operational functions (atender, proteger). Incompatible pairs (e.g., Comisaría formular presupuesto) violate institutional ontology.",
              "epistemological_stance": "Closed-world assumption: institutional functions are enumerable (Colombian Law 489/1998, Law 1257/2008). Validity = compatibility(entity_type, activity) via ontology lookup. Invalid pairs indicate either extraction errors or plan incoherence.",
              "theoretical_framework": [
                "Gruber (1993) - A Translation Approach to Portable Ontology Specifications: ontology as formal specification of conceptualization",
                "Guarino (1998) - Formal Ontology and Information Systems: ontological commitment = entity-activity compatibility constraints",
                "Colombian Law 489/1998 - Organizational Structure: defines institutional functions by entity type"
              ],
              "justification": "Validation filters extraction noise and detects plan anomalies."
            },
            "technical_approach": {
              "method_type": "ontology_based_validation",
              "algorithm": "Lookup Entity-Activity Compatibility Matrix",
              "input_types": [
                "entity_type: str",
                "activity_canonical: str"
              ],
              "output_types": [
                "is_valid: bool",
                "validation_score: float [0,1]"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Query compatibility matrix: compatibility[entity_type][activity_canonical]. Matrix encodes domain knowledge: {Secretaría Especializada: {Coordinación: 1.0, Formulación: 0.95, Atención: 0.60}, Comisaría: {Atención: 1.0, Coordinación: 0.50, Formulación: 0.20}}."
                },
                {
                  "step": 2,
                  "description": "Return is_valid = (compatibility ≥ 0.70), validation_score = compatibility."
                }
              ],
              "complexity": "O(1) dictionary lookup."
            },
            "output_interpretation": {
              "output_structure": {
                "is_valid": true,
                "validation_score": 0.95
              },
              "interpretation_guide": {
                "valid_pair (score≥0.70)": "Entity-activity pair aligns with institutional ontology. Use for mechanism tracing.",
                "invalid_pair (score<0.70)": "Pair violates domain constraints. Either extraction error or plan incoherence. Flag for review."
              }
            }
          },
          {
            "method_name": "_calculate_ea_confidence",
            "class_name": "MechanismPartExtractor",
            "priority": 10,
            "role": "_calculate_ea_confidence_calculation",
            "epistemological_foundation": {
              "paradigm": "Probabilistic Confidence Calibration",
              "ontological_basis": "Confidence scores reflect epistemic uncertainty in entity-activity extraction. Uncalibrated confidence (raw model output) may be miscalibrated: high confidence predictions fail more than expected (overconfidence). Calibration transforms scores to match empirical accuracy: if 100 predictions have confidence 0.80, ~80 should be correct.",
              "epistemological_stance": "Bayesian calibration: confidence is subjective probability P(correct|features) that should be well-calibrated (match long-run frequency). Platt scaling (Platt 1999) learns logistic transform: calibrated_conf = σ(a×raw_conf + b) where σ=sigmoid, (a,b) fit to validation data. Calibration improves reliability for decision-making under uncertainty.",
              "theoretical_framework": [
                "Platt (1999) - Probabilistic Outputs for Support Vector Machines: logistic calibration for SVM decision values",
                "Guo et al. (2017) - On Calibration of Modern Neural Networks: deep models are poorly calibrated, require temperature scaling",
                "Niculescu-Mizil & Caruana (2005) - Predicting Good Probabilities with Supervised Learning: calibration methods comparison (Platt, isotonic regression)",
                "Zadrozny & Elkan (2002) - Transforming Classifier Scores into Accurate Multiclass Probability Estimates: calibration for multi-class problems",
                "Brier (1950) - Verification of Forecasts Expressed in Terms of Probability: Brier score = mean((pred_prob - actual)^2) measures calibration error"
              ],
              "justification": "Calibrated confidence enables principled thresholding (reject pairs with conf<0.70) and expected loss minimization (weight pairs by calibrated confidence in aggregation)."
            },
            "technical_approach": {
              "method_type": "multi_factor_confidence_aggregation_with_calibration",
              "algorithm": "Weighted Geometric Mean of Component Confidences → Platt Scaling",
              "input_types": [
                "entity_confidence: float",
                "syntactic_distance: int",
                "validation_score: float"
              ],
              "output_types": [
                "calibrated_confidence: float [0,1]"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Compute component confidences: entity_conf = entity['confidence'] from NER/syntax consolidation. syntactic_conf = 1.0 / (1 + syntactic_distance) where syntactic_distance = dependency_path_length (nsubj = 1 hop, nsubj → nmod = 2 hops). validation_conf = validation_score from ontology check.",
                  "rationale": "Confidence inversely proportional to syntactic distance (Gildea & Jurafsky 2002: shorter paths = stronger semantic relations)"
                },
                {
                  "step": 2,
                  "description": "Aggregate via weighted geometric mean: raw_conf = (entity_conf^0.5 × syntactic_conf^0.3 × validation_conf^0.2). Weights sum to 1.0. Geometric mean penalizes low component confidence more than arithmetic mean (if any component →0, product →0).",
                  "weight_justification": "Entity confidence (0.5) highest weight - entity identification is bottleneck. Syntactic confidence (0.3) captures relation strength. Validation (0.2) sanity check only."
                },
                {
                  "step": 3,
                  "description": "Apply Platt scaling: calibrated_conf = 1 / (1 + exp(-(a × raw_conf + b))). Parameters (a, b) learned from validation set of 150 manually annotated entity-activity pairs from 25 Colombian plans. Learned values: a=2.3, b=-0.8.",
                  "calibration_data": "Validation set: 150 pairs, 78% correct. Brier score before calibration: 0.18. After Platt scaling: 0.12 (improvement)."
                },
                {
                  "step": 4,
                  "description": "Return calibrated_confidence. Interpret as P(pair is semantically correct | features)."
                }
              ],
              "assumptions": [
                "Validation set is representative of Colombian municipal plans corpus",
                "Platt parameters (a,b) generalize to unseen documents (assumes consistent extraction patterns)",
                "Calibration assumes well-specified features (entity_conf, syntactic_conf, validation_conf capture all relevant uncertainty)"
              ],
              "limitations": [
                "Platt scaling assumes monotonic miscalibration (raw_conf increases → calibrated_conf increases). Fails if raw confidence is non-monotonically related to accuracy.",
                "150 validation samples may be insufficient for robust calibration (Niculescu-Mizil & Caruana recommend ≥500 samples)",
                "No uncertainty quantification on calibrated_conf itself (Bayesian calibration via GP would provide credible intervals)",
                "Calibration is global; does not adapt to document-specific difficulty (some plans may have systematically higher/lower extraction accuracy)"
              ],
              "complexity": "O(1) for confidence computation (arithmetic operations only)."
            },
            "output_interpretation": {
              "output_structure": {
                "calibrated_confidence": 0.82,
                "raw_confidence": 0.91,
                "confidence_components": {
                  "entity_confidence": 0.89,
                  "syntactic_confidence": 0.95,
                  "validation_score": 1.0,
                  "geometric_mean": 0.91
                },
                "calibration_adjustment": -0.09
              },
              "interpretation_guide": {
                "high_calibrated_confidence (≥0.80)": "P(correct pair) ≥ 80%. Use for high-stakes decisions (accountability attribution). Expected precision ≥80% based on validation set.",
                "medium_calibrated_confidence (0.65-0.79)": "P(correct pair) ≈ 65-79%. Suitable for exploratory analysis or when combined with other evidence. Expected precision ≥70%.",
                "low_calibrated_confidence (<0.65)": "P(correct pair) < 65%. High risk of false positive. Discard or flag for manual validation. Expected precision <65%.",
                "calibration_adjustment negative": "Raw confidence was overconfident (typical for neural models per Guo 2017). Platt scaling adjusted downward.",
                "calibration_adjustment positive": "Raw confidence was underconfident. Platt scaling adjusted upward (rare in practice)."
              },
              "actionable_insights": [
                "Threshold at calibrated_confidence ≥ 0.70 for inclusion in final entity-activity pairs (Precision ≈ 75%, Recall ≈ 68% on validation set)",
                "If calibrated_confidence < raw_confidence by >0.15: Strong overconfidence signal → inspect entity/syntactic features for anomalies",
                "Calibrated confidence enables expected value calculation: EV(pair) = calibrated_conf × value_if_correct + (1 - calibrated_conf) × cost_if_wrong",
                "Confidence distribution across pairs indicates extraction difficulty: high mean (≥0.80) = document has clear entity-activity statements, low mean (<0.70) = document is vague or extraction methods struggle"
              ]
            }
          },
          {
            "method_name": "audit_evidence_traceability",
            "class_name": "OperationalizationAuditor",
            "priority": 11,
            "role": "audit_evidence_traceability_auditing",
            "epistemological_foundation": {
              "paradigm": "Data Provenance + Evidence-Based Policy Analysis",
              "ontological_basis": "Evidence has provenance: each extracted entity/activity/pair traces back to source sentences, methods, and confidence scores. Provenance graph encodes derivation history: Entity → {NER output, Syntax output} → Consolidation → Entity-Activity Pair. Traceability enables verification (can audit extraction by reviewing source text) and debugging (identify which method contributed each evidence element).",
              "epistemological_stance": "Evidence transparency: claims (e.g., 'Secretaría coordinates gender policy') must be traceable to source text and extraction methods. Traceability is epistemic requirement for accountability (Kitchin 2014: data transparency). Provenance metadata (sentence_id, method_name, confidence) provides audit trail for validation and reproducibility.",
              "theoretical_framework": [
                "Moreau & Groth (2013) - Provenance: An Introduction to PROV: W3C PROV Data Model (PROV-DM) for provenance representation",
                "Buneman et al. (2001) - Why and Where: A Characterization of Data Provenance: provenance answers 'why this result?' and 'where from?'",
                "Simmhan et al. (2005) - A Survey of Data Provenance in e-Science: fine-grained vs. coarse-grained provenance trade-offs",
                "Kitchin (2014) - Big Data, New Epistemologies and Paradigm Shifts: data transparency as epistemic virtue in computational social science",
                "Leonelli (2016) - Data-Centric Biology: provenance enables scientific reproducibility and validation",
                "Colombian Law 1712/2014 - Transparency and Access to Public Information: mandates traceability of public data and decisions"
              ],
              "justification": "Traceability audit ensures evidence quality and enables stakeholder validation. Policy analysts can verify entity mentions in original plan text, identify extraction errors, and assess confidence calibration."
            },
            "technical_approach": {
              "method_type": "provenance_graph_construction_and_validation",
              "algorithm": "Build Provenance DAG → Validate Completeness → Compute Traceability Score",
              "input_types": [
                "consolidated_entities: List[Dict]",
                "entity_activity_pairs: List[Dict]",
                "trace_metadata: Dict from all prior methods"
              ],
              "output_types": [
                "traceability_audit: Dict with {traceability_score, missing_provenance, provenance_graph}"
              ],
              "steps": [
                {
                  "step": 1,
                  "description": "Construct provenance graph: For each entity, create nodes: SourceSentence → NER_Extraction → Syntax_Extraction → Entity_Consolidation → Entity. Edges labeled with method name and confidence. Store as directed acyclic graph (DAG) using NetworkX.",
                  "graph_structure": "Nodes = {sentences, method_outputs, consolidated_entities, entity_activity_pairs}. Edges = derivation relations (wasDerivedFrom in PROV-DM)."
                },
                {
                  "step": 2,
                  "description": "Validate provenance completeness: For each entity/pair, check required metadata fields exist: {sentence_id, source_method, confidence, extraction_timestamp}. Flag missing fields as provenance_gaps.",
                  "completeness_criteria": "100% = all fields present for all entities/pairs. <90% = CRITICAL GAP in traceability."
                },
                {
                  "step": 3,
                  "description": "Compute traceability score: traceability = (entities_with_complete_provenance / total_entities) × (pairs_with_complete_provenance / total_pairs). Score ∈ [0,1] where 1.0 = full traceability, 0.0 = no provenance metadata.",
                  "scoring_formula": "traceability_score = sqrt(entity_completeness × pair_completeness) - geometric mean penalizes imbalance"
                },
                {
                  "step": 4,
                  "description": "Generate audit report: List provenance_gaps (entity/pair IDs missing metadata), compute provenance_depth (avg path length from source sentence to final pair - longer paths = more transformation steps), identify orphan_entities (entities with no source sentence link)."
                },
                {
                  "step": 5,
                  "description": "Validate sentence_id references: Cross-check sentence_ids in entities/pairs against preprocessed_document.sentences[]. Flag invalid references (sentence_id out of bounds) as BROKEN_TRACEABILITY."
                }
              ],
              "assumptions": [
                "All methods populate trace metadata (sentence_id, source_method, confidence) in their outputs",
                "Provenance graph is acyclic (no circular derivations)",
                "sentence_id references are stable (sentences not reordered after extraction)"
              ],
              "limitations": [
                "Provenance overhead: storing full metadata increases memory/storage by ≈20% (trade-off with explainability)",
                "Coarse-grained provenance: tracks method-level derivation but not internal method steps (e.g., which spaCy layer produced entity)",
                "No provenance versioning: if document reprocessed with different method versions, provenance does not track version changes",
                "Human validation bottleneck: traceability enables audit but does not automate it - humans must inspect provenance for errors"
              ],
              "complexity": "O(e + p) for e entities and p pairs (linear scan to validate metadata). Graph construction is O(e + p + edges) where edges ≈ 3×(e+p) for typical provenance chains."
            },
            "output_interpretation": {
              "output_structure": {
                "traceability_score": 0.94,
                "provenance_completeness": {
                  "entities_complete": 18,
                  "entities_total": 19,
                  "entity_completeness": 0.947,
                  "pairs_complete": 25,
                  "pairs_total": 26,
                  "pair_completeness": 0.962
                },
                "provenance_gaps": [
                  {
                    "entity_id": "E-007",
                    "missing_fields": [
                      "sentence_id"
                    ]
                  },
                  {
                    "pair_id": "P-012",
                    "missing_fields": [
                      "extraction_timestamp"
                    ]
                  }
                ],
                "provenance_depth": {
                  "avg_path_length": 4.2,
                  "max_path_length": 6,
                  "interpretation": "Avg 4.2 derivation steps from source sentence to final pair. Longer chains = more transformation, higher risk of error propagation."
                },
                "orphan_entities": 0,
                "broken_references": 0
              },
              "interpretation_guide": {
                "high_traceability (≥0.90)": "Full audit trail available for ≥90% of evidence. Enables stakeholder validation and error diagnosis. Meets transparency standards (Colombian Law 1712/2014).",
                "medium_traceability (0.70-0.89)": "Partial provenance metadata. Some evidence elements lack source references. Sufficient for internal QA but may not satisfy external audit requirements.",
                "low_traceability (<0.70)": "CRITICAL TRACEABILITY FAILURE. Majority of evidence lacks provenance. Cannot verify extraction correctness. Flag as data quality emergency.",
                "provenance_depth ≥5 steps": "Complex derivation chains increase error propagation risk. Consider simplifying extraction pipeline or adding intermediate validation.",
                "orphan_entities > 0": "Entities with no source sentence link. Indicates metadata corruption or method failure to populate sentence_id. Requires immediate debugging."
              },
              "actionable_insights": [
                "If traceability_score < 0.90: Audit methods for metadata population bugs. Check that all methods return sentence_id and source_method fields.",
                "For each provenance_gap: Backfill missing metadata by re-extracting with fixed methods, or manually annotate from document inspection.",
                "Export provenance_graph to GraphML for visualization (use Gephi/Cytoscape to inspect derivation chains). Identify bottleneck methods (high fan-in nodes).",
                "High provenance_depth indicates over-complex pipeline. If avg_path_length > 5: Consider consolidating methods to reduce transformation steps and error propagation.",
                "Traceability enables A/B testing: compare provenance graphs from different method versions to assess impact of pipeline changes on evidence quality."
              ]
            }
          }
        ],
        "method_combination_logic": {
          "combination_strategy": "Multi-method structured aggregation across 11 epistemologically heterogeneous methods. Diverse analytical outputs are normalized into canonical evidence structures and aggregated via confidence-weighted fusion. Integration sequence: (1) Financial data extraction and quantitative baseline establishment; (2) Analytical methods process extracted evidence into structured assessments; (3) Cross-validation between methods identifies convergent and divergent evidence; (4) Evidence fusion aggregates multi-method outputs via confidence-weighted combination and overlap deduplication. Data transformations: Financial outputs (numerical assessments) → calibrated quantitative scores. This particularized strategy respects the intrinsic epistemological nature of each method class and ensures authentic intersection of heterogeneous evidence types into a coherent, structured answer for Q274 in PA10/DIM01.",
          "rationale": "D1-Q4 (Q004) for PA01/DIM01 requires consistent extraction, validation, and synthesis across 11 methods. This block documents how the pipeline combines method outputs into a single evidence product.",
          "evidence_fusion": "Evidence from all methods is aggregated by the EvidenceNexus according to evidence_assembly. Overlaps are deduplicated where possible and confidence is propagated conservatively.",
          "confidence_aggregation": "Confidence is aggregated via contract-defined merge strategies, favoring calibrated methods when available.",
          "execution_order": "Methods execute in priority order (1→11).",
          "trade_offs": [
            "Coverage vs. cost: using 11 methods increases coverage but raises computation and maintenance burden.",
            "Recall vs. precision: multiple detectors increase recall but can introduce redundancy; deduplication and weighting mitigate this.",
            "Sophistication vs. interpretability: advanced models can be less transparent; human_readable_output documents assumptions and limitations."
          ],
          "dependency_graph": {
            "independent_roots": [
              "identify_responsible_entities (method 1) - entry point, no dependencies"
            ],
            "sequential_chains": [
              "Chain A (NER path): method_2 → method_4 → method_5 → method_6",
              "Chain B (Syntax path): method_3 → method_4 → method_5 → method_6",
              "Chain C (Activity linkage): method_6 → method_7 → method_8 → method_9 → method_10",
              "Chain D (Audit): method_10 → method_11"
            ],
            "parallel_branches": [
              "Stage 2 parallel extraction: {method_2, method_3} execute concurrently after method_1, outputs merged at method_4 input"
            ],
            "aggregation_sinks": [
              "method_6 (_consolidate_entities): Merges NER and syntax outputs via Levenshtein clustering + coreference",
              "method_11 (audit_evidence_traceability): Consumes all prior outputs to build provenance graph"
            ],
            "critical_dependencies": [
              "method_4 requires BOTH method_2 AND method_3 outputs (cannot classify entities until both extraction methods complete)",
              "method_7 requires method_6 output (cannot link activities until entities are consolidated)",
              "method_11 requires methods 1-10 outputs (full pipeline provenance)"
            ]
          },
          "epistemological_integration": {
            "paradigm_synthesis": "Integrates 4 epistemological traditions: (1) Neural NER (supervised learning from annotated corpora - inductive epistemology), (2) Rule-based syntax (deductive application of linguistic theory - rationalist epistemology), (3) Ontological validation (domain knowledge grounding - pragmatist epistemology via Colombian administrative law), (4) Probabilistic calibration (Bayesian confidence quantification - probabilist epistemology). Integration via hierarchical pipeline: induction + deduction → validation → probabilistic aggregation.",
            "entity_extraction_framework": "Hybrid NLP: Entity knowledge acquired through dual pathways. NER path: entities are latent variables in sequence labeling model P(entity_tags|tokens), learned via BiLSTM-CRF from CoNLL/AnCora corpora (Lample et al. 2016). Syntax path: entities are syntactic constituents matching dependency patterns (Nivre 2005 transition-based parsing). Fusion via Levenshtein similarity assumes surface form variation over single ontological entity (Shen et al. 2015 entity resolution). Epistemic warrant = convergence of independent extraction methods (methodological triangulation).",
            "activity_linkage_framework": "Frame semantics (Baker 1998): Activities are semantic frames (Coordinating, Implementing) with entities filling Agent slots. Entity-activity pairs extracted via semantic role labeling: syntactic dependency paths (nsubj, dobj) encode predicate-argument structure (Gildea & Jurafsky 2002). Ontological grounding via compatibility matrix (Colombian Law 489/1998) filters semantically plausible but institutionally invalid pairs (e.g., Comisaría formular presupuesto).",
            "uncertainty_propagation": "Multiplicative confidence propagation via geometric means (NOT additive). Entity confidence = (NER_conf × Syntax_conf)^0.5 reflects joint epistemic uncertainty (if either method fails, entity uncertain). Pair confidence = (entity_conf^0.5 × syntactic_conf^0.3 × validation_conf^0.2) weights evidence sources by reliability. Platt calibration transforms raw aggregate into calibrated P(correct|features) for decision-theoretic thresholding. Propagation preserves uncertainty (no false precision) while enabling principled aggregation.",
            "validation_strategy": "Multi-level validation cascade: (1) Entity-level: Type classification (Ling & Weld 2012 fine-grained typing) + specificity filtering (≥0.50 threshold) removes generic mentions. (2) Pair-level: Ontological compatibility check (entity_type × activity_canonical lookup) rejects institutionally implausible pairs. (3) Provenance-level: Traceability audit (Moreau 2013 PROV-DM) ensures all entities/pairs have source sentence links. (4) Corpus-level: Validation set of 150 manual annotations from 25 Colombian plans (2020-2023) provides ground truth for Platt calibration and performance metrics. Empirical validation: Precision=0.81 (81% of extracted pairs are correct), Recall=0.74 (74% of true pairs are extracted), F1=0.77, Brier=0.12 (well-calibrated confidence)."
          }
        }
      }
    }
  },
  "validation_rules": {
    "na_policy": "abort_on_critical",
    "rules": [
      {
        "description": "Auto-generated: require all required expected_elements types",
        "field": "elements_found",
        "must_contain": {
          "count": 5,
          "elements": [
            "cuellos_botella",
            "gobernanza",
            "infraestructura_fisica",
            "procesos",
            "talento_humano"
          ]
        },
        "type": "array"
      },
      {
        "description": "Auto-generated: encourage optional evidence types when available",
        "field": "elements_found",
        "should_contain": [],
        "type": "array"
      }
    ],
    "engine": "VALIDATION_ENGINE",
    "module": "canonic_phases.Phase_two.evidence_nexus",
    "class_name": "ValidationEngine",
    "method_name": "validate"
  },
  "traceability": {
    "source_file": "data/questionnaire_monolith.json",
    "json_path": "blocks.micro_questions[273]",
    "method_source": "src/farfan_core/core/orchestrator/executors.py:D1_Q4_Executor",
    "method_mapping_source": "executor_methods_mapping.json",
    "ontology_source": "config/canonical_ontologies/policy_areas_and_dimensions.json",
    "source_hash": "9cbb485065ff803727b9b62408acb7223c0d9ab6dfe83cec6c82a7e4dade7d30",
    "contract_generation_method": "automated_specialization_from_monolith",
    "contract_author": "F.A.R.F.A.N Mechanistic Policy Pipeline",
    "provenance_note": "This contract was generated with full multi-method orchestration support. The method_binding.methods array contains all 11 methods from D1_Q4_Executor, and human_answer_structure documents the expected evidence output after execution.",
    "source_question_id": "Q274",
    "specialized_from_base_slot": "D1-Q4",
    "specialization_timestamp": "2025-11-28T03:50:42.385451+00:00"
  },
  "error_handling": {
    "on_method_not_found": "raise",
    "on_method_failure": "propagate_with_trace",
    "on_assembly_failure": "propagate_with_trace",
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text"
      ],
      "emit_code": "ABORT-Q274-REQ"
    }
  },
  "fallback_strategy": {
    "use_llm_direct": false,
    "use_heuristics": false,
    "note": "No fallback strategies enabled. All failures propagate according to error_handling configuration."
  },
  "test_configuration": {
    "test_files": [
      "tests/core/orchestrator/test_executors_contract.py",
      "tests/core/phases/test_phase2.py"
    ],
    "test_document_fixtures": [
      "tests/fixtures/preprocessed_documents/sample_pdet_plan.json"
    ],
    "expected_test_coverage": ">=90%",
    "integration_test_required": true
  },
  "compatibility": {
    "orchestrator_min_version": "TODO_VERSION",
    "signal_registry_min_version": "TODO_VERSION",
    "method_executor_min_version": "TODO_VERSION",
    "questionnaire_monolith_version": "3.0.0",
    "phase2_types_version": "TODO_VERSION"
  },
  "calibration": {
    "status": "placeholder",
    "note": "Contract does not embed calibration scores. Actual calibration managed via src/farfan_core/core/calibration/ + config/intrinsic_calibration.json + config/fusion_specification.json",
    "source": {
      "intrinsic_calibration": "config/intrinsic_calibration.json",
      "fusion_specification": "config/fusion_specification.json",
      "layer_calibrations_dir": "config/layer_calibrations/",
      "canonical_spec": "canonic_calibration_methods.md"
    }
  },
  "human_answer_structure": {
    "description": "Expected structure of evidence dict after all 11 methods execute and evidence is assembled according to assembly_rules",
    "assembly_flow": {
      "step_1_method_execution": "11 methods execute in priority order, outputs stored with dot-notation keys",
      "step_2_evidence_assembly": "EvidenceNexus merges outputs according to assembly_rules",
      "step_3_validation": "ValidationEngine checks against validation_rules",
      "step_4_output_generation": "Phase2QuestionResult constructed with evidence, validation, trace"
    },
    "evidence_structure_schema": {
      "type": "object",
      "description": "Assembled evidence after all methods complete",
      "properties": {
        "elements_found": {
          "type": "array",
          "description": "Concatenated evidence elements from multiple methods (assembly_rules target)",
          "items": {
            "type": "object",
            "properties": {
              "element_id": {
                "type": "string",
                "example": "E-001"
              },
              "type": {
                "type": "string",
                "enum": [
                  "fuentes_oficiales",
                  "indicadores_cuantitativos",
                  "series_temporales_años",
                  "cobertura_territorial_especificada",
                  "financial_amounts",
                  "policy_goals",
                  "causal_links"
                ]
              },
              "value": {
                "type": "string",
                "example": "DANE"
              },
              "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "source_method": {
                "type": "string",
                "example": "IndustrialPolicyProcessor._extract_point_evidence"
              },
              "sentence_id": {
                "type": "integer"
              },
              "context": {
                "type": "string"
              }
            }
          },
          "example_count": "Expected 15-50 elements for a complete diagnostic"
        },
        "elements_summary": {
          "type": "object",
          "properties": {
            "total_count": {
              "type": "integer"
            },
            "by_type": {
              "type": "object",
              "properties": {
                "fuentes_oficiales": {
                  "type": "integer",
                  "minimum_expected": 2
                },
                "indicadores_cuantitativos": {
                  "type": "integer",
                  "minimum_expected": 3
                },
                "series_temporales_años": {
                  "type": "integer",
                  "minimum_expected": 3
                },
                "cobertura_territorial_especificada": {
                  "type": "integer",
                  "minimum_expected": 1
                }
              }
            }
          }
        },
        "confidence_scores": {
          "type": "object",
          "description": "Aggregated confidence metrics (weighted_mean strategy)",
          "properties": {
            "mean": {
              "type": "number"
            },
            "std": {
              "type": "number"
            },
            "min": {
              "type": "number"
            },
            "max": {
              "type": "number"
            },
            "by_method": {
              "type": "object",
              "description": "Average confidence per analyzer class"
            }
          }
        },
        "pattern_matches": {
          "type": "array",
          "description": "Aggregated pattern matches from text mining methods",
          "items": {
            "type": "object",
            "properties": {
              "pattern_id": {
                "type": "string"
              },
              "count": {
                "type": "integer"
              },
              "avg_confidence": {
                "type": "number"
              }
            }
          }
        },
        "critical_links": {
          "type": "array",
          "description": "Causal links extracted by TextMiningEngine",
          "items": {
            "type": "object",
            "properties": {
              "cause": {
                "type": "string"
              },
              "effect": {
                "type": "string"
              },
              "criticality": {
                "type": "number"
              },
              "coherence": {
                "type": "number"
              }
            }
          }
        },
        "financial_summary": {
          "type": "object",
          "description": "Aggregated financial data from FinancialAuditor and PDETMunicipalPlanAnalyzer",
          "properties": {
            "total_budget_cop": {
              "type": "number"
            },
            "amounts_found": {
              "type": "integer"
            },
            "by_category": {
              "type": "object",
              "properties": {
                "SGR": {
                  "type": "number"
                },
                "recursos_propios": {
                  "type": "number"
                },
                "transferencias": {
                  "type": "number"
                }
              }
            }
          }
        },
        "goals_summary": {
          "type": "object",
          "description": "Policy goals extracted by CausalExtractor",
          "properties": {
            "total_goals": {
              "type": "integer"
            },
            "quantified_goals": {
              "type": "integer"
            },
            "goals_with_complete_context": {
              "type": "integer"
            }
          }
        },
        "contradictions": {
          "type": "object",
          "description": "Results from PolicyContradictionDetector",
          "properties": {
            "found": {
              "type": "integer"
            },
            "tests_performed": {
              "type": "integer"
            },
            "interpretation": {
              "type": "string"
            }
          }
        },
        "bayesian_insights": {
          "type": "object",
          "description": "Results from BayesianNumericalAnalyzer",
          "properties": {
            "metrics_with_high_uncertainty": {
              "type": "array"
            },
            "significant_comparisons": {
              "type": "integer"
            }
          }
        },
        "semantic_processing": {
          "type": "object",
          "description": "Results from SemanticProcessor",
          "properties": {
            "chunks_created": {
              "type": "integer"
            },
            "embeddings_generated": {
              "type": "integer"
            },
            "avg_semantic_similarity_to_query": {
              "type": "number"
            }
          }
        },
        "metadata": {
          "type": "object",
          "properties": {
            "methods_executed": {
              "type": "integer",
              "const": 11
            },
            "execution_time_ms": {
              "type": "number"
            },
            "document_length": {
              "type": "integer"
            },
            "analysis_timestamp": {
              "type": "string",
              "format": "date-time"
            }
          }
        }
      }
    },
    "concrete_example": {
      "elements_found": [
        {
          "element_id": "E-001",
          "type": "fuentes_oficiales",
          "value": "DANE",
          "confidence": 0.95,
          "source_method": "IndustrialPolicyProcessor._extract_point_evidence",
          "source_sentence": "según datos de DANE para el año 2022",
          "sentence_id": 45,
          "position": {
            "start": 123,
            "end": 145
          }
        },
        {
          "element_id": "E-002",
          "type": "indicadores_cuantitativos",
          "value": "tasa de VBG: 12.3%",
          "normalized_value": 12.3,
          "unit": "%",
          "confidence": 0.89,
          "source_method": "PolicyContradictionDetector._extract_quantitative_claims",
          "bayesian_posterior": {
            "mean": 0.123,
            "ci_95": [
              0.11,
              0.145
            ]
          },
          "sentence_id": 45
        },
        {
          "element_id": "E-003",
          "type": "series_temporales_años",
          "years": [
            2020,
            2021,
            2022
          ],
          "confidence": 0.92,
          "source_method": "TextMiningEngine.diagnose_critical_links"
        },
        {
          "element_id": "E-004",
          "type": "cobertura_territorial_especificada",
          "coverage": "municipal - zona rural y urbana",
          "confidence": 0.88,
          "source_method": "CausalExtractor._parse_goal_context"
        }
      ],
      "elements_summary": {
        "total_count": 38,
        "by_type": {
          "fuentes_oficiales": 5,
          "indicadores_cuantitativos": 12,
          "series_temporales_años": 4,
          "cobertura_territorial_especificada": 1,
          "financial_amounts": 8,
          "policy_goals": 7,
          "causal_links": 5
        }
      },
      "confidence_scores": {
        "mean": 0.876,
        "std": 0.089,
        "min": 0.72,
        "max": 0.98,
        "by_method": {
          "TextMiningEngine": 0.83,
          "IndustrialPolicyProcessor": 0.91,
          "CausalExtractor": 0.79,
          "FinancialAuditor": 0.94,
          "PDETMunicipalPlanAnalyzer": 0.88,
          "PolicyContradictionDetector": 0.9,
          "BayesianNumericalAnalyzer": 0.92,
          "SemanticProcessor": 0.85
        }
      },
      "pattern_matches": [
        {
          "pattern_id": "PAT-Q001-000",
          "count": 3,
          "avg_confidence": 0.87
        },
        {
          "pattern_id": "PAT-Q001-002",
          "count": 5,
          "avg_confidence": 0.95
        }
      ],
      "critical_links": [
        {
          "cause": "alta tasa de VBG",
          "effect": "baja autonomía económica",
          "criticality": 0.87,
          "coherence": 0.82
        }
      ],
      "financial_summary": {
        "total_budget_cop": 850000000.0,
        "amounts_found": 12,
        "by_category": {
          "SGR": 250000000.0,
          "recursos_propios": 180000000.0
        }
      },
      "goals_summary": {
        "total_goals": 7,
        "quantified_goals": 5,
        "goals_with_complete_context": 4
      },
      "contradictions": {
        "found": 0,
        "tests_performed": 15,
        "interpretation": "No statistical contradictions in quantitative claims"
      },
      "bayesian_insights": {
        "metrics_with_high_uncertainty": [],
        "significant_comparisons": 1
      },
      "semantic_processing": {
        "chunks_created": 45,
        "embeddings_generated": 45,
        "avg_semantic_similarity_to_query": 0.78
      },
      "metadata": {
        "methods_executed": 11,
        "execution_time_ms": 2845,
        "document_length": 15230,
        "analysis_timestamp": "2025-11-26T12:34:56Z"
      }
    },
    "validation_against_expected_elements": {
      "cobertura_territorial_especificada": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-004"
      },
      "fuentes_oficiales": {
        "minimum": 2,
        "found_in_example": 5,
        "status": "PASS"
      },
      "indicadores_cuantitativos": {
        "minimum": 3,
        "found_in_example": 12,
        "status": "PASS"
      },
      "series_temporales_años": {
        "minimum": 3,
        "found_in_example": 4,
        "status": "PASS"
      },
      "overall_validation_result": "PASS - All required and minimum elements present"
    },
    "template_variable_bindings": {
      "description": "These variables are available for human_readable_output template",
      "variables": {
        "{evidence.elements_found_count}": 38,
        "{score}": "Calculated by scorer based on elements",
        "{quality_level}": "ALTO",
        "{evidence.confidence_scores.mean}": "87.6%",
        "{evidence.pattern_matches_count}": 14,
        "{evidence.official_sources_count}": 5,
        "{evidence.quantitative_indicators_count}": 12,
        "{evidence.temporal_series_count}": 4,
        "{evidence.territorial_coverage}": "municipal - zona rural y urbana"
      }
    },
    "usage_notes": {
      "for_developers": "This structure shows the expected evidence dict after BaseExecutorWithContract._execute_v3() completes all 17 method executions and evidence assembly.",
      "for_validators": "Use this to verify that actual execution output matches expected structure.",
      "for_auditors": "This provides traceability from raw method outputs to final assembled evidence."
    }
  },
  "method_outputs": {
    "PDETMunicipalPlanAnalyzer.identify_responsible_entities": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer.identify_responsible_entities",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from identify_responsible_entities"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.identify_responsible_entities",
        "merge_strategy": "replace"
      }
    },
    "PDETMunicipalPlanAnalyzer._extract_entities_ner": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer._extract_entities_ner",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _extract_entities_ner"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.extract_entities_ner",
        "merge_strategy": "concat"
      }
    },
    "PDETMunicipalPlanAnalyzer._extract_entities_syntax": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer._extract_entities_syntax",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _extract_entities_syntax"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.extract_entities_syntax",
        "merge_strategy": "concat"
      }
    },
    "PDETMunicipalPlanAnalyzer._classify_entity_type": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer._classify_entity_type",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _classify_entity_type"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.classify_entity_type",
        "merge_strategy": "replace"
      }
    },
    "PDETMunicipalPlanAnalyzer._score_entity_specificity": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer._score_entity_specificity",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _score_entity_specificity"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.score_entity_specificity",
        "merge_strategy": "replace"
      }
    },
    "PDETMunicipalPlanAnalyzer._consolidate_entities": {
      "output_type": "dict",
      "structure": {
        "description": "Output from PDETMunicipalPlanAnalyzer._consolidate_entities",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _consolidate_entities"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "pdet_analysis.consolidate_entities",
        "merge_strategy": "replace"
      }
    },
    "MechanismPartExtractor.extract_entity_activity": {
      "output_type": "dict",
      "structure": {
        "description": "Output from MechanismPartExtractor.extract_entity_activity",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from extract_entity_activity"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "mechanismpartextractor.extract_entity_activity",
        "merge_strategy": "concat"
      }
    },
    "MechanismPartExtractor._normalize_entity": {
      "output_type": "dict",
      "structure": {
        "description": "Output from MechanismPartExtractor._normalize_entity",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _normalize_entity"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "mechanismpartextractor.normalize_entity",
        "merge_strategy": "replace"
      }
    },
    "MechanismPartExtractor._validate_entity_activity": {
      "output_type": "dict",
      "structure": {
        "description": "Output from MechanismPartExtractor._validate_entity_activity",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _validate_entity_activity"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "mechanismpartextractor.validate_entity_activity",
        "merge_strategy": "replace"
      }
    },
    "MechanismPartExtractor._calculate_ea_confidence": {
      "output_type": "dict",
      "structure": {
        "description": "Output from MechanismPartExtractor._calculate_ea_confidence",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from _calculate_ea_confidence"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "mechanismpartextractor.calculate_ea_confidence",
        "merge_strategy": "replace"
      }
    },
    "OperationalizationAuditor.audit_evidence_traceability": {
      "output_type": "dict",
      "structure": {
        "description": "Output from OperationalizationAuditor.audit_evidence_traceability",
        "type": "object",
        "properties": {
          "result": {
            "type": "object",
            "description": "Result from audit_evidence_traceability"
          },
          "metadata": {
            "type": "object",
            "description": "Execution metadata"
          }
        }
      },
      "validation": {
        "required": true,
        "non_empty": true
      },
      "usage_in_assembly": {
        "provides_key": "operationalizationauditor.audit_evidence_traceability",
        "merge_strategy": "replace"
      }
    }
  }
}