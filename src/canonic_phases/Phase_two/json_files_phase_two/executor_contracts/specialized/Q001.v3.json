{
  "identity": {
    "base_slot": "D1-Q1",
    "question_id": "Q001",
    "dimension_id": "DIM01",
    "policy_area_id": "PA01",
    "contract_version": "3.0.1",
    "contract_hash": "11fb08b8c16761434fc60b6d1252f3209469b8212f690e3bcc27c8942af76bdb",
    "created_at": "2025-11-28T03:49:29.779617+00:00",
    "validated_against_schema": "executor_contract.v3.schema.json",
    "cluster_id": "CL02",
    "question_global": 1
  },
  "executor_binding": {
    "executor_class": "D1_Q1_Executor",
    "executor_module": "farfan_core.core.orchestrator.executors"
  },
  "method_binding": {
    "orchestration_mode": "multi_method_pipeline",
    "method_count": 17,
    "methods": [
      {
        "class_name": "TextMiningEngine",
        "method_name": "diagnose_critical_links",
        "priority": 1,
        "provides": "text_mining.diagnose_critical_links",
        "role": "diagnose_critical_links_diagnosis",
        "description": "TextMiningEngine.diagnose_critical_links"
      },
      {
        "class_name": "TextMiningEngine",
        "method_name": "_analyze_link_text",
        "priority": 2,
        "provides": "text_mining.analyze_link_text",
        "role": "_analyze_link_text_analysis",
        "description": "TextMiningEngine._analyze_link_text"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "process",
        "priority": 3,
        "provides": "industrial_policy.process",
        "role": "process_processing",
        "description": "IndustrialPolicyProcessor.process"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_match_patterns_in_sentences",
        "priority": 4,
        "provides": "industrial_policy.match_patterns_in_sentences",
        "role": "_match_patterns_in_sentences_matching",
        "description": "IndustrialPolicyProcessor._match_patterns_in_sentences"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_extract_point_evidence",
        "priority": 5,
        "provides": "industrial_policy.extract_point_evidence",
        "role": "_extract_point_evidence_extraction",
        "description": "IndustrialPolicyProcessor._extract_point_evidence"
      },
      {
        "class_name": "CausalExtractor",
        "method_name": "_extract_goals",
        "priority": 6,
        "provides": "causal_extraction.extract_goals",
        "role": "_extract_goals_extraction",
        "description": "CausalExtractor._extract_goals"
      },
      {
        "class_name": "CausalExtractor",
        "method_name": "_parse_goal_context",
        "priority": 7,
        "provides": "causal_extraction.parse_goal_context",
        "role": "_parse_goal_context_parsing",
        "description": "CausalExtractor._parse_goal_context"
      },
      {
        "class_name": "FinancialAuditor",
        "method_name": "_parse_amount",
        "priority": 8,
        "provides": "financial_audit.parse_amount",
        "role": "_parse_amount_parsing",
        "description": "FinancialAuditor._parse_amount"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_extract_financial_amounts",
        "priority": 9,
        "provides": "pdet_analysis.extract_financial_amounts",
        "role": "_extract_financial_amounts_extraction",
        "description": "PDETMunicipalPlanAnalyzer._extract_financial_amounts"
      },
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_extract_from_budget_table",
        "priority": 10,
        "provides": "pdet_analysis.extract_from_budget_table",
        "role": "_extract_from_budget_table_extraction",
        "description": "PDETMunicipalPlanAnalyzer._extract_from_budget_table"
      },
      {
        "class_name": "PolicyContradictionDetector",
        "method_name": "_extract_quantitative_claims",
        "priority": 11,
        "provides": "contradiction_detection.extract_quantitative_claims",
        "role": "_extract_quantitative_claims_extraction",
        "description": "PolicyContradictionDetector._extract_quantitative_claims"
      },
      {
        "class_name": "PolicyContradictionDetector",
        "method_name": "_parse_number",
        "priority": 12,
        "provides": "contradiction_detection.parse_number",
        "role": "_parse_number_parsing",
        "description": "PolicyContradictionDetector._parse_number"
      },
      {
        "class_name": "PolicyContradictionDetector",
        "method_name": "_statistical_significance_test",
        "priority": 13,
        "provides": "contradiction_detection.statistical_significance_test",
        "role": "_statistical_significance_test_execution",
        "description": "PolicyContradictionDetector._statistical_significance_test"
      },
      {
        "class_name": "BayesianNumericalAnalyzer",
        "method_name": "evaluate_policy_metric",
        "priority": 14,
        "provides": "bayesian_analysis.evaluate_policy_metric",
        "role": "evaluate_policy_metric_evaluation",
        "description": "BayesianNumericalAnalyzer.evaluate_policy_metric"
      },
      {
        "class_name": "BayesianNumericalAnalyzer",
        "method_name": "compare_policies",
        "priority": 15,
        "provides": "bayesian_analysis.compare_policies",
        "role": "compare_policies_comparison",
        "description": "BayesianNumericalAnalyzer.compare_policies"
      },
      {
        "class_name": "SemanticProcessor",
        "method_name": "chunk_text",
        "priority": 16,
        "provides": "semantic_processing.chunk_text",
        "role": "chunk_text_chunking",
        "description": "SemanticProcessor.chunk_text"
      },
      {
        "class_name": "SemanticProcessor",
        "method_name": "embed_single",
        "priority": 17,
        "provides": "semantic_processing.embed_single",
        "role": "embed_single_embedding",
        "description": "SemanticProcessor.embed_single"
      }
    ],
    "execution_sequence": {
      "step_1": {
        "method": "TextMiningEngine.diagnose_critical_links",
        "provides": "text_mining.diagnose_critical_links",
        "output_type": "list[CausalLink]",
        "output_structure": {
          "cause": "string",
          "effect": "string",
          "connector": "string",
          "criticality_score": "float",
          "sentence_id": "int",
          "context": "string"
        }
      },
      "step_2": {
        "method": "TextMiningEngine._analyze_link_text",
        "provides": "text_mining.analyze_link_text",
        "depends_on": ["text_mining.diagnose_critical_links"],
        "output_type": "list[LinkAnalysis]",
        "output_structure": {
          "link_id": "int",
          "coherence_score": "float",
          "context_window": "string",
          "supporting_sentences": "list[string]",
          "contradicting_sentences": "list[string]"
        }
      },
      "step_3": {
        "method": "IndustrialPolicyProcessor.process",
        "provides": "industrial_policy.process",
        "output_type": "dict",
        "output_structure": {
          "document_structure": "dict",
          "extracted_segments": "dict",
          "structural_completeness": "float"
        }
      },
      "step_4": {
        "method": "IndustrialPolicyProcessor._match_patterns_in_sentences",
        "provides": "industrial_policy.match_patterns_in_sentences",
        "depends_on": ["industrial_policy.process"],
        "output_type": "list[PatternMatch]",
        "output_structure": {
          "sentence_id": "int",
          "pattern_id": "string",
          "matched_text": "string",
          "start_pos": "int",
          "end_pos": "int",
          "confidence": "float"
        }
      },
      "step_5": {
        "method": "IndustrialPolicyProcessor._extract_point_evidence",
        "provides": "industrial_policy.extract_point_evidence",
        "depends_on": ["industrial_policy.match_patterns_in_sentences"],
        "output_type": "list[EvidencePoint]",
        "output_structure": {
          "element_type": "string",
          "value": "string",
          "normalized_value": "float|null",
          "unit": "string|null",
          "confidence": "float",
          "sentence_id": "int",
          "context_snippet": "string"
        }
      },
      "step_6": {
        "method": "CausalExtractor._extract_goals",
        "provides": "causal_extraction.extract_goals",
        "output_type": "list[PolicyGoal]",
        "output_structure": {
          "goal_verb": "string",
          "target_entity": "string",
          "quantifier": "string|null",
          "sentence_id": "int",
          "full_text": "string"
        }
      },
      "step_7": {
        "method": "CausalExtractor._parse_goal_context",
        "provides": "causal_extraction.parse_goal_context",
        "depends_on": ["causal_extraction.extract_goals"],
        "output_type": "dict[int, GoalContext]",
        "output_structure": {
          "goal_id": {
            "temporal_context": "string|null",
            "spatial_context": "string|null",
            "actor_context": "string|null"
          }
        }
      },
      "step_8": {
        "method": "FinancialAuditor._parse_amount",
        "provides": "financial_audit.parse_amount",
        "output_type": "list[FinancialAmount]",
        "output_structure": {
          "raw_text": "string",
          "normalized_value": "float",
          "currency": "string",
          "parsing_confidence": "float",
          "sentence_id": "int"
        }
      },
      "step_9": {
        "method": "PDETMunicipalPlanAnalyzer._extract_financial_amounts",
        "provides": "pdet_analysis.extract_financial_amounts",
        "depends_on": ["financial_audit.parse_amount"],
        "output_type": "list[CategorizedAmount]",
        "output_structure": {
          "amount": "float",
          "category": "string",
          "source_type": "string",
          "confidence": "float"
        }
      },
      "step_10": {
        "method": "PDETMunicipalPlanAnalyzer._extract_from_budget_table",
        "provides": "pdet_analysis.extract_from_budget_table",
        "output_type": "list[BudgetTableRow]",
        "output_structure": {
          "row_label": "string",
          "column_label": "string",
          "amount": "float",
          "table_id": "string"
        }
      },
      "step_11": {
        "method": "PolicyContradictionDetector._extract_quantitative_claims",
        "provides": "contradiction_detection.extract_quantitative_claims",
        "output_type": "list[QuantitativeClaim]",
        "output_structure": {
          "subject": "string",
          "value": "float",
          "unit": "string",
          "sentence_id": "int",
          "confidence": "float"
        }
      },
      "step_12": {
        "method": "PolicyContradictionDetector._parse_number",
        "provides": "contradiction_detection.parse_number",
        "output_type": "dict",
        "output_structure": {
          "parsed_value": "float",
          "parsing_confidence": "float",
          "ambiguity_flags": "list[string]"
        }
      },
      "step_13": {
        "method": "PolicyContradictionDetector._statistical_significance_test",
        "provides": "contradiction_detection.statistical_significance_test",
        "depends_on": ["contradiction_detection.extract_quantitative_claims"],
        "output_type": "list[SignificanceTest]",
        "output_structure": {
          "claim1_id": "int",
          "claim2_id": "int",
          "difference": "float",
          "p_value": "float",
          "is_significant": "bool",
          "test_type": "string"
        }
      },
      "step_14": {
        "method": "BayesianNumericalAnalyzer.evaluate_policy_metric",
        "provides": "bayesian_analysis.evaluate_policy_metric",
        "depends_on": ["contradiction_detection.extract_quantitative_claims"],
        "output_type": "dict[string, BayesianMetric]",
        "output_structure": {
          "metric_id": {
            "posterior_mean": "float",
            "credible_interval_95": "[float, float]",
            "posterior_samples": "list[float]|null"
          }
        }
      },
      "step_15": {
        "method": "BayesianNumericalAnalyzer.compare_policies",
        "provides": "bayesian_analysis.compare_policies",
        "depends_on": ["bayesian_analysis.evaluate_policy_metric"],
        "output_type": "dict[string, PolicyComparison]",
        "output_structure": {
          "comparison_id": {
            "prob_A_better": "float",
            "effect_size": "float",
            "overlap": "float"
          }
        }
      },
      "step_16": {
        "method": "SemanticProcessor.chunk_text",
        "provides": "semantic_processing.chunk_text",
        "output_type": "list[TextChunk]",
        "output_structure": {
          "chunk_id": "string",
          "chunk_text": "string",
          "start_pos": "int",
          "end_pos": "int",
          "token_count": "int"
        }
      },
      "step_17": {
        "method": "SemanticProcessor.embed_single",
        "provides": "semantic_processing.embed_single",
        "depends_on": ["semantic_processing.chunk_text"],
        "output_type": "dict[string, Embedding]",
        "output_structure": {
          "chunk_id": {
            "embedding": "list[float]",
            "model_id": "string"
          }
        }
      }
    },
    "note": "All 17 methods extracted from D1_Q1_Executor in executors.py"
  },
  "question_context": {
    "question_text": "¿El diagnóstico presenta datos numéricos (tasas de VBG, porcentajes de participación, cifras de brechas salariales) para el área de Derechos de las mujeres e igualdad de género que sirvan como línea base? Se debe verificar la presencia de un año de referencia y la mención de fuentes (ej. DANE, Medicina Legal, Observatorio de Género).",
    "question_type": "micro",
    "scoring_modality": "TYPE_A",
    "modality": "count_and_scale",
    "expected_output_type": "score",
    "patterns": [
      {
        "category": "TEMPORAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-000",
        "match_type": "REGEX",
        "pattern": "línea base|año base|situación inicial|diagnóstico de género"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-001",
        "match_type": "REGEX",
        "pattern": "fuente:|según|reportado por|con datos de"
      },
      {
        "category": "FUENTE_OFICIAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-002",
        "match_type": "REGEX",
        "pattern": "DANE|Medicina Legal|Fiscalía|Policía Nacional|SIVIGILA|SISPRO"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-003",
        "match_type": "REGEX",
        "pattern": "Observatorio de Asuntos de Género|Secretaría de la Mujer|Comisaría de Familia"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-004",
        "match_type": "REGEX",
        "pattern": "Encuesta Nacional de Demografía y Salud|ENDS"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-005",
        "match_type": "REGEX",
        "pattern": "violencia intrafamiliar|VBG|violencia basada en género|delitos sexuales|feminicidio"
      },
      {
        "category": "INDICADOR",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-006",
        "match_type": "REGEX",
        "pattern": "tasa de|porcentaje de|número de casos|brecha salarial de"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-007",
        "match_type": "REGEX",
        "pattern": "participación política de las mujeres|mujeres en cargos directivos"
      },
      {
        "category": "INDICADOR",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-008",
        "match_type": "REGEX",
        "pattern": "autonomía económica|tasa de desempleo femenina"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-009",
        "match_type": "REGEX",
        "pattern": "madres adolescentes|embarazo en adolescentes"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-010",
        "match_type": "LITERAL",
        "pattern": "2021|2022|2023|vigencia anterior|cuatrienio anterior"
      },
      {
        "category": "INDICADOR",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-011",
        "match_type": "REGEX",
        "pattern": "\\d+(\\.\\d+)?\\s*%"
      },
      {
        "category": "UNIDAD_MEDIDA",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-012",
        "match_type": "REGEX",
        "pattern": "por cada 100\\.000 mujeres|por 100 mil habitantes"
      },
      {
        "category": "TEMPORAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q001-013",
        "match_type": "REGEX",
        "pattern": "serie histórica|evolución 20\\d{2}-20\\d{2}|tendencia de los últimos"
      }
    ],
    "expected_elements": [
      {
        "required": true,
        "type": "cobertura_territorial_especificada"
      },
      {
        "minimum": 2,
        "type": "fuentes_oficiales"
      },
      {
        "minimum": 3,
        "type": "indicadores_cuantitativos"
      },
      {
        "minimum": 3,
        "type": "series_temporales_años"
      }
    ],
    "validations": {
      "buscar_indicadores_cuantitativos": {
        "minimum_required": 3,
        "patterns": [
          "\\d+%",
          "\\d+\\s*por\\s*\\d+",
          "tasa de",
          "índice de",
          "cobertura de"
        ],
        "specificity": "HIGH"
      },
      "cobertura": {
        "minimum_required": 1,
        "patterns": [
          "departamental",
          "municipal",
          "urbano",
          "rural",
          "territorial",
          "poblacional"
        ],
        "specificity": "HIGH"
      },
      "series_temporales": {
        "minimum_years": 3,
        "patterns": [
          "20\\d{2}",
          "año",
          "periodo",
          "histórico",
          "serie"
        ],
        "specificity": "MEDIUM"
      },
      "unidades_medicion": {
        "minimum_required": 2,
        "patterns": [
          "por 100.000",
          "por 1.000",
          "%",
          "porcentaje",
          "tasa",
          "razón"
        ],
        "specificity": "MEDIUM"
      },
      "verificar_fuentes": {
        "minimum_required": 2,
        "patterns": [
          "fuente:",
          "según",
          "datos de",
          "DANE",
          "DNP",
          "SISPRO",
          "SIVIGILA",
          "Ministerio"
        ],
        "specificity": "MEDIUM"
      }
    }
  },
  "signal_requirements": {
    "mandatory_signals": [
      "baseline_completeness",
      "data_sources",
      "gender_baseline_data",
      "policy_coverage",
      "vbg_statistics"
    ],
    "optional_signals": [
      "geographic_scope",
      "source_validation",
      "temporal_coverage",
      "temporal_series",
      "territorial_scope"
    ],
    "signal_aggregation": "weighted_mean",
    "minimum_signal_threshold": 0.5,
    "note": "Signal requirements enforce minimum quality threshold of 0.5. Mandatory signals must be present with sufficient strength for execution to proceed."
  },
  "evidence_assembly": {
    "module": "canonic_phases.Phase_two.evidence_nexus",
    "class_name": "EvidenceNexus",
    "method_name": "process",
    "output_schema": {
      "type": "object",
      "required": [
        "evidence",
        "validation",
        "trace"
      ],
      "properties": {
        "evidence": {
          "type": "object",
          "description": "Legacy-compatible evidence dict with elements, by_type, confidence_scores",
          "properties": {
            "elements": {
              "type": "array",
              "description": "Evidence nodes from graph"
            },
            "by_type": {
              "type": "object",
              "description": "Count of elements by evidence type"
            },
            "confidence_scores": {
              "type": "object",
              "description": "Confidence statistics (mean, min, max)"
            },
            "graph_hash": {
              "type": "string",
              "description": "SHA-256 hash of evidence graph"
            }
          }
        },
        "validation": {
          "type": "object",
          "description": "Validation report from ValidationEngine",
          "properties": {
            "valid": {"type": "boolean"},
            "consistency_score": {"type": "number"},
            "errors": {"type": "array"},
            "warnings": {"type": "array"}
          }
        },
        "trace": {
          "type": "object",
          "description": "Execution trace and graph statistics"
        },
        "synthesized_answer": {
          "type": "object",
          "description": "Complete synthesized answer from NarrativeSynthesizer"
        },
        "human_readable_output": {
          "type": "string",
          "description": "Formatted narrative (Carver-style) for human consumption"
        },
        "overall_confidence": {
          "type": "number",
          "description": "Overall confidence for Phase 3 scoring"
        },
        "completeness": {
          "type": "string",
          "enum": ["complete", "partial", "insufficient", "not_applicable"],
          "description": "Answer completeness level"
        },
        "graph_statistics": {
          "type": "object",
          "description": "Evidence graph metrics (node_count, edge_count, etc.)"
        }
      },
      "additionalProperties": true
    },
    "assembly_rules": [
      {
        "target": "evidence_graph",
        "sources": [
          "text_mining.diagnose_critical_links",
          "text_mining.analyze_link_text",
          "industrial_policy.process",
          "industrial_policy.match_patterns_in_sentences",
          "industrial_policy.extract_point_evidence",
          "causal_extraction.extract_goals",
          "causal_extraction.parse_goal_context",
          "financial_audit.parse_amount",
          "pdet_analysis.extract_financial_amounts",
          "pdet_analysis.extract_from_budget_table",
          "contradiction_detection.extract_quantitative_claims",
          "contradiction_detection.parse_number",
          "contradiction_detection.statistical_significance_test",
          "bayesian_analysis.evaluate_policy_metric",
          "bayesian_analysis.compare_policies",
          "semantic_processing.chunk_text",
          "semantic_processing.embed_single"
        ],
        "merge_strategy": "graph_construction",
        "description": "EvidenceNexus transforms ALL 17 method outputs into EvidenceNode objects with SHA-256 hashing and builds causal evidence graph"
      },
      {
        "target": "relationships",
        "sources": [
          "*.causal_links",
          "*.supports",
          "*.contradicts"
        ],
        "merge_strategy": "edge_inference",
        "description": "Nexus infers EvidenceEdge relationships (SUPPORTS, CONTRADICTS, CAUSES, CORRELATES) between nodes"
      },
      {
        "target": "belief_propagation",
        "sources": [
          "*.confidence",
          "*.bayesian_posterior"
        ],
        "merge_strategy": "dempster_shafer",
        "description": "Apply Dempster-Shafer belief propagation across graph for calibrated confidence intervals"
      },
      {
        "target": "narrative_synthesis",
        "sources": [
          "evidence_graph",
          "validation_report",
          "question_context"
        ],
        "merge_strategy": "carver_doctoral_synthesis",
        "description": "DoctoralCarverSynthesizer generates Raymond Carver-style PhD-level narrative with citations and gap analysis"
      }
    ]
  },
  "output_contract": {
    "result_type": "Phase2QuestionResult",
    "schema": {
      "type": "object",
      "required": [
        "base_slot",
        "question_id",
        "question_global",
        "evidence",
        "validation"
      ],
      "properties": {
        "base_slot": {
          "type": "string",
          "description": "Debe coincidir con identity.base_slot.",
          "const": "D1-Q1"
        },
        "question_id": {
          "type": "string",
          "description": "Debe coincidir con identity.question_id.",
          "const": "Q001"
        },
        "question_global": {
          "type": "integer",
          "description": "Índice global de la pregunta (de questionnaire_monolith).",
          "const": 1
        },
        "policy_area_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "PA canónica, debe ser coherente con identity.policy_area_id.",
          "const": "PA01"
        },
        "dimension_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Dimensión canónica, coherente con identity.dimension_id.",
          "const": "DIM01"
        },
        "cluster_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Cluster de análisis según el monolith, si aplica.",
          "const": "CL02"
        },
        "evidence": {
          "type": [
            "object",
            "null"
          ],
          "description": "Objeto de evidencia procesado por EvidenceNexus con estructura de grafo y campos legacy-compatible; incluye elements, by_type, confidence_scores, graph_hash.",
          "additionalProperties": true
        },
        "validation": {
          "type": [
            "object",
            "null"
          ],
          "description": "Resultado de validaciones lógicas de la respuesta (coherencia, integridad, etc.).",
          "additionalProperties": true
        },
        "trace": {
          "type": [
            "object",
            "null"
          ],
          "description": "Información de trazabilidad (provenance, logs) específica de la ejecución.",
          "additionalProperties": true
        },
        "synthesized_answer": {
          "type": ["object", "null"],
          "description": "Respuesta sintetizada completa por NarrativeSynthesizer"
        },
        "human_readable_output": {
          "type": ["string", "null"],
          "description": "Narrativa formateada estilo Carver para consumo humano"
        },
        "overall_confidence": {
          "type": ["number", "null"],
          "description": "Confianza general para scoring en Phase 3",
          "minimum": 0,
          "maximum": 1
        },
        "completeness": {
          "type": ["string", "null"],
          "enum": ["complete", "partial", "insufficient", "not_applicable"]
        },
        "graph_statistics": {
          "type": ["object", "null"],
          "description": "Métricas del grafo de evidencia",
          "properties": {
            "node_count": {"type": "integer"},
            "edge_count": {"type": "integer"},
            "density": {"type": "number"},
            "avg_confidence": {"type": "number"}
          }
        },
        "metadata": {
          "type": [
            "object",
            "null"
          ],
          "description": "Metadatos adicionales de la pregunta para consumo posterior.",
          "additionalProperties": true
        }
      },
      "additionalProperties": false
    },
    "consumer_modules": [
      "src.farfan_core.core.phases.phase2_types.validate_phase2_result",
      "src.farfan_core.core.orchestrator.core.Orchestrator._score_micro_results_async",
      "src.farfan_core.analysis.scoring.MicroQuestionScorer"
    ],
    "human_readable_output": {
      "format": "markdown",
      "template": {
        "title": "## Análisis D1-Q1: Línea Base Cuantitativa en Derechos de las Mujeres",
        "summary": "### Resumen Ejecutivo\n\nSe analizó la presencia de **{evidence.elements_count}** nodos de evidencia en el grafo construido por EvidenceNexus para la línea base diagnóstica en el área de Derechos de las Mujeres e Igualdad de Género.\n\n**Puntaje**: {score}/3.0 | **Calidad**: {quality_level} | **Confianza**: {overall_confidence}",
        "score_section": "### Evaluación Cuantitativa\n\n- **Puntaje bruto**: {score}/3.0\n- **Nivel de calidad**: {quality_level}\n- **Confianza general**: {overall_confidence}\n- **Completitud**: {completeness}\n- **Nodos en grafo**: {graph_statistics.node_count} | **Relaciones**: {graph_statistics.edge_count}",
        "elements_section": "### Elementos de Evidencia Identificados (Grafo)\n\n{evidence.elements_list}\n\n**Gaps críticos**: {synthesized_answer.gaps}",
        "details": [
          "**Fuentes oficiales identificadas**: {evidence.official_sources_count}",
          "**Indicadores cuantitativos**: {evidence.quantitative_indicators_count}",
          "**Series temporales**: {evidence.temporal_series_count}",
          "**Cobertura territorial**: {evidence.territorial_coverage}"
        ],
        "interpretation": "### Interpretación de Resultados\n\n{methodological_interpretation}",
        "recommendations": "### Recomendaciones\n\n{evidence.recommendations}"
      },
      "methodological_depth": {
        "methods": [
          {
            "method_name": "diagnose_critical_links",
            "class_name": "TextMiningEngine",
            "priority": 1,
            "role": "critical_link_diagnosis",
            "technical_approach": {
              "algorithm": "Pattern-based causal link extraction with context window analysis",
              "input": "Preprocessed document sentences",
              "output": "list[CausalLink] with cause, effect, connector, criticality_score",
              "steps": [
                "Identify causal connectors in sentences (porque, por lo tanto, conduce a, genera)",
                "Extract entities before connector (cause) and after (effect)",
                "Calculate criticality score based on proximity to gender indicators",
                "Return structured CausalLink objects with sentence_id for traceability"
              ],
              "complexity": "O(n*p) where n=sentences, p=causal patterns"
            },
            "output_interpretation": {
              "high_criticality": "≥0.8: Link directly mentions gender inequality outcomes (VBG, autonomía económica)",
              "medium_criticality": "0.5-0.79: Link relates to intermediate factors (educación, empleo)",
              "low_criticality": "<0.5: Peripheral causal relationship",
              "actionable_insight": "Few critical links → diagnosis lacks causal depth, may be purely descriptive"
            }
          },
          {
            "method_name": "_analyze_link_text",
            "class_name": "TextMiningEngine",
            "priority": 2,
            "role": "link_context_analysis",
            "technical_approach": {
              "algorithm": "Context window semantic coherence analysis",
              "input": "CausalLink objects from step 1 + document sentences",
              "output": "list[LinkAnalysis] with coherence_score, supporting/contradicting sentences",
              "steps": [
                "For each causal link, extract ±3 sentence context window",
                "Calculate semantic similarity between link and context using embeddings",
                "Identify supporting evidence (sentences that reinforce the link)",
                "Identify contradicting evidence (sentences that undermine the link)",
                "Return LinkAnalysis with coherence_score [0-1]"
              ],
              "complexity": "O(k*w*e) where k=links, w=context window, e=embedding cost"
            },
            "output_interpretation": {
              "high_coherence": "≥0.7: Link well-supported by surrounding text, empirically grounded",
              "low_coherence": "<0.5: Link may be spurious or poorly contextualized",
              "actionable_insight": "Low coherence + many links → scattered causal claims without substantiation"
            }
          },
          {
            "method_name": "process",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 3,
            "role": "structural_processing",
            "technical_approach": {
              "algorithm": "Hierarchical structural extraction with pattern matching",
              "input": "Preprocessed document text",
              "output": "dict with document_structure, extracted_segments, structural_completeness",
              "steps": [
                "Identify structural markers (pillar headers, objective numbering, section titles)",
                "Extract content within each structural segment (pillars → objectives → actions)",
                "Apply pattern registry to each segment to find baseline data, targets, indicators",
                "Calculate structural_completeness score based on presence of expected sections",
                "Return nested dict mapping structure → content"
              ],
              "complexity": "O(n*m) where n=document sections, m=pattern types"
            },
            "output_interpretation": {
              "complete_structure": "≥0.8: Document follows standard Colombian municipal planning format",
              "incomplete_structure": "<0.5: Document lacks formal structure, may indicate low technical capacity",
              "actionable_insight": "Complete structure but no baseline data → compliance without substance"
            }
          },
          {
            "method_name": "_match_patterns_in_sentences",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 4,
            "role": "sentence_pattern_matching",
            "technical_approach": {
              "algorithm": "Regex pattern matching at sentence granularity",
              "input": "Document sentences + pattern registry (14 patterns for Q001)",
              "output": "list[PatternMatch] with sentence_id, pattern_id, matched_text, positions, confidence",
              "steps": [
                "Segment document into sentences",
                "For each sentence, apply all 14 patterns from question_context.patterns",
                "Record matches with precise start/end positions in sentence",
                "Assign confidence from pattern.confidence_weight (0.85 for Q001 patterns)",
                "Return list of PatternMatch objects"
              ],
              "complexity": "O(s*p) where s=sentences, p=patterns (14 for Q001)"
            },
            "output_interpretation": {
              "dense_matches": "Many matches per sentence → rich informational content",
              "sparse_matches": "Few matches → document lacks expected policy elements",
              "actionable_insight": "Matches concentrated in few sentences → evidence localized, not systemic"
            }
          },
          {
            "method_name": "_extract_point_evidence",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 5,
            "role": "atomic_evidence_extraction",
            "technical_approach": {
              "algorithm": "Atomic evidence unit extraction from pattern matches",
              "input": "PatternMatch objects from step 4",
              "output": "list[EvidencePoint] with element_type, value, normalized_value, confidence",
              "steps": [
                "For each pattern match, identify evidence unit type (fuentes_oficiales, indicadores_cuantitativos, series_temporales_años, cobertura_territorial)",
                "Extract value (e.g., 'DANE' for source, '12.3%' for indicator)",
                "Normalize numeric values where applicable (parse percentages, rates)",
                "Include minimal context snippet for traceability",
                "Return list of EvidencePoint objects with element_type classification"
              ],
              "complexity": "O(m) where m=pattern matches"
            },
            "output_interpretation": {
              "high_point_count": "Many evidence points → rich baseline",
              "type_imbalance": "Many indicators but few sources → data without provenance",
              "actionable_insight": "Balanced by_type distribution → comprehensive evidence base"
            }
          },
          {
            "method_name": "_extract_goals",
            "class_name": "CausalExtractor",
            "priority": 6,
            "role": "goal_extraction",
            "technical_approach": {
              "algorithm": "Goal phrase extraction with teleological verb detection",
              "input": "Document sentences",
              "output": "list[PolicyGoal] with goal_verb, target_entity, quantifier",
              "steps": [
                "Detect goal verbs in sentences (reducir, incrementar, alcanzar, lograr)",
                "Extract object of goal verb (what is to be reduced/increased)",
                "Extract quantifier if present (percentage, absolute number, target year)",
                "Assign sentence_id for traceability",
                "Return list of PolicyGoal objects"
              ],
              "complexity": "O(n) where n=sentences"
            },
            "output_interpretation": {
              "quantified_goals": "Goals with numbers are measurable and SMART-compliant",
              "vague_goals": "Goals without quantifiers are non-measurable aspirations",
              "actionable_insight": "Goals without baseline data → targets lack empirical foundation"
            }
          },
          {
            "method_name": "_parse_goal_context",
            "class_name": "CausalExtractor",
            "priority": 7,
            "role": "goal_contextualization",
            "technical_approach": {
              "algorithm": "Context parsing around goal statements",
              "input": "PolicyGoal objects from step 6 + document sentences",
              "output": "dict[goal_id, GoalContext] with temporal, spatial, actor context",
              "steps": [
                "For each goal, extract ±5 sentence context window",
                "Identify temporal markers (plazo, 2024-2027, cuatrienio)",
                "Identify spatial scope (municipal, rural, urbano, corregimiento)",
                "Identify responsible actors (Secretaría de..., Alcaldía, entidad)",
                "Return dict mapping goal_id to GoalContext with three dimensions"
              ],
              "complexity": "O(g*w) where g=goals, w=context window size"
            },
            "output_interpretation": {
              "complete_context": "All three dimensions present → well-specified SMART goal",
              "incomplete_context": "Missing dimensions → ambiguous goal with low accountability",
              "actionable_insight": "Goals without temporal context → no deadline, diffused responsibility"
            }
          },
          {
            "method_name": "_parse_amount",
            "class_name": "FinancialAuditor",
            "priority": 8,
            "role": "financial_parsing",
            "technical_approach": {
              "algorithm": "Monetary amount parsing with unit normalization",
              "input": "Document text",
              "output": "list[FinancialAmount] with raw_text, normalized_value (COP), currency, confidence",
              "steps": [
                "Detect amount patterns in text ($ X.XXX.XXX, X millones de pesos)",
                "Parse numeric component handling Colombian formatting (. as thousands separator)",
                "Identify unit multiplier (millones, mil millones) and apply",
                "Normalize to standard currency (COP)",
                "Assign parsing_confidence based on format clarity",
                "Return list of FinancialAmount objects"
              ],
              "complexity": "O(n) where n=amount patterns detected"
            },
            "output_interpretation": {
              "high_confidence": "≥0.9: Amount clearly stated with explicit currency",
              "low_confidence": "<0.7: Ambiguous format, may be misparsed",
              "actionable_insight": "Many low-confidence amounts → poor financial data formatting"
            }
          },
          {
            "method_name": "_extract_financial_amounts",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 9,
            "role": "pdet_financial_categorization",
            "technical_approach": {
              "algorithm": "PDET-specific financial categorization",
              "input": "FinancialAmount objects from step 8 + document text",
              "output": "list[CategorizedAmount] with amount, category (SGR|PAC|recursos_propios), confidence",
              "steps": [
                "For each financial amount, search proximity for PDET categories (SGR, regalías, PAC, recursos propios)",
                "Link amount to category if found within ±2 sentences",
                "Handle PDET-specific terminology (Sistema General de Regalías, Plan de Acción Cuatrienal)",
                "Assign confidence based on proximity and explicitness of link",
                "Return list of CategorizedAmount objects"
              ],
              "complexity": "O(a*c) where a=amounts, c=category patterns"
            },
            "output_interpretation": {
              "categorized": "Amount linked to funding source → transparent budget",
              "uncategorized": "Amount without source → lack of transparency",
              "actionable_insight": "Heavy reliance on single source (e.g., all SGR) → diversification risk"
            }
          },
          {
            "method_name": "_extract_from_budget_table",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 10,
            "role": "table_parsing",
            "technical_approach": {
              "algorithm": "Structured table parsing with row-column extraction",
              "input": "Document text with embedded tables (HTML, Markdown, or aligned whitespace)",
              "output": "list[BudgetTableRow] with row_label, column_label, amount, table_id",
              "steps": [
                "Detect table structures using format markers (HTML <table>, Markdown |, whitespace alignment)",
                "Parse table into grid structure identifying headers (row labels, column labels)",
                "Extract cells containing financial amounts using amount patterns",
                "Link amounts to row labels (program/project names) and column labels (years)",
                "Assign unique table_id for multi-table documents",
                "Return list of BudgetTableRow objects"
              ],
              "complexity": "O(r*c) where r=table rows, c=table columns"
            },
            "output_interpretation": {
              "complete_tables": "All expected columns present → comprehensive budget detail",
              "incomplete_tables": "Missing columns/rows → partial financial information",
              "actionable_insight": "Multi-year columns → long-term planning; single-year → short-term focus"
            }
          },
          {
            "method_name": "_extract_quantitative_claims",
            "class_name": "PolicyContradictionDetector",
            "priority": 11,
            "role": "claim_extraction",
            "technical_approach": {
              "algorithm": "Quantitative statement extraction with subject-value parsing",
              "input": "Document sentences",
              "output": "list[QuantitativeClaim] with subject, value, unit, sentence_id, confidence",
              "steps": [
                "Identify sentences with quantitative patterns (X es Y%, la tasa de X es Y)",
                "Parse subject (what is being quantified, e.g., 'tasa de VBG')",
                "Parse value (numeric component) and unit (%, por 100.000, etc.)",
                "Store as structured QuantitativeClaim {subject, value, unit, sentence_id}",
                "Return list for contradiction analysis in step 13"
              ],
              "complexity": "O(n) where n=sentences with quantitative patterns"
            },
            "output_interpretation": {
              "duplicate_subjects": "Multiple claims about same metric → check for contradictions",
              "unique_subjects": "Each claim distinct → comprehensive coverage",
              "actionable_insight": "Contradictory claims → data quality issue requiring investigation"
            }
          },
          {
            "method_name": "_parse_number",
            "class_name": "PolicyContradictionDetector",
            "priority": 12,
            "role": "numeric_parsing",
            "technical_approach": {
              "algorithm": "Robust numeric parsing with Colombian format handling",
              "input": "Numeric strings from text",
              "output": "dict with parsed_value (float), parsing_confidence, ambiguity_flags",
              "steps": [
                "Detect numeric patterns (12.5, 1.234, 1,234.56)",
                "Infer separator convention (Colombian uses . for thousands, , for decimals in some contexts)",
                "Handle ambiguous cases (1.234 could be 1234 or 1.234) and flag",
                "Convert to float preserving precision",
                "Return parsed_value with confidence and ambiguity_flags"
              ],
              "complexity": "O(n) where n=numeric strings"
            },
            "output_interpretation": {
              "high_confidence": "≥0.95: Unambiguous format (e.g., 12,5% with explicit %)",
              "low_confidence": "<0.8: Ambiguous separator usage",
              "actionable_insight": "Low confidence → document uses non-standard formatting"
            }
          },
          {
            "method_name": "_statistical_significance_test",
            "class_name": "PolicyContradictionDetector",
            "priority": 13,
            "role": "statistical_testing",
            "technical_approach": {
              "algorithm": "Frequentist hypothesis testing for contradiction detection",
              "input": "QuantitativeClaim objects from step 11",
              "output": "list[SignificanceTest] with p_value, is_significant, test_type",
              "steps": [
                "For each pair of claims about same subject, compute observed difference",
                "Estimate measurement error if metadata available (typically unavailable, use conservative estimates)",
                "Perform appropriate significance test: t-test for continuous metrics, chi-square for categorical",
                "Test null hypothesis H0: difference = 0 at alpha = 0.05",
                "Flag contradiction if p < 0.05 and difference is practically meaningful",
                "Return list of SignificanceTest results for contradictory pairs"
              ],
              "complexity": "O(c²) for pairwise comparisons of c claims"
            },
            "output_interpretation": {
              "p < 0.05": "Statistically significant contradiction → data quality problem",
              "p ≥ 0.05": "Difference not significant → likely rounding or measurement error",
              "actionable_insight": "Multiple significant contradictions → systemic data collection issue"
            }
          },
          {
            "method_name": "evaluate_policy_metric",
            "class_name": "BayesianNumericalAnalyzer",
            "priority": 14,
            "role": "bayesian_inference",
            "technical_approach": {
              "algorithm": "Bayesian posterior computation for policy metrics",
              "input": "QuantitativeClaim objects with values and metadata",
              "output": "dict[metric_id, BayesianMetric] with posterior_mean, credible_interval, samples",
              "steps": [
                "For each quantitative metric, specify prior distribution (e.g., Beta for rates, Normal for counts)",
                "Incorporate observed data as likelihood (count of events, population size)",
                "Compute posterior distribution via conjugate updates (fast) or MCMC (flexible)",
                "Extract posterior mean as point estimate",
                "Calculate 95% Bayesian credible interval",
                "Optionally store posterior samples for downstream analysis",
                "Return dict mapping metric_id to BayesianMetric"
              ],
              "complexity": "O(1) for conjugate priors, O(MCMC_iterations) for non-conjugate"
            },
            "output_interpretation": {
              "narrow_credible_interval": "High precision, sufficient data",
              "wide_credible_interval": "High uncertainty, need more data",
              "actionable_insight": "Wide CI for critical metric → strengthen data collection"
            }
          },
          {
            "method_name": "compare_policies",
            "class_name": "BayesianNumericalAnalyzer",
            "priority": 15,
            "role": "bayesian_comparison",
            "technical_approach": {
              "algorithm": "Posterior distribution comparison via sampling",
              "input": "BayesianMetric objects from step 14 for multiple policies/municipalities",
              "output": "dict[comparison_id, PolicyComparison] with prob_A_better, effect_size, overlap",
              "steps": [
                "Obtain posterior distributions for both policies/municipalities being compared",
                "Draw N samples from each posterior (typically N=10000)",
                "Compute proportion of samples where policy_A > policy_B",
                "Calculate effect size as mean(posterior_A) - mean(posterior_B)",
                "Quantify overlap as proportion of posterior mass intersection",
                "Return PolicyComparison with probabilistic comparison results"
              ],
              "complexity": "O(S) where S=posterior sample size (typically 10000)"
            },
            "output_interpretation": {
              "prob_A_better > 0.95": "Strong evidence policy A is better",
              "0.75 < prob < 0.95": "Moderate evidence",
              "prob ≈ 0.5": "No clear difference given uncertainty",
              "actionable_insight": "High overlap despite different point estimates → differences not meaningful"
            }
          },
          {
            "method_name": "chunk_text",
            "class_name": "SemanticProcessor",
            "priority": 16,
            "role": "text_chunking",
            "technical_approach": {
              "algorithm": "Semantic-aware text chunking with overlap",
              "input": "Preprocessed document text",
              "output": "list[TextChunk] with chunk_id, chunk_text, positions, token_count",
              "steps": [
                "Identify natural text boundaries (paragraphs, section breaks)",
                "Create chunks respecting boundaries with max token limit (typically 512 for BERT-based models)",
                "Add overlap between consecutive chunks (typically 50 tokens) for context continuity",
                "Assign unique chunk_id for traceability",
                "Calculate token_count for each chunk",
                "Return list of TextChunk objects"
              ],
              "complexity": "O(n) where n=document length"
            },
            "output_interpretation": {
              "many_small_chunks": "Document is dense or highly structured",
              "few_large_chunks": "Document is sparse or unstructured",
              "actionable_insight": "Chunk boundaries split semantic units → adjust chunking strategy"
            }
          },
          {
            "method_name": "embed_single",
            "class_name": "SemanticProcessor",
            "priority": 17,
            "role": "semantic_embedding",
            "technical_approach": {
              "algorithm": "Transformer-based text embedding generation",
              "input": "TextChunk objects from step 16",
              "output": "dict[chunk_id, Embedding] with embedding vector, model_id",
              "steps": [
                "Tokenize chunk text for transformer model (e.g., BERT, MPNet, sentence-transformers)",
                "Pass through pretrained model forward pass",
                "Extract embedding: [CLS] token representation or mean pooling of token embeddings",
                "Normalize to unit vector for cosine similarity",
                "Store embedding vector (typically 768-dim for BERT) with model_id",
                "Return dict mapping chunk_id to Embedding"
              ],
              "complexity": "O(L) where L=sequence length for single transformer forward pass"
            },
            "output_interpretation": {
              "cosine_similarity": "Use to compare embeddings (1=identical, 0=orthogonal, -1=opposite)",
              "clustering": "High-dimensional clustering reveals thematic document groups",
              "actionable_insight": "Low similarity between baseline and goals → diagnostic-planning disconnect"
            }
          }
        ],
        "method_combination_logic": {
          "combination_strategy": "Sequential multi-method pipeline with evidence fusion via graph construction",
          "rationale": "D1-Q1 requires comprehensive extraction of quantitative baseline data from heterogeneous sources (narrative text, causal statements, tables, financial data). The 17 methods provide complementary coverage: text mining (1-2) for causal structure, industrial processing (3-5) for structural extraction, causal extraction (6-7) for goals, financial analysis (8-10) for budget data, contradiction detection (11-13) for quality assurance, Bayesian inference (14-15) for uncertainty quantification, and semantic processing (16-17) for similarity-based retrieval.",
          "evidence_fusion": "All 17 method outputs are transformed into EvidenceNode objects by EvidenceNexus. Content-identical nodes are deduplicated via SHA-256 hashing. Confidence values are combined using Dempster-Shafer belief propagation across the evidence graph. Causal relationships are inferred via edge construction (SUPPORTS, CONTRADICTS, CAUSES, CORRELATES).",
          "confidence_aggregation": "Final confidence per evidence element = weighted_mean([confidence_method1, confidence_method2, ...]) where weights reflect method reliability. Bayesian methods receive higher weights (0.95) than regex-based extraction (0.85) due to principled uncertainty quantification. Dempster-Shafer combination rule handles conflicting evidence.",
          "execution_order": "Methods execute in strict priority order (1→17). Later methods can access outputs of earlier methods via provides/depends_on mechanism. For example, method 7 (_parse_goal_context) depends on method 6 (_extract_goals) and enriches goal objects with context.",
          "trade_offs": [
            "Comprehensiveness vs. Complexity: 17 methods ensure thorough coverage but increase computational cost (O(n) → O(n²) for pairwise comparisons) and maintenance burden. Mitigated by caching and parallel execution where dependencies allow.",
            "Precision vs. Recall: Multiple methods increase recall (finding more evidence) but risk redundancy. SHA-256 deduplication and graph-based merging handle overlap. Conservative confidence weighting prevents false positives.",
            "Interpretability vs. Sophistication: Bayesian and embedding methods are powerful but less transparent than regex matching. human_readable_output compensates via methodological documentation and Carver-style narrative synthesis explaining model reasoning."
          ],
          "dependency_graph": {
            "independent": ["text_mining.diagnose_critical_links", "industrial_policy.process", "causal_extraction.extract_goals", "financial_audit.parse_amount", "contradiction_detection.extract_quantitative_claims", "semantic_processing.chunk_text"],
            "dependent_chains": [
              "text_mining.diagnose_critical_links → text_mining.analyze_link_text",
              "industrial_policy.process → industrial_policy.match_patterns_in_sentences → industrial_policy.extract_point_evidence",
              "causal_extraction.extract_goals → causal_extraction.parse_goal_context",
              "financial_audit.parse_amount → pdet_analysis.extract_financial_amounts",
              "contradiction_detection.extract_quantitative_claims → contradiction_detection.statistical_significance_test",
              "contradiction_detection.extract_quantitative_claims → bayesian_analysis.evaluate_policy_metric → bayesian_analysis.compare_policies",
              "semantic_processing.chunk_text → semantic_processing.embed_single"
            ]
          }
        }
      }
    }
  },
  "validation_rules": {
    "na_policy": "abort_on_critical",
    "rules": [
      {
        "field": "elements",
        "type": "array",
        "must_contain": {
          "count": 1,
          "elements": [
            "cobertura_territorial_especificada"
          ]
        },
        "description": "Derived from monolith expected_elements where required is true",
        "severity": "CRITICAL",
        "error_code": "MISSING_TERRITORIAL_COVERAGE"
      },
      {
        "field": "elements",
        "type": "array",
        "should_contain": [
          {
            "elements": [
              "fuentes_oficiales"
            ],
            "minimum": 2
          },
          {
            "elements": [
              "indicadores_cuantitativos"
            ],
            "minimum": 3
          },
          {
            "elements": [
              "series_temporales_años"
            ],
            "minimum": 3
          }
        ],
        "description": "Derived from monolith expected_elements with minimum counts",
        "severity": "HIGH",
        "error_codes": {
          "fuentes_oficiales": "INSUFFICIENT_SOURCES",
          "indicadores_cuantitativos": "INSUFFICIENT_INDICATORS",
          "series_temporales_años": "INSUFFICIENT_TEMPORAL_SERIES"
        }
      },
      {
        "field": "confidence_scores.mean",
        "type": "number",
        "minimum": 0.5,
        "description": "Mean confidence must meet minimum signal threshold",
        "severity": "MEDIUM",
        "error_code": "LOW_CONFIDENCE"
      },
      {
        "field": "graph_statistics.node_count",
        "type": "integer",
        "minimum": 10,
        "description": "Evidence graph must have sufficient nodes for meaningful analysis",
        "severity": "MEDIUM",
        "error_code": "SPARSE_EVIDENCE_GRAPH"
      }
    ]
  },
  "human_answer_structure": {
    "description": "Expected structure after EvidenceNexus processes 17 method outputs: evidence graph, validation report, synthesized narrative, and legacy-compatible evidence dict",
    "assembly_flow": {
      "step_1_method_execution": "17 methods execute in priority order, outputs stored with dot-notation keys (e.g., 'text_mining.diagnose_critical_links')",
      "step_2_evidence_nexus": "EvidenceNexus.process() builds evidence graph from method outputs, SHA-256 hashes nodes, infers relationships",
      "step_3_validation": "ValidationEngine runs graph-theoretic validation (consistency checks, completeness assessment)",
      "step_4_belief_propagation": "Dempster-Shafer propagation across graph to calibrate confidence intervals",
      "step_5_carver_synthesis": "DoctoralCarverSynthesizer generates PhD-level narrative from evidence graph with gap analysis",
      "step_6_output_generation": "Phase2QuestionResult with evidence (legacy), synthesized_answer, human_readable_output, graph_statistics, overall_confidence, completeness"
    },
    "evidence_structure_schema": {
      "type": "object",
      "description": "Evidence structure from EvidenceNexus after graph construction, validation, and Carver synthesis",
      "properties": {
        "elements": {
          "type": "array",
          "description": "Evidence nodes (EvidenceNode objects serialized) from evidence graph built by Nexus",
          "items": {
            "type": "object",
            "properties": {
              "node_id": {
                "type": "string",
                "description": "SHA-256 hash of node content for deduplication",
                "example": "sha256:a3f2b1c0..."
              },
              "element_type": {
                "type": "string",
                "enum": [
                  "fuentes_oficiales",
                  "indicadores_cuantitativos",
                  "series_temporales_años",
                  "cobertura_territorial_especificada",
                  "financial_amounts",
                  "policy_goals",
                  "causal_links",
                  "pattern_matches",
                  "quantitative_claims",
                  "bayesian_metrics"
                ]
              },
              "value": {
                "type": "any",
                "description": "The actual evidence value (string, number, object)",
                "examples": ["DANE", "12.3%", {"mean": 0.123, "ci": [0.11, 0.145]}]
              },
              "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Node-level confidence after belief propagation"
              },
              "source_method": {
                "type": "string",
                "description": "Which of the 17 methods produced this evidence",
                "example": "industrial_policy.extract_point_evidence"
              },
              "source_data": {
                "type": "object",
                "description": "Original method output that produced this node",
                "properties": {
                  "sentence_id": "int|null",
                  "position": "object|null",
                  "context": "string|null"
                }
              },
              "relationships": {
                "type": "array",
                "description": "Edge references to other nodes",
                "items": {
                  "type": "string",
                  "description": "Target node_id"
                }
              },
              "metadata": {
                "type": "object",
                "description": "Additional node metadata",
                "properties": {
                  "created_by_step": "int (1-17)",
                  "extraction_timestamp": "string (ISO8601)",
                  "document_section": "string|null"
                }
              }
            }
          },
          "example_count": "Expected 15-50 elements for a complete diagnostic"
        },
        "by_type": {
          "type": "object",
          "description": "Count of nodes by element_type",
          "properties": {
            "fuentes_oficiales": {
              "type": "integer",
              "minimum_expected": 2,
              "description": "Official sources cited (DANE, Medicina Legal, etc.)"
            },
            "indicadores_cuantitativos": {
              "type": "integer",
              "minimum_expected": 3,
              "description": "Quantitative indicators (rates, percentages, counts)"
            },
            "series_temporales_años": {
              "type": "integer",
              "minimum_expected": 3,
              "description": "Years in temporal series"
            },
            "cobertura_territorial_especificada": {
              "type": "integer",
              "minimum_expected": 1,
              "description": "Territorial coverage specifications"
            },
            "financial_amounts": {
              "type": "integer",
              "description": "Parsed financial amounts"
            },
            "policy_goals": {
              "type": "integer",
              "description": "Extracted policy goals"
            },
            "causal_links": {
              "type": "integer",
              "description": "Detected causal relationships"
            }
          }
        },
        "confidence_scores": {
          "type": "object",
          "description": "Aggregated confidence metrics after Dempster-Shafer fusion",
          "properties": {
            "mean": {
              "type": "number",
              "description": "Weighted mean confidence across all nodes"
            },
            "std": {
              "type": "number",
              "description": "Standard deviation of confidence values"
            },
            "min": {
              "type": "number",
              "description": "Minimum confidence in graph"
            },
            "max": {
              "type": "number",
              "description": "Maximum confidence in graph"
            },
            "by_method": {
              "type": "object",
              "description": "Average confidence per analyzer class",
              "example": {
                "TextMiningEngine": 0.83,
                "IndustrialPolicyProcessor": 0.91,
                "BayesianNumericalAnalyzer": 0.92
              }
            }
          }
        },
        "graph_hash": {
          "type": "string",
          "description": "SHA-256 hash of entire evidence graph for versioning and change detection"
        },
        "relationships": {
          "type": "array",
          "description": "Edges in evidence graph",
          "items": {
            "type": "object",
            "properties": {
              "source_node": {
                "type": "string",
                "description": "Source node SHA-256 hash"
              },
              "target_node": {
                "type": "string",
                "description": "Target node SHA-256 hash"
              },
              "edge_type": {
                "type": "string",
                "enum": ["SUPPORTS", "CONTRADICTS", "CAUSES", "CORRELATES", "DEPENDS_ON"],
                "description": "Type of relationship"
              },
              "weight": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Edge strength"
              },
              "metadata": {
                "type": "object",
                "properties": {
                  "inference_method": "string",
                  "confidence": "number"
                }
              }
            }
          }
        },
        "aggregated_outputs": {
          "type": "object",
          "description": "High-level aggregations from method outputs",
          "properties": {
            "critical_links_summary": {
              "type": "object",
              "properties": {
                "total_links": "int",
                "high_criticality_count": "int",
                "top_critical_links": "list[CausalLink]"
              }
            },
            "financial_summary": {
              "type": "object",
              "properties": {
                "total_budget_cop": "float",
                "amounts_found": "int",
                "by_category": {
                  "SGR": "float",
                  "recursos_propios": "float",
                  "transferencias": "float",
                  "otros": "float"
                }
              }
            },
            "goals_summary": {
              "type": "object",
              "properties": {
                "total_goals": "int",
                "quantified_goals": "int",
                "goals_with_complete_context": "int",
                "goals_linked_to_baseline": "int"
              }
            },
            "contradictions_summary": {
              "type": "object",
              "properties": {
                "contradictions_found": "int",
                "tests_performed": "int",
                "significant_contradictions": "list[SignificanceTest]"
              }
            },
            "bayesian_insights": {
              "type": "object",
              "properties": {
                "metrics_with_high_uncertainty": "list[string]",
                "metrics_needing_more_data": "list[string]",
                "comparison_results": "dict"
              }
            }
          }
        },
        "validation_report": {
          "type": "object",
          "properties": {
            "valid": "boolean",
            "consistency_score": "float",
            "errors": "list[string]",
            "warnings": "list[string]",
            "completeness_assessment": {
              "cobertura_territorial": "complete|partial|missing",
              "fuentes_oficiales": "sufficient|insufficient",
              "indicadores_cuantitativos": "sufficient|insufficient",
              "series_temporales": "sufficient|insufficient"
            }
          }
        }
      }
    },
    "concrete_example": {
      "description": "Ejemplo concreto de estructura de evidencia después del procesamiento completo",
      "elements": [
        {
          "node_id": "sha256:a3f2b1c0d4e5...",
          "element_type": "fuentes_oficiales",
          "value": "DANE",
          "confidence": 0.95,
          "source_method": "industrial_policy.extract_point_evidence",
          "source_data": {
            "sentence_id": 45,
            "position": {"start": 123, "end": 127},
            "context": "según datos de DANE para el año 2022",
            "matched_pattern": "PAT-Q001-002"
          },
          "relationships": ["sha256:b4g3c2d1...", "sha256:c5h4d3..."],
          "metadata": {
            "created_by_step": 5,
            "extraction_timestamp": "2025-11-26T12:34:56Z",
            "document_section": "2.1 Diagnóstico de Género"
          }
        },
        {
          "node_id": "sha256:b4g3c2d1e6f7...",
          "element_type": "indicadores_cuantitativos",
          "value": {
            "indicator_name": "tasa de VBG",
            "raw_value": "12.3%",
            "normalized_value": 12.3,
            "unit": "%"
          },
          "confidence": 0.89,
          "source_method": "contradiction_detection.extract_quantitative_claims",
          "source_data": {
            "sentence_id": 45,
            "full_claim": "la tasa de VBG en el municipio es del 12.3%",
            "subject": "tasa de VBG",
            "value": 12.3,
            "unit": "%"
          },
          "relationships": ["sha256:a3f2b1...", "sha256:d7j6e4..."],
          "metadata": {
            "created_by_step": 11,
            "bayesian_analysis": {
              "posterior_mean": 0.123,
              "credible_interval_95": [0.11, 0.145],
              "uncertainty": "medium"
            }
          }
        },
        {
          "node_id": "sha256:c5h4d3e7f8...",
          "element_type": "series_temporales_años",
          "value": {
            "years": [2020, 2021, 2022],
            "context": "evolución de la tasa de VBG 2020-2022"
          },
          "confidence": 0.92,
          "source_method": "text_mining.diagnose_critical_links",
          "source_data": {
            "sentence_id": 46,
            "temporal_pattern": "PAT-Q001-013"
          },
          "relationships": ["sha256:b4g3c2..."],
          "metadata": {
            "created_by_step": 1,
            "temporal_coverage": "3_years"
          }
        },
        {
          "node_id": "sha256:d6i5e4f9g0...",
          "element_type": "cobertura_territorial_especificada",
          "value": "municipal - zona rural y urbana",
          "confidence": 0.88,
          "source_method": "causal_extraction.parse_goal_context",
          "source_data": {
            "goal_id": 3,
            "spatial_context": "zona rural y urbana del municipio",
            "sentence_id": 52
          },
          "relationships": [],
          "metadata": {
            "created_by_step": 7,
            "coverage_type": "comprehensive"
          }
        },
        {
          "node_id": "sha256:e7j6f5g1h2...",
          "element_type": "causal_links",
          "value": {
            "cause": "alta tasa de VBG",
            "effect": "baja autonomía económica de las mujeres",
            "connector": "genera",
            "criticality_score": 0.87
          },
          "confidence": 0.83,
          "source_method": "text_mining.diagnose_critical_links",
          "source_data": {
            "sentence_id": 48,
            "full_text": "La alta tasa de VBG genera baja autonomía económica de las mujeres",
            "coherence_analysis": {
              "coherence_score": 0.82,
              "supporting_sentences": 2,
              "contradicting_sentences": 0
            }
          },
          "relationships": ["sha256:b4g3c2...", "sha256:f8k7g6..."],
          "metadata": {
            "created_by_step": 1,
            "validated_by_step": 2
          }
        },
        {
          "node_id": "sha256:f8k7g6h3i4...",
          "element_type": "financial_amounts",
          "value": {
            "amount_cop": 850000000.0,
            "formatted": "$850.000.000 COP",
            "category": "recursos_propios"
          },
          "confidence": 0.94,
          "source_method": "pdet_analysis.extract_financial_amounts",
          "source_data": {
            "raw_text": "$850 millones",
            "parsing_confidence": 0.96,
            "categorization_confidence": 0.92,
            "sentence_id": 67
          },
          "relationships": [],
          "metadata": {
            "created_by_step": 9,
            "budget_line": "Promoción de la mujer y equidad de género"
          }
        }
      ],
      "by_type": {
        "fuentes_oficiales": 5,
        "indicadores_cuantitativos": 12,
        "series_temporales_años": 4,
        "cobertura_territorial_especificada": 1,
        "financial_amounts": 8,
        "policy_goals": 7,
        "causal_links": 5,
        "pattern_matches": 28,
        "quantitative_claims": 12,
        "bayesian_metrics": 10
      },
      "confidence_scores": {
        "mean": 0.876,
        "std": 0.089,
        "min": 0.72,
        "max": 0.98,
        "by_method": {
          "TextMiningEngine": 0.83,
          "IndustrialPolicyProcessor": 0.91,
          "CausalExtractor": 0.79,
          "FinancialAuditor": 0.94,
          "PDETMunicipalPlanAnalyzer": 0.88,
          "PolicyContradictionDetector": 0.90,
          "BayesianNumericalAnalyzer": 0.92,
          "SemanticProcessor": 0.85
        }
      },
      "graph_hash": "sha256:abc123def456...",
      "relationships": [
        {
          "source_node": "sha256:a3f2b1...",
          "target_node": "sha256:b4g3c2...",
          "edge_type": "SUPPORTS",
          "weight": 0.95,
          "metadata": {
            "inference_method": "provenance_link",
            "confidence": 0.95,
            "reasoning": "Source DANE supports indicator value"
          }
        },
        {
          "source_node": "sha256:e7j6f5...",
          "target_node": "sha256:b4g3c2...",
          "edge_type": "CAUSES",
          "weight": 0.87,
          "metadata": {
            "inference_method": "causal_link_extraction",
            "confidence": 0.83,
            "reasoning": "Extracted causal relationship from text"
          }
        }
      ],
      "aggregated_outputs": {
        "critical_links_summary": {
          "total_links": 5,
          "high_criticality_count": 2,
          "avg_criticality": 0.78
        },
        "financial_summary": {
          "total_budget_cop": 850000000.0,
          "amounts_found": 12,
          "by_category": {
            "SGR": 250000000.0,
            "recursos_propios": 180000000.0,
            "transferencias": 320000000.0,
            "otros": 100000000.0
          }
        },
        "goals_summary": {
          "total_goals": 7,
          "quantified_goals": 5,
          "goals_with_complete_context": 4,
          "goals_linked_to_baseline": 3
        },
        "contradictions_summary": {
          "contradictions_found": 0,
          "tests_performed": 15,
          "interpretation": "No statistical contradictions detected in quantitative claims"
        },
        "bayesian_insights": {
          "metrics_with_high_uncertainty": [],
          "metrics_needing_more_data": ["tasa de embarazo adolescente"],
          "comparison_results": {}
        }
      },
      "validation_report": {
        "valid": true,
        "consistency_score": 0.91,
        "errors": [],
        "warnings": [
          "Some goals lack direct linkage to baseline indicators"
        ],
        "completeness_assessment": {
          "cobertura_territorial": "complete",
          "fuentes_oficiales": "sufficient",
          "indicadores_cuantitativos": "sufficient",
          "series_temporales": "sufficient"
        }
      }
    },
    "validation_against_expected_elements": {
      "cobertura_territorial_especificada": {
        "required": true,
        "found_in_example": true,
        "count": 1,
        "status": "PASS",
        "example_node_id": "sha256:d6i5e4..."
      },
      "fuentes_oficiales": {
        "minimum": 2,
        "found_in_example": 5,
        "status": "PASS",
        "severity": "HIGH"
      },
      "indicadores_cuantitativos": {
        "minimum": 3,
        "found_in_example": 12,
        "status": "PASS",
        "severity": "HIGH"
      },
      "series_temporales_años": {
        "minimum": 3,
        "found_in_example": 4,
        "status": "PASS",
        "severity": "MEDIUM"
      },
      "overall_validation_result": "PASS - All required and minimum elements present with sufficient confidence"
    },
    "template_variable_bindings": {
      "description": "Variables available from EvidenceNexus output for template rendering",
      "variables": {
        "{evidence.elements_count}": "72 (total nodes in evidence graph)",
        "{graph_statistics.node_count}": "72",
        "{graph_statistics.edge_count}": "142",
        "{overall_confidence}": "0.876 (weighted mean after belief propagation)",
        "{completeness}": "complete",
        "{score}": "2.8 (calculated by Phase 3 scorer from overall_confidence and completeness)",
        "{quality_level}": "ALTO",
        "{evidence.by_type.fuentes_oficiales}": "5",
        "{evidence.by_type.indicadores_cuantitativos}": "12",
        "{evidence.by_type.series_temporales_años}": "4",
        "{evidence.by_type.cobertura_territorial_especificada}": "1",
        "{evidence.confidence_scores.mean}": "0.876",
        "{evidence.confidence_scores.std}": "0.089",
        "{synthesized_answer.gaps}": "['Falta desagregación por zona rural/urbana para algunos indicadores', 'No se especifica metodología de recolección para datos de VBG']",
        "{financial_summary.total_budget_cop}": "850000000.0",
        "{critical_links_summary.total_links}": "5",
        "{goals_summary.goals_linked_to_baseline}": "3",
        "{contradictions_summary.contradictions_found}": "0",
        "{validation_report.completeness_assessment}": "{'cobertura_territorial': 'complete', 'fuentes_oficiales': 'sufficient', ...}"
      }
    },
    "usage_notes": {
      "for_developers": "This structure is the actual output after BaseExecutorWithContract._execute_v3() → EvidenceNexus.process() → ValidationEngine.validate() → DoctoralCarverSynthesizer.synthesize() completes. Developers should expect: (1) evidence dict with elements array (nodes), by_type counts, relationships array (edges), graph_hash, (2) validation dict with valid boolean and completeness_assessment, (3) synthesized_answer dict with narrative and gap analysis, (4) human_readable_output string (Markdown), (5) overall_confidence float, (6) completeness enum, (7) graph_statistics dict.",
      "for_validators": "Verify actual execution produces all required fields in output_contract.schema. Check: elements array has ≥10 nodes, by_type matches expected_elements minimums, confidence_scores.mean ≥ 0.5, validation.valid = true, completeness != 'insufficient', graph_hash is valid SHA-256.",
      "for_auditors": "Full traceability chain: method outputs (17 steps) → EvidenceNode objects (SHA-256 IDs) → evidence graph (nodes + edges) → belief propagation (Dempster-Shafer) → validation report → doctoral narrative (Carver synthesis). Each node has source_method and source_data for provenance. Each edge has inference_method and reasoning.",
      "architecture_notes": "EvidenceAssembler (legacy) is REPLACED by EvidenceNexus (graph-native). Manual assembly_rules from contracts v1/v2 are REPLACED by automatic graph construction from method output types. Template-based synthesis is REPLACED by DoctoralCarverSynthesizer (neural + rule-based narrative generation). Confidence combination uses Dempster-Shafer (not naive averaging)."
    }
  },
  "traceability": {
    "source_file": "data/questionnaire_monolith.json",
    "json_path": "blocks.micro_questions[270]",
    "method_source": "src/farfan_core/core/orchestrator/executors.py:D1_Q1_Executor",
    "method_mapping_source": "executor_methods_mapping.json",
    "ontology_source": "config/canonical_ontologies/policy_areas_and_dimensions.json",
    "source_hash": "TODO_SHA256_HASH_OF_QUESTIONNAIRE_MONOLITH",
    "contract_generation_method": "automated_specialization_from_monolith",
    "contract_author": "F.A.R.F.A.N Mechanistic Policy Pipeline",
    "provenance_note": "This contract was generated with full multi-method orchestration support. The method_binding.methods array contains all 17 methods from D1_Q1_Executor, execution_sequence documents dependencies, and human_answer_structure provides complete output specification.",
    "source_question_id": "Q001",
    "specialized_from_base_slot": "D1-Q1",
    "specialization_timestamp": "2025-11-28T03:49:29.779693+00:00",
    "last_revision": "2025-12-13T00:00:00.000000+00:00",
    "revision_notes": "Versión operativa completa: alineación método-output, secuencia de ejecución con dependencias, estructura completa de evidencia post-Nexus con ejemplos concretos, template de output humano, fundamentación metodológica de 17 métodos",
    "revision_author": "System Architecture Review"
  },
  "error_handling": {
    "on_method_not_found": "raise",
    "on_method_failure": "propagate_with_trace",
    "on_assembly_failure": "propagate_with_trace",
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text",
        "confidence_below_threshold",
        "validation_critical_error"
      ],
      "emit_code": "ABORT-Q001-REQ",
      "fallback_behavior": "none"
    },
    "retry_policy": {
      "max_retries": 0,
      "retry_on": [],
      "note": "No automatic retries. Failures propagate for manual investigation."
    }
  },
  "fallback_strategy": {
    "use_llm_direct": false,
    "use_heuristics": false,
    "note": "No fallback strategies enabled. All failures propagate according to error_handling configuration. This ensures traceability and prevents contamination of evidence graph with unvalidated data."
  },
  "test_configuration": {
    "test_files": [
      "tests/core/orchestrator/test_executors_contract.py",
      "tests/core/phases/test_phase2.py",
      "tests/integration/test_d1_q1_full_pipeline.py"
    ],
    "test_document_fixtures": [
      "tests/fixtures/preprocessed_documents/sample_pdet_plan.json",
      "tests/fixtures/preprocessed_documents/municipio_gender_baseline_complete.json",
      "tests/fixtures/preprocessed_documents/municipio_gender_baseline_partial.json"
    ],
    "expected_test_coverage": ">=90%",
    "integration_test_required": true,
    "test_scenarios": [
      {
        "scenario": "complete_baseline",
        "fixture": "municipio_gender_baseline_complete.json",
        "expected_completeness": "complete",
        "expected_min_confidence": 0.85,
        "expected_node_count_range": [40, 80]
      },
      {
        "scenario": "partial_baseline",
        "fixture": "municipio_gender_baseline_partial.json",
        "expected_completeness": "partial",
        "expected_min_confidence": 0.60,
        "expected_validation_warnings": ["INSUFFICIENT_TEMPORAL_SERIES"]
      },
      {
        "scenario": "insufficient_baseline",
        "fixture": "municipio_no_gender_data.json",
        "expected_completeness": "insufficient",
        "expected_validation_errors": ["MISSING_TERRITORIAL_COVERAGE", "INSUFFICIENT_SOURCES"]
      }
    ]
  },
  "compatibility": {
    "orchestrator_min_version": "3.0.0",
    "signal_registry_min_version": "3.0.0",
    "method_executor_min_version": "3.0.0",
    "questionnaire_monolith_version": "3.0.0",
    "phase2_types_version": "3.0.0",
    "evidence_nexus_min_version": "3.0.0",
    "validation_engine_min_version": "3.0.0",
    "carver_synthesizer_min_version": "3.0.0"
  },
  "calibration": {
    "status": "placeholder",
    "note": "Contract does not embed calibration scores. Actual calibration managed via src/farfan_core/core/calibration/ + config/intrinsic_calibration.json + config/fusion_specification.json",
    "source": {
      "intrinsic_calibration": "config/intrinsic_calibration.json",
      "fusion_specification": "config/fusion_specification.json",
      "layer_calibrations_dir": "config/layer_calibrations/",
      "canonical_spec": "canonic_calibration_methods.md"
    },
    "method_reliability_weights": {
      "TextMiningEngine": 0.85,
      "IndustrialPolicyProcessor": 0.90,
      "CausalExtractor": 0.80,
      "FinancialAuditor": 0.95,
      "PDETMunicipalPlanAnalyzer": 0.90,
      "PolicyContradictionDetector": 0.92,
      "BayesianNumericalAnalyzer": 0.95,
      "SemanticProcessor": 0.85
    },
    "confidence_aggregation_formula": "weighted_mean with Dempster-Shafer combination for conflicting evidence",
    "calibration_targets": {
      "overall_confidence_correlation_with_human_scores": 0.85,
      "false_positive_rate_contradictions": 0.05,
      "recall_critical_baseline_elements": 0.95
    }
  }
}