{
  "identity": {
    "base_slot": "D1-Q5",
    "question_id": "Q005",
    "dimension_id": "DIM01",
    "policy_area_id": "PA01",
    "contract_version": "3.0.0",
    "contract_hash": "3d69d1deea4aa01e2402e7e47c0aae0d58725fd28b9f294ac74f68ecbcfccaae",
    "created_at": "2025-11-28T03:49:29.794908+00:00",
    "validated_against_schema": "executor_contract.v3.schema.json",
    "cluster_id": "CL02",
    "question_global": 5
  },
  "executor_binding": {
    "executor_class": "D1_Q5_Executor",
    "executor_module": "farfan_core.core.orchestrator.executors"
  },
  "method_binding": {
    "orchestration_mode": "multi_method_pipeline",
    "method_count": 7,
    "methods": [
      {
        "class_name": "TemporalLogicVerifier",
        "method_name": "_check_deadline_constraints",
        "priority": 1,
        "provides": "temporallogicverifier.check_deadline_constraints",
        "role": "_check_deadline_constraints_execution",
        "description": "TemporalLogicVerifier._check_deadline_constraints"
      },
      {
        "class_name": "TemporalLogicVerifier",
        "method_name": "verify_temporal_consistency",
        "priority": 2,
        "provides": "temporallogicverifier.verify_temporal_consistency",
        "role": "verify_temporal_consistency_execution",
        "description": "TemporalLogicVerifier.verify_temporal_consistency"
      },
      {
        "class_name": "CausalInferenceSetup",
        "method_name": "identify_failure_points",
        "priority": 3,
        "provides": "causalinferencesetup.identify_failure_points",
        "role": "identify_failure_points_execution",
        "description": "CausalInferenceSetup.identify_failure_points"
      },
      {
        "class_name": "CausalExtractor",
        "method_name": "_assess_temporal_coherence",
        "priority": 4,
        "provides": "causal_extraction.assess_temporal_coherence",
        "role": "_assess_temporal_coherence_execution",
        "description": "CausalExtractor._assess_temporal_coherence"
      },
      {
        "class_name": "TextMiningEngine",
        "method_name": "_analyze_link_text",
        "priority": 5,
        "provides": "text_mining.analyze_link_text",
        "role": "_analyze_link_text_analysis",
        "description": "TextMiningEngine._analyze_link_text"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_analyze_causal_dimensions",
        "priority": 6,
        "provides": "industrial_policy.analyze_causal_dimensions",
        "role": "_analyze_causal_dimensions_analysis",
        "description": "IndustrialPolicyProcessor._analyze_causal_dimensions"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_extract_metadata",
        "priority": 7,
        "provides": "industrial_policy.extract_metadata",
        "role": "_extract_metadata_extraction",
        "description": "IndustrialPolicyProcessor._extract_metadata"
      }
    ],
    "note": "All 7 methods extracted from D1_Q5_Executor in executors.py"
  },
  "question_context": {
    "question_text": "¿El plan justifica su alcance en materia de género mencionando el marco legal (ej. Ley 1257) o reconociendo restricciones explícitas de tipo presupuestal, temporal o de competencias?",
    "question_type": "micro",
    "scoring_modality": "TYPE_E",
    "modality": "count_and_scale",
    "expected_output_type": "score",
    "patterns": [
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-000",
        "match_type": "REGEX",
        "pattern": "en el marco de la Ley 1257 de 2018|Decreto 1630"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-001",
        "match_type": "REGEX",
        "pattern": "Política Pública Nacional de Equidad de Género|PPEG"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-002",
        "match_type": "REGEX",
        "pattern": "CONPES de equidad de género"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-003",
        "match_type": "LITERAL",
        "pattern": "sentencia T-|Corte Constitucional"
      },
      {
        "category": "TERRITORIAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-004",
        "match_type": "REGEX",
        "pattern": "Acuerdo Municipal|Decreto Municipal"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-005",
        "match_type": "REGEX",
        "pattern": "competencias del municipio en VBG|responsabilidad subsidiaria"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-006",
        "match_type": "REGEX",
        "pattern": "límite fiscal|disponibilidad de recursos del SGP"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-007",
        "match_type": "LITERAL",
        "pattern": "presupuesto insuficiente para|restricción presupuestal"
      },
      {
        "category": "TEMPORAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-008",
        "match_type": "REGEX",
        "pattern": "durante el cuatrienio|en el periodo 2024-2027|plazo de implementación"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q005-009",
        "match_type": "REGEX",
        "pattern": "coherencia entre metas y recursos|factibilidad financiera"
      }
    ],
    "expected_elements": [
      {
        "required": true,
        "type": "coherencia_demostrada"
      },
      {
        "required": true,
        "type": "restricciones_legales"
      },
      {
        "required": true,
        "type": "restricciones_presupuestales"
      },
      {
        "required": true,
        "type": "restricciones_temporales"
      }
    ],
    "validations": {}
  },
  "signal_requirements": {
    "mandatory_signals": [
      "baseline_completeness",
      "data_sources",
      "gender_baseline_data",
      "policy_coverage",
      "vbg_statistics"
    ],
    "optional_signals": [
      "geographic_scope",
      "source_validation",
      "temporal_coverage",
      "temporal_series",
      "territorial_scope"
    ],
    "signal_aggregation": "weighted_mean",
    "minimum_signal_threshold": 0.5,
    "note": "Signal requirements are currently under development. Signal IDs will be populated once the signal_registry provides a canonical mapping for PA01/DIM01."
  },
  "evidence_assembly": {
    "module": "farfan_core.core.orchestrator.evidence_assembler",
    "class_name": "EvidenceAssembler",
    "method_name": "assemble",
    "output_schema": {
      "type": "object",
      "required": [
        "elements",
        "raw_results"
      ],
      "properties": {
        "elements": {
          "type": "array",
          "description": "Lista de elementos de evidencia encontrados para esta micro-pregunta."
        },
        "raw_results": {
          "type": "object",
          "properties": {
            "confidence_scores": {
              "type": "array",
              "description": "Scores de confianza usados por el scorer."
            },
            "semantic_similarity": {
              "description": "Métrica de similitud semántica (si aplica)."
            },
            "pattern_matches": {
              "type": "object",
              "description": "Matches de patrones esperados vs texto."
            },
            "metadata": {
              "type": "object",
              "description": "Metadatos arbitrarios pasados al scorer."
            }
          },
          "additionalProperties": true
        }
      },
      "additionalProperties": true
    },
    "assembly_rules": [
      {
        "target": "elements_found",
        "sources": [
          "temporallogicverifier.check_deadline_constraints",
          "temporallogicverifier.verify_temporal_consistency",
          "causalinferencesetup.identify_failure_points",
          "causal_extraction.assess_temporal_coherence",
          "text_mining.analyze_link_text",
          "industrial_policy.analyze_causal_dimensions",
          "industrial_policy.extract_metadata"
        ],
        "merge_strategy": "concat",
        "description": "Combine all evidence elements from 7 method invocations"
      },
      {
        "target": "confidence_scores",
        "sources": [
          "*.confidence",
          "*.bayesian_posterior"
        ],
        "merge_strategy": "weighted_mean",
        "default": [],
        "description": "Aggregate confidence scores across all methods"
      },
      {
        "target": "pattern_matches",
        "sources": [
          "text_mining.analyze_link_text",
          "industrial_policy.analyze_causal_dimensions"
        ],
        "merge_strategy": "concat",
        "default": {},
        "description": "Combine pattern matches from text mining methods"
      },
      {
        "target": "metadata",
        "sources": [
          "*.metadata"
        ],
        "merge_strategy": "concat",
        "description": "Combine metadata from all 7 methods for full traceability"
      }
    ]
  },
  "output_contract": {
    "result_type": "Phase2QuestionResult",
    "schema": {
      "type": "object",
      "required": [
        "base_slot",
        "question_id",
        "question_global",
        "evidence",
        "validation"
      ],
      "properties": {
        "base_slot": {
          "type": "string",
          "description": "Debe coincidir con identity.base_slot.",
          "const": "D1-Q5"
        },
        "question_id": {
          "type": "string",
          "description": "Debe coincidir con identity.question_id.",
          "const": "Q005"
        },
        "question_global": {
          "type": "integer",
          "description": "Índice global de la pregunta (de questionnaire_monolith).",
          "const": 5
        },
        "policy_area_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "PA canónica, debe ser coherente con identity.policy_area_id.",
          "const": "PA01"
        },
        "dimension_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Dimensión canónica, coherente con identity.dimension_id.",
          "const": "DIM01"
        },
        "cluster_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Cluster de análisis según el monolith, si aplica.",
          "const": "CL02"
        },
        "evidence": {
          "type": [
            "object",
            "null"
          ],
          "description": "Objeto de evidencia ensamblado por el EvidenceAssembler; debe cumplir evidence_assembly.output_schema.",
          "additionalProperties": true
        },
        "validation": {
          "type": [
            "object",
            "null"
          ],
          "description": "Resultado de validaciones lógicas de la respuesta (coherencia, integridad, etc.).",
          "additionalProperties": true
        },
        "trace": {
          "type": [
            "object",
            "null"
          ],
          "description": "Información de trazabilidad (provenance, logs) específica de la ejecución.",
          "additionalProperties": true
        },
        "metadata": {
          "type": [
            "object",
            "null"
          ],
          "description": "Metadatos adicionales de la pregunta para consumo posterior.",
          "additionalProperties": true
        }
      },
      "additionalProperties": false
    },
    "consumer_modules": [
      "src.farfan_core.core.phases.phase2_types.validate_phase2_result",
      "src.farfan_core.core.orchestrator.core.Orchestrator._score_micro_results_async",
      "src.farfan_core.analysis.scoring.MicroQuestionScorer"
    ],
    "human_readable_output": {
      "format": "markdown",
      "template": {
        "title": "## Análisis D1-Q5: Justificación de Alcance con Marco Legal y Restricciones",
        "summary": "### Resumen Ejecutivo\n\nSe analizó la presencia de **{evidence.elements_found_count}** elementos de evidencia relacionados con la justificación del alcance del plan en materia de género, incluyendo referencias al marco legal y reconocimiento de restricciones.\n\n**Puntaje**: {score}/3.0 | **Calidad**: {quality_level}",
        "score_section": "### Evaluación Cuantitativa\n\n- **Puntaje bruto**: {score}/3.0\n- **Nivel de calidad**: {quality_level}\n- **Confianza promedio**: {evidence.confidence_scores.mean}%\n- **Cobertura de patrones**: {evidence.pattern_matches_count}/10 patrones detectados",
        "elements_section": "### Elementos de Evidencia Identificados\n\n{evidence.elements_found_list}\n\n**Elementos críticos faltantes**: {evidence.missing_required_elements}",
        "details": [
          "**Referencias legales identificadas**: {evidence.legal_references_count}",
          "**Restricciones presupuestales**: {evidence.budget_constraints_count}",
          "**Restricciones temporales**: {evidence.temporal_constraints_count}",
          "**Coherencia justificada**: {evidence.coherence_demonstrated}"
        ],
        "interpretation": "### Interpretación de Resultados\n\n{methodological_interpretation}",
        "recommendations": "### Recomendaciones\n\n{evidence.recommendations}"
      },
      "methodological_depth": {
        "methods": [
          {
            "method_name": "_check_deadline_constraints",
            "class_name": "TemporalLogicVerifier",
            "priority": 1,
            "role": "_check_deadline_constraints_execution",
            "epistemological_foundation": {
              "paradigm": "Temporal logic and constraint satisfaction",
              "ontological_basis": "Policy documents contain explicit and implicit temporal commitments that must be internally consistent. Deadlines form a constraint network where violations signal planning incoherence.",
              "epistemological_stance": "Formalist-computational: temporal constraints are verifiable logical propositions that can be checked mechanically",
              "theoretical_framework": [
                "Temporal constraint satisfaction problems (Dechter et al., 1991)",
                "Allen's interval algebra for temporal reasoning",
                "Logic-based policy coherence verification"
              ],
              "justification": "Deadline constraints reveal whether the plan's timeline is internally consistent and feasible given stated temporal restrictions. Violations indicate unrealistic planning or scope misalignment."
            },
            "technical_approach": {
              "method_type": "constraint_verification",
              "algorithm": "Extract temporal intervals, construct constraint graph, verify consistency via path consistency algorithm",
              "steps": [
                {
                  "step": 1,
                  "description": "Parse temporal expressions (deadlines, durations, sequences) from document"
                },
                {
                  "step": 2,
                  "description": "Construct temporal constraint network with intervals as nodes"
                },
                {
                  "step": 3,
                  "description": "Check for constraint violations via path consistency algorithm"
                },
                {
                  "step": 4,
                  "description": "Report violated constraints with severity scores"
                }
              ],
              "assumptions": [
                "Temporal expressions follow standard formats (dates, durations)",
                "Implicit temporal constraints can be inferred from context",
                "Violated constraints indicate planning problems"
              ],
              "limitations": [
                "Cannot detect implicit temporal dependencies not linguistically marked",
                "Assumes temporal expressions are accurate (not aspirational)",
                "May miss temporal constraints stated in external documents"
              ],
              "complexity": "O(n^3) where n=number of temporal intervals (path consistency algorithm)"
            },
            "output_interpretation": {
              "output_structure": {
                "constraints_checked": "List of temporal constraints extracted",
                "violations": "List of constraint violations with severity",
                "consistency_score": "Overall temporal consistency (0-1)"
              },
              "interpretation_guide": {
                "high_consistency": "≥0.8: Timeline is feasible and internally consistent",
                "medium_consistency": "0.5-0.79: Some temporal tensions, may need adjustment",
                "low_consistency": "<0.5: Significant temporal conflicts, plan likely infeasible"
              },
              "actionable_insights": [
                "Violated deadlines indicate scope-timeline misalignment",
                "High violation density suggests unrealistic planning or poor constraint awareness"
              ]
            }
          },
          {
            "method_name": "verify_temporal_consistency",
            "class_name": "TemporalLogicVerifier",
            "priority": 2,
            "role": "verify_temporal_consistency_verification",
            "epistemological_foundation": {
              "paradigm": "Modal temporal logic verification",
              "ontological_basis": "Policy commitments have temporal modalities (before, after, during) that must satisfy logical consistency rules. Temporal inconsistency reveals conceptual confusion.",
              "epistemological_stance": "Logical-formal: temporal consistency is a necessary condition for policy coherence, verifiable through modal logic",
              "theoretical_framework": [
                "Linear temporal logic (LTL) for policy verification",
                "Modal logic for temporal relations (Prior, 1957)",
                "Formal verification of planning documents"
              ],
              "justification": "Temporal consistency verification detects logical contradictions in the plan's temporal structure, revealing whether policymakers understand temporal constraints and dependencies."
            },
            "technical_approach": {
              "method_type": "modal_logic_verification",
              "algorithm": "Extract temporal claims, formalize as LTL propositions, check satisfiability via model checking",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract temporal claims with modal operators (before, after, always, eventually)"
                },
                {
                  "step": 2,
                  "description": "Formalize claims as Linear Temporal Logic (LTL) formulas"
                },
                {
                  "step": 3,
                  "description": "Check satisfiability using bounded model checking"
                },
                {
                  "step": 4,
                  "description": "Identify unsatisfiable formula sets (temporal contradictions)"
                }
              ],
              "assumptions": [
                "Temporal claims can be formalized as LTL propositions",
                "Model checking is tractable within document scope",
                "Contradictions indicate genuine conceptual errors"
              ],
              "limitations": [
                "Complexity grows exponentially with formula nesting depth",
                "Cannot verify claims dependent on external state",
                "May produce false positives from ambiguous language"
              ],
              "complexity": "O(2^k * n) where k=formula depth, n=document length (model checking)"
            },
            "output_interpretation": {
              "output_structure": {
                "temporal_claims": "List of formalized temporal propositions",
                "contradictions": "Unsatisfiable formula sets",
                "consistency_verdict": "Boolean: consistent or inconsistent"
              },
              "interpretation_guide": {
                "consistent": "All temporal claims are mutually satisfiable",
                "inconsistent": "Logical contradictions detected in temporal structure"
              },
              "actionable_insights": [
                "Contradictions reveal conceptual confusion about temporal dependencies",
                "Consistent but unrealistic timelines suggest poor constraint awareness"
              ]
            }
          },
          {
            "method_name": "identify_failure_points",
            "class_name": "CausalInferenceSetup",
            "priority": 3,
            "role": "identify_failure_points_identification",
            "epistemological_foundation": {
              "paradigm": "Causal graph analysis and failure mode detection",
              "ontological_basis": "Policy plans implicitly define causal graphs where interventions produce outcomes. Failure points are nodes or edges where causal mechanisms are vulnerable to breakdown.",
              "epistemological_stance": "Structural-causal: failures arise from causal structure vulnerabilities, identifiable via graph analysis and counterfactual reasoning",
              "theoretical_framework": [
                "Causal graph analysis (Pearl, 2009)",
                "Failure Mode and Effects Analysis (FMEA)",
                "Counterfactual reasoning for policy evaluation"
              ],
              "justification": "Identifying failure points reveals where the plan's causal logic is fragile, enabling proactive risk mitigation and realistic scope setting."
            },
            "technical_approach": {
              "method_type": "causal_graph_vulnerability_analysis",
              "algorithm": "Construct causal DAG from policy document, identify high-criticality nodes via centrality metrics and counterfactual fragility",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract causal claims and construct directed acyclic graph (DAG)"
                },
                {
                  "step": 2,
                  "description": "Calculate node criticality via betweenness centrality and reachability metrics"
                },
                {
                  "step": 3,
                  "description": "Simulate interventions and counterfactuals to identify fragile edges"
                },
                {
                  "step": 4,
                  "description": "Rank failure points by impact and likelihood"
                }
              ],
              "assumptions": [
                "Causal structure can be extracted from linguistic patterns",
                "Node criticality correlates with failure risk",
                "Counterfactual simulations approximate real failure modes"
              ],
              "limitations": [
                "Cannot detect failures from unmentioned causal factors",
                "Centrality metrics may not capture domain-specific vulnerability",
                "Simulations assume causal graph completeness"
              ],
              "complexity": "O(V + E) for graph construction, O(V^3) for all-pairs shortest paths (betweenness)"
            },
            "output_interpretation": {
              "output_structure": {
                "causal_graph": "DAG with nodes (mechanisms) and edges (causal links)",
                "failure_points": "Ranked list of vulnerable nodes/edges",
                "criticality_scores": "Impact scores per failure point"
              },
              "interpretation_guide": {
                "high_criticality": "≥0.8: Failure here collapses entire causal chain",
                "medium_criticality": "0.5-0.79: Failure degrades outcomes but recoverable",
                "low_criticality": "<0.5: Failure has localized impact"
              },
              "actionable_insights": [
                "High-criticality nodes should have explicit contingency plans",
                "Multiple failure points in sequence indicate brittle design"
              ]
            }
          },
          {
            "method_name": "_assess_temporal_coherence",
            "class_name": "CausalExtractor",
            "priority": 4,
            "role": "_assess_temporal_coherence_execution",
            "epistemological_foundation": {
              "paradigm": "Temporal coherence in causal narratives",
              "ontological_basis": "Causal claims have implicit temporal orderings (causes precede effects). Temporal incoherence in causal narratives signals conceptual confusion or post-hoc rationalization.",
              "epistemological_stance": "Narrative-causal: coherent causality requires temporally ordered sequences; violations undermine epistemic trustworthiness",
              "theoretical_framework": [
                "Temporal precedence in causality (Granger, 1969)",
                "Narrative coherence theory (Bruner, 1991)",
                "Causal process tracing in policy analysis"
              ],
              "justification": "Assessing temporal coherence of causal claims distinguishes genuine causal understanding from rhetorical causality (post-hoc storytelling without temporal logic)."
            },
            "technical_approach": {
              "method_type": "temporal_ordering_verification",
              "algorithm": "Extract causal links with temporal markers, verify cause-precedes-effect ordering, score coherence based on violations",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract causal links (cause → effect pairs) with temporal context"
                },
                {
                  "step": 2,
                  "description": "Identify temporal markers (before, after, during) for each entity"
                },
                {
                  "step": 3,
                  "description": "Verify temporal precedence: does cause timestamp < effect timestamp?"
                },
                {
                  "step": 4,
                  "description": "Score coherence as (valid_orderings / total_links)"
                }
              ],
              "assumptions": [
                "Temporal markers accurately reflect entity timing",
                "Causes must temporally precede effects (no simultaneous causation)",
                "Coherence violations indicate conceptual errors"
              ],
              "limitations": [
                "Cannot detect implicit temporal orderings without linguistic markers",
                "May misinterpret simultaneous causation as incoherent",
                "Assumes all causal claims have extractable temporal context"
              ],
              "complexity": "O(n*m) where n=causal links, m=average temporal markers per link"
            },
            "output_interpretation": {
              "output_structure": {
                "causal_links_assessed": "List of cause-effect pairs with temporal data",
                "coherence_violations": "Links where temporal ordering is violated",
                "coherence_score": "Proportion of temporally coherent links (0-1)"
              },
              "interpretation_guide": {
                "high_coherence": "≥0.8: Causal narrative is temporally sound",
                "medium_coherence": "0.5-0.79: Some temporal inconsistencies present",
                "low_coherence": "<0.5: Causal narrative is temporally confused or post-hoc"
              },
              "actionable_insights": [
                "Low coherence suggests post-hoc rationalization rather than genuine causal analysis",
                "Violation clusters may indicate conceptual blind spots"
              ]
            }
          },
          {
            "method_name": "_analyze_link_text",
            "class_name": "TextMiningEngine",
            "priority": 5,
            "role": "_analyze_link_text_analysis",
            "epistemological_foundation": {
              "paradigm": "Contextual semantic analysis",
              "ontological_basis": "The meaning and validity of a causal claim depends on its textual context (surrounding sentences, semantic coherence)",
              "epistemological_stance": "Coherentist: A causal link is epistemically justified if it coheres with surrounding textual evidence",
              "theoretical_framework": [
                "Semantic coherence theory: Valid claims are embedded in coherent semantic contexts",
                "Evidential reasoning: Context provides supporting or undermining evidence for causal claims"
              ],
              "justification": "Detecting a causal connector alone is insufficient; analyzing surrounding text validates whether the link is substantive or superficial"
            },
            "technical_approach": {
              "method_type": "context_window_semantic_analysis",
              "algorithm": "Extract ±N sentences around link, analyze semantic consistency",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract context window (±3 sentences) around detected causal link"
                },
                {
                  "step": 2,
                  "description": "Calculate semantic similarity between link and context using embeddings"
                },
                {
                  "step": 3,
                  "description": "Identify supporting/contradicting evidence in context"
                }
              ],
              "assumptions": [
                "Coherent contexts indicate valid causal claims",
                "Context window of ±3 sentences captures relevant information"
              ],
              "limitations": [
                "May miss long-range dependencies beyond context window",
                "Semantic similarity doesn't guarantee logical validity"
              ],
              "complexity": "O(k*w) where k=links, w=context window size"
            },
            "output_interpretation": {
              "output_structure": {
                "context_coherence_score": "Semantic coherence metric (0-1)",
                "supporting_evidence": "Contextual sentences that support the link",
                "contradicting_evidence": "Contextual sentences that contradict the link"
              },
              "interpretation_guide": {
                "high_coherence": "≥0.7: Link is well-supported by context",
                "low_coherence": "<0.5: Link may be spurious or poorly contextualized"
              },
              "actionable_insights": [
                "Low coherence + many links: Document has scattered causal claims without substantiation",
                "High coherence: Causal claims are evidence-based and well-argued"
              ]
            }
          },
          {
            "method_name": "_analyze_causal_dimensions",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 6,
            "role": "_analyze_causal_dimensions_analysis",
            "epistemological_foundation": {
              "paradigm": "Multi-dimensional causal analysis",
              "ontological_basis": "Policy causality operates across multiple dimensions (temporal, spatial, institutional, financial). Single-dimension analysis misses cross-dimensional dependencies.",
              "epistemological_stance": "Systems-theoretic: causal mechanisms are multi-dimensional; understanding requires analyzing dimensions separately and interactions jointly",
              "theoretical_framework": [
                "Systems theory: complex causality emerges from dimension interactions",
                "Multi-level analysis in policy science (Ostrom, 2005)",
                "Cross-cutting dimensions in institutional analysis"
              ],
              "justification": "Analyzing causal dimensions separately reveals whether constraints in one dimension (e.g., budget) are acknowledged when discussing another (e.g., scope), revealing planning realism."
            },
            "technical_approach": {
              "method_type": "dimensional_decomposition_analysis",
              "algorithm": "Extract causal claims per dimension (legal, budget, temporal, institutional), analyze cross-dimensional coherence",
              "steps": [
                {
                  "step": 1,
                  "description": "Classify causal claims by dimension using keyword matching and NER"
                },
                {
                  "step": 2,
                  "description": "Analyze each dimension separately for internal coherence"
                },
                {
                  "step": 3,
                  "description": "Check cross-dimensional references: do budget claims acknowledge temporal constraints?"
                },
                {
                  "step": 4,
                  "description": "Score dimensional integration as proportion of cross-references"
                }
              ],
              "assumptions": [
                "Dimensions can be reliably classified via linguistic markers",
                "Cross-dimensional coherence indicates planning sophistication",
                "Dimension interactions are linguistically expressed"
              ],
              "limitations": [
                "Cannot detect implicit cross-dimensional dependencies",
                "Dimension taxonomy may not capture all relevant policy dimensions",
                "Assumes dimensions are orthogonal (may have conceptual overlap)"
              ],
              "complexity": "O(n*d) where n=claims, d=dimensions analyzed"
            },
            "output_interpretation": {
              "output_structure": {
                "dimensional_breakdown": "Claims per dimension (legal, budget, temporal, etc.)",
                "cross_references": "Claims that explicitly link multiple dimensions",
                "integration_score": "Proportion of multi-dimensional claims (0-1)"
              },
              "interpretation_guide": {
                "high_integration": "≥0.6: Plan explicitly connects dimensions (e.g., budget-timeline linkage)",
                "low_integration": "<0.3: Dimensions treated in isolation, missing dependencies"
              },
              "actionable_insights": [
                "Low integration suggests siloed planning (e.g., ambitious goals without budget reality)",
                "High integration indicates systems-aware planning"
              ]
            }
          },
          {
            "method_name": "_extract_metadata",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 7,
            "role": "_extract_metadata_extraction",
            "epistemological_foundation": {
              "paradigm": "Metadata-driven policy document analysis",
              "ontological_basis": "Policy documents contain structural metadata (sections, hierarchy, authorship markers) that reveal planning process and institutional context.",
              "epistemological_stance": "Document-as-artifact: structural features of the document reflect institutional capacity and planning maturity",
              "theoretical_framework": [
                "Document genre analysis: structure reveals institutional norms",
                "Digital forensics: metadata as process trace",
                "Institutional analysis via document artifacts"
              ],
              "justification": "Metadata extraction reveals document provenance, authorship patterns, and structural sophistication, which correlate with planning quality and legitimacy."
            },
            "technical_approach": {
              "method_type": "structural_metadata_extraction",
              "algorithm": "Parse document structure, extract metadata fields, analyze hierarchical organization and formatting patterns",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract document structure (sections, subsections, headings)"
                },
                {
                  "step": 2,
                  "description": "Parse metadata fields (author, date, version, institution)"
                },
                {
                  "step": 3,
                  "description": "Analyze hierarchical depth and organizational complexity"
                },
                {
                  "step": 4,
                  "description": "Identify formatting patterns (tables, lists, citations) as quality signals"
                }
              ],
              "assumptions": [
                "Metadata presence correlates with institutional capacity",
                "Structural sophistication indicates planning maturity",
                "Formatting patterns are reliable quality signals"
              ],
              "limitations": [
                "Metadata can be fabricated or incomplete",
                "Structural complexity doesn't guarantee content quality",
                "Formatting may reflect template use rather than genuine organization"
              ],
              "complexity": "O(n) where n=document elements (linear scan)"
            },
            "output_interpretation": {
              "output_structure": {
                "document_metadata": "Extracted fields (author, date, version, institution)",
                "structural_metrics": "Hierarchy depth, section count, formatting richness",
                "quality_indicators": "Presence of tables, citations, versioning"
              },
              "interpretation_guide": {
                "high_quality": "Rich metadata + deep hierarchy + citations: indicates mature planning",
                "low_quality": "Sparse metadata + flat structure: suggests rushed or low-capacity planning"
              },
              "actionable_insights": [
                "Missing metadata signals accountability gaps",
                "Flat structure may indicate copy-paste planning without adaptation"
              ]
            }
          }
        ],
        "method_combination_logic": {
          "combination_strategy": "Sequential multi-method pipeline with evidence fusion",
          "rationale": "Q005 requires analyzing justification of scope through multiple lenses: temporal logic (methods 1-2), causal reasoning (3-4), textual evidence (5), dimensional integration (6), and structural quality (7). Each method examines different aspects of justification quality.",
          "evidence_fusion": "Evidence from all 7 methods is aggregated by the EvidenceAssembler. Temporal logic violations, causal incoherence, weak contextual support, poor dimensional integration, and metadata gaps are combined to assess overall justification quality.",
          "confidence_aggregation": "Final confidence per evidence element = weighted_mean([confidence_method1, confidence_method2, ...]) where weights reflect method reliability for this question type (temporal methods have higher weight for Q005).",
          "execution_order": "Methods execute in priority order (1→7). Later methods can access outputs of earlier methods (e.g., method 6 uses causal links from method 4).",
          "trade_offs": [
            "Comprehensiveness vs. Complexity: 7 methods ensure thorough justification assessment but increase computational cost",
            "Precision vs. Recall: Multiple methods increase recall (find more justification elements) but may introduce redundancy; deduplication and confidence weighting mitigate this",
            "Interpretability vs. Sophistication: Temporal logic and causal analysis are powerful but less transparent than regex; methodological documentation compensates"
          ]
        }
      }
    }
  },
  "validation_rules": {
    "na_policy": "abort_on_critical",
    "rules": [
      {
        "field": "elements_found",
        "type": "array",
        "must_contain": {
          "count": 1,
          "elements": [
            "coherencia_demostrada",
            "restricciones_legales",
            "restricciones_presupuestales",
            "restricciones_temporales"
          ]
        },
        "description": "Derived from monolith expected_elements where required is true"
      },
      {
        "field": "elements_found",
        "type": "array",
        "should_contain": [
          {
            "elements": [
              "marco_legal_citado"
            ],
            "minimum": 1
          },
          {
            "elements": [
              "restricciones_explicitadas"
            ],
            "minimum": 2
          }
        ],
        "description": "Additional quality indicators for justification completeness"
      }
    ]
  },
  "traceability": {
    "source_file": "data/questionnaire_monolith.json",
    "json_path": "blocks.micro_questions[4]",
    "method_source": "src/farfan_core/core/orchestrator/executors.py:D1_Q5_Executor",
    "method_mapping_source": "executor_methods_mapping.json",
    "ontology_source": "config/canonical_ontologies/policy_areas_and_dimensions.json",
    "source_hash": "TODO_SHA256_HASH_OF_QUESTIONNAIRE_MONOLITH",
    "contract_generation_method": "automated_specialization_from_monolith",
    "contract_author": "F.A.R.F.A.N Mechanistic Policy Pipeline",
    "provenance_note": "This contract was generated with full multi-method orchestration support. The method_binding.methods array contains all 7 methods from D1_Q5_Executor, with substantive epistemological foundations replacing generic placeholders.",
    "source_question_id": "Q005",
    "specialized_from_base_slot": "D1-Q5",
    "specialization_timestamp": "2025-11-28T03:49:29.794948+00:00"
  },
  "error_handling": {
    "on_method_not_found": "raise",
    "on_method_failure": "propagate_with_trace",
    "on_assembly_failure": "propagate_with_trace",
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text"
      ],
      "emit_code": "ABORT-Q005-REQ"
    }
  },
  "fallback_strategy": {
    "use_llm_direct": false,
    "use_heuristics": false,
    "note": "No fallback strategies enabled. All failures propagate according to error_handling configuration."
  },
  "test_configuration": {
    "test_files": [
      "tests/core/orchestrator/test_executors_contract.py",
      "tests/core/phases/test_phase2.py"
    ],
    "test_document_fixtures": [
      "tests/fixtures/preprocessed_documents/sample_pdet_plan.json"
    ],
    "expected_test_coverage": ">=90%",
    "integration_test_required": true
  },
  "compatibility": {
    "orchestrator_min_version": "TODO_VERSION",
    "signal_registry_min_version": "TODO_VERSION",
    "method_executor_min_version": "TODO_VERSION",
    "questionnaire_monolith_version": "3.0.0",
    "phase2_types_version": "TODO_VERSION"
  },
  "calibration": {
    "status": "placeholder",
    "note": "Contract does not embed calibration scores. Actual calibration managed via src/farfan_core/core/calibration/ + config/intrinsic_calibration.json + config/fusion_specification.json",
    "source": {
      "intrinsic_calibration": "config/intrinsic_calibration.json",
      "fusion_specification": "config/fusion_specification.json",
      "layer_calibrations_dir": "config/layer_calibrations/",
      "canonical_spec": "canonic_calibration_methods.md"
    }
  },
  "human_answer_structure": {
    "description": "Expected structure of evidence dict after all 7 methods execute and evidence is assembled according to assembly_rules",
    "assembly_flow": {
      "step_1_method_execution": "7 methods execute in priority order, outputs stored with dot-notation keys",
      "step_2_evidence_assembly": "EvidenceAssembler merges outputs according to assembly_rules",
      "step_3_validation": "EvidenceValidator checks against validation_rules",
      "step_4_output_generation": "Phase2QuestionResult constructed with evidence, validation, trace"
    },
    "evidence_structure_schema": {
      "type": "object",
      "description": "Assembled evidence after all methods complete",
      "properties": {
        "elements_found": {
          "type": "array",
          "description": "Concatenated evidence elements from multiple methods (assembly_rules target)",
          "items": {
            "type": "object",
            "properties": {
              "element_id": {
                "type": "string",
                "example": "E-001"
              },
              "type": {
                "type": "string",
                "enum": [
                  "coherencia_demostrada",
                  "restricciones_legales",
                  "restricciones_presupuestales",
                  "restricciones_temporales",
                  "marco_legal_citado",
                  "restricciones_explicitadas"
                ]
              },
              "value": {
                "type": "string",
                "example": "Ley 1257 de 2008"
              },
              "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "source_method": {
                "type": "string",
                "example": "TemporalLogicVerifier._check_deadline_constraints"
              },
              "sentence_id": {
                "type": "integer"
              },
              "context": {
                "type": "string"
              }
            }
          },
          "example_count": "Expected 8-20 elements for a complete justification analysis"
        },
        "elements_summary": {
          "type": "object",
          "properties": {
            "total_count": {
              "type": "integer"
            },
            "by_type": {
              "type": "object",
              "properties": {
                "coherencia_demostrada": {
                  "type": "integer",
                  "minimum_expected": 1
                },
                "restricciones_legales": {
                  "type": "integer",
                  "minimum_expected": 1
                },
                "restricciones_presupuestales": {
                  "type": "integer",
                  "minimum_expected": 1
                },
                "restricciones_temporales": {
                  "type": "integer",
                  "minimum_expected": 1
                }
              }
            }
          }
        },
        "confidence_scores": {
          "type": "object",
          "description": "Aggregated confidence metrics (weighted_mean strategy)",
          "properties": {
            "mean": {
              "type": "number"
            },
            "std": {
              "type": "number"
            },
            "min": {
              "type": "number"
            },
            "max": {
              "type": "number"
            },
            "by_method": {
              "type": "object",
              "description": "Average confidence per analyzer class"
            }
          }
        },
        "pattern_matches": {
          "type": "array",
          "description": "Aggregated pattern matches from text mining methods",
          "items": {
            "type": "object",
            "properties": {
              "pattern_id": {
                "type": "string"
              },
              "count": {
                "type": "integer"
              },
              "avg_confidence": {
                "type": "number"
              }
            }
          }
        },
        "temporal_consistency": {
          "type": "object",
          "description": "Temporal logic verification results",
          "properties": {
            "constraints_checked": {
              "type": "integer"
            },
            "violations": {
              "type": "integer"
            },
            "consistency_score": {
              "type": "number"
            }
          }
        },
        "causal_coherence": {
          "type": "object",
          "description": "Causal analysis results",
          "properties": {
            "failure_points": {
              "type": "array"
            },
            "temporal_coherence_score": {
              "type": "number"
            }
          }
        },
        "dimensional_integration": {
          "type": "object",
          "description": "Cross-dimensional analysis results",
          "properties": {
            "dimensions_analyzed": {
              "type": "array"
            },
            "cross_references": {
              "type": "integer"
            },
            "integration_score": {
              "type": "number"
            }
          }
        },
        "metadata": {
          "type": "object",
          "properties": {
            "methods_executed": {
              "type": "integer",
              "const": 7
            },
            "execution_time_ms": {
              "type": "number"
            },
            "document_length": {
              "type": "integer"
            },
            "analysis_timestamp": {
              "type": "string",
              "format": "date-time"
            }
          }
        }
      }
    },
    "concrete_example": {
      "elements_found": [
        {
          "element_id": "E-001",
          "type": "restricciones_legales",
          "value": "Ley 1257 de 2008",
          "confidence": 0.95,
          "source_method": "TextMiningEngine._analyze_link_text",
          "source_sentence": "en el marco de la Ley 1257 de 2008",
          "sentence_id": 23,
          "position": {
            "start": 456,
            "end": 485
          }
        },
        {
          "element_id": "E-002",
          "type": "restricciones_presupuestales",
          "value": "límite fiscal municipal",
          "confidence": 0.88,
          "source_method": "IndustrialPolicyProcessor._analyze_causal_dimensions",
          "sentence_id": 67
        },
        {
          "element_id": "E-003",
          "type": "restricciones_temporales",
          "value": "cuatrienio 2024-2027",
          "confidence": 0.92,
          "source_method": "TemporalLogicVerifier._check_deadline_constraints"
        },
        {
          "element_id": "E-004",
          "type": "coherencia_demostrada",
          "value": "coherencia entre metas y recursos disponibles",
          "confidence": 0.85,
          "source_method": "CausalInferenceSetup.identify_failure_points"
        }
      ],
      "elements_summary": {
        "total_count": 15,
        "by_type": {
          "coherencia_demostrada": 2,
          "restricciones_legales": 4,
          "restricciones_presupuestales": 5,
          "restricciones_temporales": 4
        }
      },
      "confidence_scores": {
        "mean": 0.892,
        "std": 0.067,
        "min": 0.78,
        "max": 0.96,
        "by_method": {
          "TemporalLogicVerifier": 0.91,
          "CausalInferenceSetup": 0.87,
          "CausalExtractor": 0.84,
          "TextMiningEngine": 0.90,
          "IndustrialPolicyProcessor": 0.93
        }
      },
      "pattern_matches": [
        {
          "pattern_id": "PAT-Q005-000",
          "count": 2,
          "avg_confidence": 0.93
        },
        {
          "pattern_id": "PAT-Q005-006",
          "count": 3,
          "avg_confidence": 0.87
        }
      ],
      "temporal_consistency": {
        "constraints_checked": 12,
        "violations": 1,
        "consistency_score": 0.92
      },
      "causal_coherence": {
        "failure_points": 3,
        "temporal_coherence_score": 0.88
      },
      "dimensional_integration": {
        "dimensions_analyzed": [
          "legal",
          "presupuestal",
          "temporal",
          "competencias"
        ],
        "cross_references": 8,
        "integration_score": 0.67
      },
      "metadata": {
        "methods_executed": 7,
        "execution_time_ms": 1834,
        "document_length": 12450,
        "analysis_timestamp": "2025-11-26T14:22:18Z"
      }
    },
    "validation_against_expected_elements": {
      "coherencia_demostrada": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-004"
      },
      "restricciones_legales": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-001"
      },
      "restricciones_presupuestales": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-002"
      },
      "restricciones_temporales": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-003"
      },
      "overall_validation_result": "PASS - All required elements present"
    },
    "template_variable_bindings": {
      "description": "These variables are available for human_readable_output template",
      "variables": {
        "{evidence.elements_found_count}": 15,
        "{score}": "Calculated by scorer based on elements",
        "{quality_level}": "ALTO",
        "{evidence.confidence_scores.mean}": "89.2%",
        "{evidence.pattern_matches_count}": 10,
        "{evidence.legal_references_count}": 4,
        "{evidence.budget_constraints_count}": 5,
        "{evidence.temporal_constraints_count}": 4,
        "{evidence.coherence_demonstrated}": "Presente"
      }
    },
    "usage_notes": {
      "for_developers": "This structure shows the expected evidence dict after BaseExecutorWithContract._execute_v3() completes all 7 method executions and evidence assembly.",
      "for_validators": "Use this to verify that actual execution output matches expected structure.",
      "for_auditors": "This provides traceability from raw method outputs to final assembled evidence."
    }
  }
}
