{
  "identity": {
    "base_slot": "D3-Q1",
    "question_id": "Q011",
    "dimension_id": "DIM03",
    "policy_area_id": "PA01",
    "contract_version": "3.1.0",
    "contract_hash": "TRANSFORMED_AWAITING_FINAL_HASH",
    "created_at": "2025-01-19T00:00:00.000000+00:00",
    "validated_against_schema": "executor_contract.v3.schema.json",
    "cluster_id": "CL02",
    "question_global": 11
  },
  "executor_binding": {
    "executor_class": "D3_Q1_Executor",
    "executor_module": "farfan_core.core.orchestrator.executors"
  },
  "method_binding": {
    "orchestration_mode": "multi_method_pipeline",
    "method_count": 8,
    "methods": [
      {
        "class_name": "PDETMunicipalPlanAnalyzer",
        "method_name": "_score_indicators",
        "priority": 1,
        "provides": "pdet_analysis.score_indicators",
        "role": "_score_indicators_execution",
        "description": "PDETMunicipalPlanAnalyzer._score_indicators"
      },
      {
        "class_name": "OperationalizationAuditor",
        "method_name": "audit_evidence_traceability",
        "priority": 2,
        "provides": "operationalizationauditor.audit_evidence_traceability",
        "role": "audit_evidence_traceability_execution",
        "description": "OperationalizationAuditor.audit_evidence_traceability"
      },
      {
        "class_name": "CausalInferenceSetup",
        "method_name": "assign_probative_value",
        "priority": 3,
        "provides": "causalinferencesetup.assign_probative_value",
        "role": "assign_probative_value_execution",
        "description": "CausalInferenceSetup.assign_probative_value"
      },
      {
        "class_name": "BeachEvidentialTest",
        "method_name": "apply_test_logic",
        "priority": 4,
        "provides": "beachevidentialtest.apply_test_logic",
        "role": "apply_test_logic_execution",
        "description": "BeachEvidentialTest.apply_test_logic"
      },
      {
        "class_name": "TextMiningEngine",
        "method_name": "diagnose_critical_links",
        "priority": 5,
        "provides": "text_mining.diagnose_critical_links",
        "role": "diagnose_critical_links_diagnosis",
        "description": "TextMiningEngine.diagnose_critical_links"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_extract_metadata",
        "priority": 6,
        "provides": "industrial_policy.extract_metadata",
        "role": "_extract_metadata_extraction",
        "description": "IndustrialPolicyProcessor._extract_metadata"
      },
      {
        "class_name": "IndustrialPolicyProcessor",
        "method_name": "_calculate_quality_score",
        "priority": 7,
        "provides": "industrial_policy.calculate_quality_score",
        "role": "_calculate_quality_score_calculation",
        "description": "IndustrialPolicyProcessor._calculate_quality_score"
      },
      {
        "class_name": "AdaptivePriorCalculator",
        "method_name": "generate_traceability_record",
        "priority": 8,
        "provides": "adaptivepriorcalculator.generate_traceability_record",
        "role": "generate_traceability_record_execution",
        "description": "AdaptivePriorCalculator.generate_traceability_record"
      }
    ],
    "note": "All 8 methods extracted from D3_Q1_Executor in executors.py"
  },
  "question_context": {
    "question_text": "¿Los indicadores de producto para género (ej. mujeres capacitadas, kits entregados) incluyen 'línea base', 'meta' cuantitativa, y 'fuente de verificación'?",
    "question_type": "micro",
    "scoring_modality": "TYPE_A",
    "modality": "count_and_scale",
    "expected_output_type": "score",
    "patterns": [
      {
        "category": "INDICADOR",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-000",
        "match_type": "REGEX",
        "pattern": "indicador de producto|meta de producto"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-001",
        "match_type": "REGEX",
        "pattern": "número de mujeres capacitadas|personas formadas"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-002",
        "match_type": "REGEX",
        "pattern": "emprendimientos apoyados|unidades productivas"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-003",
        "match_type": "REGEX",
        "pattern": "casos atendidos|mujeres asistidas"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-004",
        "match_type": "LITERAL",
        "pattern": "Línea Base:|LB:|Valor inicial:"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-005",
        "match_type": "REGEX",
        "pattern": "Meta Cuatrienio:|Meta:|Valor esperado:"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-006",
        "match_type": "REGEX",
        "pattern": "Fuente de verificación:|Medio de verificación:|Fuente:"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-007",
        "match_type": "REGEX",
        "pattern": "listados de asistencia|actas de entrega|registros administrativos"
      },
      {
        "category": "GENERAL",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-008",
        "match_type": "REGEX",
        "pattern": "informes de supervisión|sistema de seguimiento"
      },
      {
        "category": "INDICADOR",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q011-009",
        "match_type": "REGEX",
        "pattern": "Ficha de Indicador|Anexo de metas"
      }
    ],
    "expected_elements": [
      {
        "required": true,
        "type": "fuente_verificacion"
      },
      {
        "required": true,
        "type": "linea_base_producto"
      },
      {
        "required": true,
        "type": "meta_cuantitativa"
      }
    ],
    "validations": {}
  },
  "signal_requirements": {
    "mandatory_signals": [
      "budget_allocation",
      "gender_baseline_data",
      "policy_coverage",
      "product_targets",
      "vbg_statistics"
    ],
    "optional_signals": [
      "implementation_schedule",
      "responsible_entities",
      "source_validation",
      "temporal_series",
      "territorial_scope"
    ],
    "signal_aggregation": "weighted_mean",
    "minimum_signal_threshold": 0.0,
    "note": "Signal requirements are currently under development. Signal IDs will be populated once the signal_registry provides a canonical mapping for PA01/DIM01."
  },
  "evidence_assembly": {
    "module": "farfan_core.core.orchestrator.evidence_assembler",
    "class_name": "EvidenceAssembler",
    "method_name": "assemble",
    "output_schema": {
      "type": "object",
      "required": [
        "elements",
        "raw_results"
      ],
      "properties": {
        "elements": {
          "type": "array",
          "description": "Lista de elementos de evidencia encontrados para esta micro-pregunta."
        },
        "raw_results": {
          "type": "object",
          "properties": {
            "confidence_scores": {
              "type": "array",
              "description": "Scores de confianza usados por el scorer."
            },
            "semantic_similarity": {
              "description": "Métrica de similitud semántica (si aplica)."
            },
            "pattern_matches": {
              "type": "object",
              "description": "Matches de patrones esperados vs texto."
            },
            "metadata": {
              "type": "object",
              "description": "Metadatos arbitrarios pasados al scorer."
            }
          },
          "additionalProperties": true
        }
      },
      "additionalProperties": true
    },
    "assembly_rules": [
      {
        "target": "elements_found",
        "sources": [
          "pdet_analysis.score_indicators",
          "operationalizationauditor.audit_evidence_traceability",
          "causalinferencesetup.assign_probative_value",
          "beachevidentialtest.apply_test_logic",
          "text_mining.diagnose_critical_links",
          "industrial_policy.extract_metadata",
          "industrial_policy.calculate_quality_score",
          "adaptivepriorcalculator.generate_traceability_record"
        ],
        "merge_strategy": "concat",
        "description": "Combine evidence from 8 methods"
      },
      {
        "target": "confidence_scores",
        "sources": [
          "*.confidence",
          "*.bayesian_posterior"
        ],
        "merge_strategy": "weighted_mean",
        "default": [],
        "description": "Aggregate confidence scores across all methods"
      },
      {
        "target": "pattern_matches",
        "sources": [
          "text_mining.patterns",
          "industrial_policy.patterns"
        ],
        "merge_strategy": "concat",
        "default": {},
        "description": "Combine pattern matches from text mining methods"
      },
      {
        "target": "metadata",
        "sources": [
          "*.metadata"
        ],
        "merge_strategy": "concat",
        "description": "Combine metadata from all 17 methods for full traceability"
      }
    ]
  },
  "output_contract": {
    "result_type": "Phase2QuestionResult",
    "schema": {
      "type": "object",
      "required": [
        "base_slot",
        "question_id",
        "question_global",
        "evidence",
        "validation"
      ],
      "properties": {
        "base_slot": {
          "type": "string",
          "description": "Debe coincidir con identity.base_slot.",
          "const": "D3-Q1"
        },
        "question_id": {
          "type": "string",
          "description": "Debe coincidir con identity.question_id.",
          "const": "Q011"
        },
        "question_global": {
          "type": "integer",
          "description": "Índice global de la pregunta (de questionnaire_monolith).",
          "const": 11
        },
        "policy_area_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "PA canónica, debe ser coherente con identity.policy_area_id.",
          "const": "PA01"
        },
        "dimension_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Dimensión canónica, coherente con identity.dimension_id.",
          "const": "DIM03"
        },
        "cluster_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Cluster de análisis según el monolith, si aplica.",
          "const": "CL02"
        },
        "evidence": {
          "type": [
            "object",
            "null"
          ],
          "description": "Objeto de evidencia ensamblado por el EvidenceAssembler; debe cumplir evidence_assembly.output_schema.",
          "additionalProperties": true
        },
        "validation": {
          "type": [
            "object",
            "null"
          ],
          "description": "Resultado de validaciones lógicas de la respuesta (coherencia, integridad, etc.).",
          "additionalProperties": true
        },
        "trace": {
          "type": [
            "object",
            "null"
          ],
          "description": "Información de trazabilidad (provenance, logs) específica de la ejecución.",
          "additionalProperties": true
        },
        "metadata": {
          "type": [
            "object",
            "null"
          ],
          "description": "Metadatos adicionales de la pregunta para consumo posterior.",
          "additionalProperties": true
        }
      },
      "additionalProperties": false
    },
    "consumer_modules": [
      "src.farfan_core.core.phases.phase2_types.validate_phase2_result",
      "src.farfan_core.core.orchestrator.core.Orchestrator._score_micro_results_async",
      "src.farfan_core.analysis.scoring.MicroQuestionScorer"
    ],
    "human_readable_output": {
      "format": "markdown",
      "template": {
        "title": "## Análisis D1-Q1: Línea Base Cuantitativa en Derechos de las Mujeres",
        "summary": "### Resumen Ejecutivo\n\nSe analizó la presencia de **{evidence.elements_found_count}** elementos de evidencia cuantitativa relacionados con la línea base diagnóstica en el área de Derechos de las Mujeres e Igualdad de Género.\n\n**Puntaje**: {score}/3.0 | **Calidad**: {quality_level}",
        "score_section": "### Evaluación Cuantitativa\n\n- **Puntaje bruto**: {score}/3.0\n- **Nivel de calidad**: {quality_level}\n- **Confianza promedio**: {evidence.confidence_scores.mean}%\n- **Cobertura de patrones**: {evidence.pattern_matches_count}/14 patrones detectados",
        "elements_section": "### Elementos de Evidencia Identificados\n\n{evidence.elements_found_list}\n\n**Elementos críticos faltantes**: {evidence.missing_required_elements}",
        "details": [
          "**Fuentes oficiales identificadas**: {evidence.official_sources_count}",
          "**Indicadores cuantitativos**: {evidence.quantitative_indicators_count}",
          "**Series temporales**: {evidence.temporal_series_count}",
          "**Cobertura territorial**: {evidence.territorial_coverage}"
        ],
        "interpretation": "### Interpretación de Resultados\n\n{methodological_interpretation}",
        "recommendations": "### Recomendaciones\n\n{evidence.recommendations}"
      },
      "methodological_depth": {
        "methods": [
          {
            "method_name": "_score_indicators",
            "class_name": "PDETMunicipalPlanAnalyzer",
            "priority": 1,
            "role": "_score_indicators",
            "epistemological_foundation": {
              "paradigm": "Quantitative indicator analysis with municipal development framework",
              "ontological_basis": "Product indicators exist as measurable outcomes traceable to baseline data, targets, and verification sources in municipal planning documents",
              "epistemological_stance": "Empirical-analytical: Knowledge emerges from systematic scoring of indicator completeness (baseline, target, source presence) against structured criteria",
              "theoretical_framework": [
                "Results-based management: Product indicators must link outputs to verifiable evidence (Kusek & Rist, 2004)",
                "PDET framework: Territorial development plans require gender-disaggregated metrics with accountability mechanisms"
              ],
              "justification": "Scoring indicators reveals institutional capacity to operationalize gender commitments through measurable, verifiable product delivery"
            },
            "technical_approach": {
              "method_type": "rule_based_scoring_with_pattern_matching",
              "algorithm": "Structured indicator completeness scoring across baseline/target/source dimensions",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract indicator mentions using regex patterns for product indicators (capacitadas, kits entregados, etc.)"
                },
                {
                  "step": 2,
                  "description": "For each indicator, search context window (±50 tokens) for baseline markers (Línea Base, LB, Valor inicial)"
                },
                {
                  "step": 3,
                  "description": "Search for target markers (Meta Cuatrienio, Meta, Valor esperado) with numeric extraction"
                },
                {
                  "step": 4,
                  "description": "Detect verification sources (Fuente de verificación, Medio de verificación, listados de asistencia)"
                },
                {
                  "step": 5,
                  "description": "Calculate completeness score: 1.0 if all three elements present, 0.67 if two, 0.33 if one, 0.0 if zero"
                }
              ],
              "assumptions": [
                "Indicators appear in proximity to their baseline/target/source specifications",
                "Standard Colombian planning terminology used (Meta Cuatrienio, Línea Base, etc.)",
                "Context window of ±50 tokens captures most indicator metadata"
              ],
              "limitations": [
                "Cannot detect implicit baselines or targets without linguistic markers",
                "May miss indicators specified in tables or structured data formats",
                "Assumes Spanish-language documents with Colombian public sector conventions"
              ],
              "complexity": "O(n*p) where n=document sentences, p=indicator patterns"
            },
            "output_interpretation": {
              "output_structure": {
                "indicator_scores": "List of dicts with {indicator_name, baseline_present, target_present, source_present, completeness_score}",
                "aggregate_score": "Mean completeness across all indicators (0-1 scale)",
                "missing_elements": "List of indicators missing baseline/target/source"
              },
              "interpretation_guide": {
                "high_completeness": "≥0.8: Indicators fully specified with baseline, target, and verification sources",
                "medium_completeness": "0.5-0.79: Most indicators have 2/3 elements, some gaps remain",
                "low_completeness": "<0.5: Systematic gaps in indicator specification, likely implementation challenges"
              },
              "actionable_insights": [
                "If baseline missing: Cannot assess progress, need baseline data collection",
                "If targets missing: Unclear success criteria, need target specification",
                "If sources missing: Verification impossible, need source identification and validation protocols"
              ]
            }
          },
          {
            "method_name": "audit_evidence_traceability",
            "class_name": "OperationalizationAuditor",
            "priority": 2,
            "role": "audit_evidence_traceability_auditing",
            "epistemological_foundation": {
              "paradigm": "Evidence chain verification with traceability analysis",
              "ontological_basis": "Evidence exists as traceable artifacts linking claims to sources through verifiable chains of custody",
              "epistemological_stance": "Critical-analytical: Knowledge validity depends on transparent provenance from claim to primary source",
              "theoretical_framework": [
                "Evidence-based policy: Claims require traceable evidence chains (Nutley et al., 2007)",
                "Audit theory: Traceability establishes epistemic warrant for policy assertions"
              ],
              "justification": "Auditing traceability exposes gaps between rhetorical commitments and evidentiary foundations"
            },
            "technical_approach": {
              "method_type": "chain_of_custody_validation",
              "algorithm": "Backward tracing from claims to sources with gap detection",
              "steps": [
                {
                  "step": 1,
                  "description": "Identify quantitative claims (numeric assertions about gender indicators)"
                },
                {
                  "step": 2,
                  "description": "Extract source citations (DANE, INML, Secretary reports) within claim context"
                },
                {
                  "step": 3,
                  "description": "Validate source authority (official entity, publication year, dataset ID)"
                },
                {
                  "step": 4,
                  "description": "Flag traceability gaps: claims without sources, sources without validation, broken citation chains"
                },
                {
                  "step": 5,
                  "description": "Generate traceability score: (validated_claims / total_claims) * confidence_weight"
                }
              ],
              "assumptions": [
                "Claims and sources appear in same paragraph or adjacent paragraphs",
                "Standard citation patterns used (según DANE, fuente: X, datos de Y)"
              ],
              "limitations": [
                "Cannot validate source authenticity without external database lookup",
                "May miss indirect citations or footnote-based referencing"
              ],
              "complexity": "O(n*c) where n=claims, c=citation patterns"
            },
            "output_interpretation": {
              "output_structure": {
                "traced_claims": "List of claims with {claim_text, source_citation, source_valid, traceability_score}",
                "traceability_gaps": "Claims without sources or with invalid sources",
                "aggregate_traceability": "Percentage of claims with valid source traceability"
              },
              "interpretation_guide": {
                "high_traceability": "≥0.8: Strong evidence chain, most claims traceable to valid sources",
                "medium_traceability": "0.5-0.79: Moderate gaps, some claims lack source validation",
                "low_traceability": "<0.5: Weak evidence foundation, many unsubstantiated claims"
              },
              "actionable_insights": [
                "If many gaps: Request source documentation from plan authors",
                "If invalid sources: Flag for verification with official databases",
                "If high traceability: Evidence foundation strong, can proceed with confidence"
              ]
            }
          },
          {
            "method_name": "assign_probative_value",
            "class_name": "CausalInferenceSetup",
            "priority": 3,
            "role": "assign_probative_value",
            "epistemological_foundation": {
              "paradigm": "Bayesian probative value assignment for causal inference",
              "ontological_basis": "Evidence has varying probative strength based on causal proximity, reliability, and inferential warrant",
              "epistemological_stance": "Bayesian-inferential: Evidence strength quantified through posterior probabilities given causal structure",
              "theoretical_framework": [
                "Bayesian epistemology: Probative value reflects evidential support for causal hypotheses (Joyce, 2003)",
                "Beach & Pedersen: Process tracing assigns probative weight based on test type (hoop/smoking gun/doubly decisive)"
              ],
              "justification": "Probative value assignment enables weighted aggregation of evidence with differential epistemic strength"
            },
            "technical_approach": {
              "method_type": "bayesian_weight_assignment",
              "algorithm": "Posterior probability computation for evidential strength",
              "steps": [
                {
                  "step": 1,
                  "description": "Classify evidence by type (statistical, observational, testimonial)"
                },
                {
                  "step": 2,
                  "description": "Assign prior probative weight based on evidence type (statistical: 0.9, observational: 0.7, testimonial: 0.5)"
                },
                {
                  "step": 3,
                  "description": "Adjust for source reliability (official sources +0.1, academic +0.15, anecdotal -0.2)"
                },
                {
                  "step": 4,
                  "description": "Compute posterior probative value via Bayesian updating given document quality score"
                },
                {
                  "step": 5,
                  "description": "Return ranked evidence with probative values for weighted aggregation"
                }
              ],
              "assumptions": [
                "Prior probative weights reflect true evidential strength hierarchy",
                "Source reliability is independent of evidence type"
              ],
              "limitations": [
                "Subjective priors for probative weights may not generalize across contexts",
                "Independence assumptions may not hold for correlated evidence"
              ],
              "complexity": "O(e) where e=evidence elements"
            },
            "output_interpretation": {
              "output_structure": {
                "evidence_elements": "List with {element_id, evidence_type, source_reliability, prior_weight, posterior_probative_value}",
                "high_value_evidence": "Elements with probative_value ≥ 0.8",
                "low_value_evidence": "Elements with probative_value < 0.5"
              },
              "interpretation_guide": {
                "high_probative": "≥0.8: Strong evidential warrant, suitable for primary inferences",
                "medium_probative": "0.5-0.79: Moderate strength, useful for triangulation",
                "low_probative": "<0.5: Weak warrant, use cautiously or discard"
              },
              "actionable_insights": [
                "Prioritize high-probative evidence for causal claims",
                "Use medium-probative for corroboration, not primary inference",
                "Flag low-probative evidence for exclusion or sensitivity analysis"
              ]
            }
          },
          {
            "method_name": "apply_test_logic",
            "class_name": "BeachEvidentialTest",
            "priority": 4,
            "role": "apply_test_logic",
            "epistemological_foundation": {
              "paradigm": "Process-tracing evidential tests (Beach & Pedersen framework)",
              "ontological_basis": "Evidence can be classified by logical strength: hoop tests (necessary), smoking gun tests (sufficient), doubly decisive tests (both)",
              "epistemological_stance": "Quasi-experimental: Causal mechanisms inferred through structured evidential tests eliminating rival hypotheses",
              "theoretical_framework": [
                "Beach & Pedersen (2013): Process tracing uses evidential tests to evaluate causal mechanisms",
                "Van Evera (1997): Tests vary in uniqueness and certainty, affecting inferential strength"
              ],
              "justification": "Structured evidential tests provide rigorous basis for causal claims in observational policy contexts"
            },
            "technical_approach": {
              "method_type": "structured_process_tracing",
              "algorithm": "Multi-test evidential logic with elimination inferencing",
              "steps": [
                {
                  "step": 1,
                  "description": "Define mechanism hypothesis (e.g., 'lack of baseline data causes incomplete indicator specification')"
                },
                {
                  "step": 2,
                  "description": "Apply hoop test: Is baseline data presence necessary? If absent, mechanism rejected"
                },
                {
                  "step": 3,
                  "description": "Apply smoking gun test: Is complete indicator spec sufficient to confirm mechanism? If present, mechanism confirmed"
                },
                {
                  "step": 4,
                  "description": "Aggregate test results: passed hoop + passed smoking gun = strong confirmation, failed hoop = rejection"
                },
                {
                  "step": 5,
                  "description": "Return mechanism confidence: doubly decisive (both passed) = 0.9, smoking gun only = 0.7, hoop only = 0.4, neither = 0.1"
                }
              ],
              "assumptions": [
                "Mechanisms are discrete and testable via observable implications",
                "Tests are correctly classified as hoop/smoking gun based on logical strength"
              ],
              "limitations": [
                "Requires pre-specified mechanism hypotheses, cannot discover novel mechanisms",
                "Test classification subjective and context-dependent"
              ],
              "complexity": "O(m*t) where m=mechanisms, t=tests per mechanism"
            },
            "output_interpretation": {
              "output_structure": {
                "mechanism": "Hypothesized causal mechanism being tested",
                "hoop_test_result": "{passed: bool, evidence: str, confidence: float}",
                "smoking_gun_result": "{passed: bool, evidence: str, confidence: float}",
                "overall_confidence": "Mechanism confidence (0-1) based on test outcomes"
              },
              "interpretation_guide": {
                "doubly_decisive": "Both tests passed (0.9): Strong mechanism confirmation",
                "smoking_gun_only": "Sufficient but not necessary (0.7): Mechanism plausible but not unique",
                "hoop_only": "Necessary but not sufficient (0.4): Mechanism possible but not confirmed",
                "both_failed": "Neither test passed (0.1): Mechanism rejected or unsupported"
              },
              "actionable_insights": [
                "Doubly decisive: Accept mechanism, use for intervention design",
                "Smoking gun only: Consider alternative mechanisms with same sufficient evidence",
                "Hoop only: Mechanism survives but needs additional evidence",
                "Both failed: Reject mechanism, explore alternative causal pathways"
              ]
            }
          },
          {
            "method_name": "diagnose_critical_links",
            "class_name": "TextMiningEngine",
            "priority": 1,
            "role": "critical_link_diagnosis",
            "epistemological_foundation": {
              "paradigm": "Critical text mining with causal link detection",
              "ontological_basis": "Texts contain latent causal structures that can be detected through linguistic patterns indicating causal relationships (because, therefore, leads to, etc.)",
              "epistemological_stance": "Empirical-interpretive: Knowledge about policy mechanisms emerges from detecting linguistic markers of causality in policy documents",
              "theoretical_framework": [
                "Causal discourse analysis: Texts reveal causal beliefs through specific linguistic constructions (Fairclough, 2003)",
                "Theory of change reconstruction: Policy documents implicitly encode theories of change that can be extracted via causal link detection (Weiss, 1995)"
              ],
              "justification": "Diagnosing critical causal links in baseline diagnostics reveals whether policymakers understand the causal pathways between gender inequalities and their determinants"
            },
            "technical_approach": {
              "method_type": "pattern_based_causal_link_extraction",
              "algorithm": "Multi-pattern regex matching with context window analysis",
              "steps": [
                {
                  "step": 1,
                  "description": "Identify causal connectors (porque, por lo tanto, conduce a, genera, resulta en)"
                },
                {
                  "step": 2,
                  "description": "Extract entities before and after connector (cause → effect)"
                },
                {
                  "step": 3,
                  "description": "Classify link criticality based on proximity to gender indicators"
                }
              ],
              "assumptions": [
                "Causal language reflects causal understanding",
                "Critical links mention gender-related outcomes"
              ],
              "limitations": [
                "Cannot detect implicit causality without linguistic markers",
                "May miss causal relationships expressed across distant sentences"
              ],
              "complexity": "O(n*p) where n=sentences, p=causal patterns"
            },
            "output_interpretation": {
              "output_structure": {
                "critical_links": "List of detected causal links with source/target entities",
                "link_scores": "Criticality scores (0-1) based on relevance to gender outcomes"
              },
              "interpretation_guide": {
                "high_criticality": "≥0.8: Link directly connects to gender inequality outcomes",
                "medium_criticality": "0.5-0.79: Link relates to intermediate factors",
                "low_criticality": "<0.5: Peripheral causal relationship"
              },
              "actionable_insights": [
                "If few critical links found: Diagnosis lacks causal depth, may be purely descriptive",
                "If many links but low criticality: Diagnosis discusses tangential issues, not core gender inequalities"
              ]
            }
          },
          {
            "method_name": "_extract_metadata",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 6,
            "role": "_extract_metadata_extraction",
            "epistemological_foundation": {
              "paradigm": "Metadata extraction for policy document characterization",
              "ontological_basis": "Policy documents contain structured and unstructured metadata revealing document provenance, scope, and administrative context",
              "epistemological_stance": "Empirical-descriptive: Document metadata provides contextual knowledge for interpretation and validation",
              "theoretical_framework": [
                "Document analysis: Metadata enables systematic comparison and quality assessment (Prior, 2003)",
                "Administrative records theory: Metadata reveals institutional production conditions"
              ],
              "justification": "Metadata extraction enables quality filtering and contextualization of evidence by document characteristics"
            },
            "technical_approach": {
              "method_type": "structured_metadata_extraction",
              "algorithm": "Pattern-based metadata field extraction with validation",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract document identifiers (plan name, municipality, year) from title and header sections"
                },
                {
                  "step": 2,
                  "description": "Detect policy area classification (gender, rural development, etc.) via keyword matching"
                },
                {
                  "step": 3,
                  "description": "Parse temporal scope (plan period: 2020-2023) from common metadata fields"
                },
                {
                  "step": 4,
                  "description": "Identify responsible entities (Secretarías, alcaldía) from authorship and approval sections"
                },
                {
                  "step": 5,
                  "description": "Validate metadata completeness and flag missing critical fields (year, municipality)"
                }
              ],
              "assumptions": [
                "Metadata fields appear in standard locations (headers, footers, first pages)",
                "Standard Colombian municipal plan structure followed"
              ],
              "limitations": [
                "Cannot extract metadata from unstructured or non-standard documents",
                "May fail on scanned PDFs without OCR or poorly formatted text"
              ],
              "complexity": "O(n) where n=document tokens (single-pass extraction)"
            },
            "output_interpretation": {
              "output_structure": {
                "document_id": "Unique identifier (plan name + municipality + year)",
                "metadata_fields": "Dict with {municipality, year, policy_area, temporal_scope, responsible_entity, author}",
                "completeness": "Percentage of required metadata fields present",
                "validation_flags": "Missing or invalid fields requiring attention"
              },
              "interpretation_guide": {
                "complete_metadata": "100%: All required fields present and valid",
                "partial_metadata": "50-99%: Some fields missing, usable with caveats",
                "incomplete_metadata": "<50%: Critical fields missing, document may be unreliable"
              },
              "actionable_insights": [
                "Complete metadata: Document well-characterized, suitable for analysis",
                "Partial metadata: Use with caution, note limitations in reporting",
                "Incomplete metadata: Request additional documentation or exclude from analysis"
              ]
            }
          },
          {
            "method_name": "_calculate_quality_score",
            "class_name": "IndustrialPolicyProcessor",
            "priority": 7,
            "role": "_calculate_quality_score_calculation",
            "epistemological_foundation": {
              "paradigm": "Multi-dimensional document quality assessment",
              "ontological_basis": "Document quality is a composite construct spanning completeness, consistency, traceability, and specification",
              "epistemological_stance": "Evaluative-analytical: Quality emerges from weighted aggregation of measurable quality dimensions",
              "theoretical_framework": [
                "Information quality framework: Quality assessed via completeness, accuracy, consistency dimensions (Wang & Strong, 1996)",
                "Policy quality metrics: Operationalization quality predicts implementation success"
              ],
              "justification": "Quality scoring enables prioritization of high-reliability evidence and flagging of low-quality sources"
            },
            "technical_approach": {
              "method_type": "composite_quality_scoring",
              "algorithm": "Weighted aggregation of quality dimensions with threshold checks",
              "steps": [
                {
                  "step": 1,
                  "description": "Calculate completeness: (present_fields / required_fields) * 0.3"
                },
                {
                  "step": 2,
                  "description": "Calculate consistency: 1 - (contradictions_detected / total_claims) * 0.25"
                },
                {
                  "step": 3,
                  "description": "Calculate traceability: (claims_with_sources / total_claims) * 0.25"
                },
                {
                  "step": 4,
                  "description": "Calculate specification: (indicators_with_baseline_target / total_indicators) * 0.2"
                },
                {
                  "step": 5,
                  "description": "Aggregate: quality_score = completeness + consistency + traceability + specification (0-1 scale)"
                }
              ],
              "assumptions": [
                "Quality dimensions are independent and equally important within their weights",
                "Weighted formula reflects true document quality construct"
              ],
              "limitations": [
                "Weights subjectively chosen, may not match all use cases",
                "Cannot assess semantic quality or logical coherence beyond contradiction detection"
              ],
              "complexity": "O(n) where n=document elements (claims, indicators, fields)"
            },
            "output_interpretation": {
              "output_structure": {
                "quality_score": "Composite score (0-1) aggregating completeness, consistency, traceability, specification",
                "dimension_scores": "Dict with {completeness, consistency, traceability, specification} subscores",
                "quality_flags": "Specific issues detected (contradictions, missing sources, incomplete indicators)"
              },
              "interpretation_guide": {
                "high_quality": "≥0.8: Document meets quality standards, suitable for primary evidence",
                "medium_quality": "0.6-0.79: Acceptable quality with minor issues",
                "low_quality": "<0.6: Quality concerns, use cautiously or exclude"
              },
              "actionable_insights": [
                "High quality: Proceed with analysis, document is reliable",
                "Medium quality: Flag specific issues, use with caveats",
                "Low quality: Request document revision or seek alternative sources"
              ]
            }
          },
          {
            "method_name": "generate_traceability_record",
            "class_name": "AdaptivePriorCalculator",
            "priority": 8,
            "role": "generate_traceability_record_generation",
            "epistemological_foundation": {
              "paradigm": "Bayesian prior adaptation with full provenance tracking",
              "ontological_basis": "Prior distributions encode background knowledge that should adapt as evidence accumulates, with adaptation traced for reproducibility",
              "epistemological_stance": "Bayesian-reflexive: Priors updated systematically with transparent documentation of adaptation rationale",
              "theoretical_framework": [
                "Adaptive Bayesian inference: Priors updated via empirical Bayes or hierarchical modeling (Gelman et al., 2013)",
                "Provenance tracking: Scientific reproducibility requires documented lineage of analytical choices"
              ],
              "justification": "Traceability records enable auditing of prior choices and sensitivity analysis of posterior conclusions"
            },
            "technical_approach": {
              "method_type": "provenance_logging_with_bayesian_updating",
              "algorithm": "Structured prior adaptation with full audit trail generation",
              "steps": [
                {
                  "step": 1,
                  "description": "Initialize prior distribution from expert elicitation or empirical data (e.g., Beta(2, 5) for baseline presence)"
                },
                {
                  "step": 2,
                  "description": "Update prior to posterior using observed data via Bayesian conjugate updating"
                },
                {
                  "step": 3,
                  "description": "Log adaptation record: prior parameters, observed data, posterior parameters, update rationale"
                },
                {
                  "step": 4,
                  "description": "Generate provenance graph: link posterior to evidence elements and methods contributing to update"
                },
                {
                  "step": 5,
                  "description": "Return traceability record with full audit trail for reproducibility and sensitivity analysis"
                }
              ],
              "assumptions": [
                "Conjugate priors available for efficient updating (Beta-Binomial, Normal-Normal, etc.)",
                "Prior choice transparent and justified via expert knowledge or data"
              ],
              "limitations": [
                "Non-conjugate updates require MCMC or variational inference (computationally expensive)",
                "Prior sensitivity not automatically assessed, requires additional sensitivity analysis"
              ],
              "complexity": "O(d) where d=data points for posterior update (O(1) for conjugate, O(n*iterations) for MCMC)"
            },
            "output_interpretation": {
              "output_structure": {
                "prior_distribution": "Initial distribution (e.g., Beta(2, 5))",
                "observed_data": "Data used for updating (e.g., 8 successes in 10 trials)",
                "posterior_distribution": "Updated distribution (e.g., Beta(10, 7))",
                "adaptation_rationale": "Reason for update (observed data, expert input)",
                "provenance_graph": "Linkage from posterior to contributing evidence elements"
              },
              "interpretation_guide": {
                "strong_update": "Large shift in posterior mean (>0.2): Data highly informative",
                "moderate_update": "Moderate shift (0.05-0.2): Data provides some information",
                "weak_update": "Small shift (<0.05): Data weakly informative, prior dominates"
              },
              "actionable_insights": [
                "Strong update: Data-driven inference, posterior reflects observed patterns",
                "Moderate update: Balanced inference, both prior and data contribute",
                "Weak update: Prior-dominated, consider collecting more data or refining prior",
                "Always check provenance graph for sensitivity to specific evidence elements"
              ]
            }
          }
        ],
        "method_combination_logic": {
          "combination_strategy": "Sequential multi-method pipeline with evidence fusion",
          "rationale": "D3-Q1 requires comprehensive analysis of product indicators with baseline/target/source verification. The 8 methods cover complementary aspects: indicator scoring (method 1), evidence traceability (method 2), probative value assignment (method 3), evidential tests (method 4), causal link diagnosis (method 5), metadata extraction (method 6), quality scoring (method 7), and traceability recording (method 8).",
          "evidence_fusion": "Evidence from all 8 methods is aggregated by the EvidenceAssembler. Overlapping evidence (e.g., same indicator detected by multiple methods) is deduplicated. Confidence scores are combined via weighted averaging.",
          "confidence_aggregation": "Final confidence per evidence element = weighted_mean([confidence_method1, confidence_method2, ...]) where weights reflect method reliability (e.g., Bayesian methods have higher weight than pattern matching).",
          "execution_order": "Methods execute in priority order (1→8). Later methods can access outputs of earlier methods (e.g., method 7 quality scoring uses metadata from method 6).",
          "trade_offs": [
            "Comprehensiveness vs. Complexity: 8 methods ensure thorough coverage but increase computational cost and maintenance burden",
            "Precision vs. Recall: Multiple methods increase recall (find more evidence) but may introduce redundancy; deduplication and confidence weighting mitigate this",
            "Interpretability vs. Sophistication: Bayesian and process-tracing methods are powerful but less transparent than regex; human_readable_output compensates via methodological documentation"
          ]
        }
      }
    }
  },
  "validation_rules": {
    "na_policy": "abort_on_critical",
    "rules": [
      {
        "field": "elements_found",
        "type": "array",
        "must_contain": {
          "count": 1,
          "elements": [
            "cobertura_territorial_especificada"
          ]
        },
        "description": "Derived from monolith expected_elements where required is true"
      },
      {
        "field": "elements_found",
        "type": "array",
        "should_contain": [
          {
            "elements": [
              "fuentes_oficiales"
            ],
            "minimum": 2
          },
          {
            "elements": [
              "indicadores_cuantitativos"
            ],
            "minimum": 3
          },
          {
            "elements": [
              "series_temporales_años"
            ],
            "minimum": 3
          }
        ],
        "description": "Derived from monolith expected_elements with minimum counts"
      }
    ]
  },
  "traceability": {
    "source_file": "data/questionnaire_monolith.json",
    "json_path": "blocks.micro_questions[280]",
    "method_source": "src/farfan_core/core/orchestrator/executors.py:D3_Q1_Executor",
    "method_mapping_source": "executor_methods_mapping.json",
    "ontology_source": "config/canonical_ontologies/policy_areas_and_dimensions.json",
    "source_hash": "TODO_SHA256_HASH_OF_QUESTIONNAIRE_MONOLITH",
    "contract_generation_method": "automated_specialization_from_monolith",
    "contract_author": "F.A.R.F.A.N Mechanistic Policy Pipeline",
    "provenance_note": "This contract was generated with full multi-method orchestration support. The method_binding.methods array contains all 17 methods from D1_Q1_QuantitativeBaselineExtractor, and human_answer_structure documents the expected evidence output after execution.",
    "source_question_id": "Q011",
    "specialized_from_base_slot": "D3-Q1",
    "specialization_timestamp": "2025-11-28T03:49:29.814148+00:00"
  },
  "error_handling": {
    "on_method_not_found": "raise",
    "on_method_failure": "propagate_with_trace",
    "on_assembly_failure": "propagate_with_trace",
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text"
      ],
      "emit_code": "ABORT-Q011-REQ"
    }
  },
  "fallback_strategy": {
    "use_llm_direct": false,
    "use_heuristics": false,
    "note": "No fallback strategies enabled. All failures propagate according to error_handling configuration."
  },
  "test_configuration": {
    "test_files": [
      "tests/core/orchestrator/test_executors_contract.py",
      "tests/core/phases/test_phase2.py"
    ],
    "test_document_fixtures": [
      "tests/fixtures/preprocessed_documents/sample_pdet_plan.json"
    ],
    "expected_test_coverage": ">=90%",
    "integration_test_required": true
  },
  "compatibility": {
    "orchestrator_min_version": "TODO_VERSION",
    "signal_registry_min_version": "TODO_VERSION",
    "method_executor_min_version": "TODO_VERSION",
    "questionnaire_monolith_version": "3.0.0",
    "phase2_types_version": "TODO_VERSION"
  },
  "calibration": {
    "status": "placeholder",
    "note": "Contract does not embed calibration scores. Actual calibration managed via src/farfan_core/core/calibration/ + config/intrinsic_calibration.json + config/fusion_specification.json",
    "source": {
      "intrinsic_calibration": "config/intrinsic_calibration.json",
      "fusion_specification": "config/fusion_specification.json",
      "layer_calibrations_dir": "config/layer_calibrations/",
      "canonical_spec": "canonic_calibration_methods.md"
    }
  },
  "human_answer_structure": {
    "description": "Expected structure of evidence dict after all 17 methods execute and evidence is assembled according to assembly_rules",
    "assembly_flow": {
      "step_1_method_execution": "17 methods execute in priority order, outputs stored with dot-notation keys",
      "step_2_evidence_assembly": "EvidenceAssembler merges outputs according to assembly_rules",
      "step_3_validation": "EvidenceValidator checks against validation_rules",
      "step_4_output_generation": "Phase2QuestionResult constructed with evidence, validation, trace"
    },
    "evidence_structure_schema": {
      "type": "object",
      "description": "Assembled evidence after all methods complete",
      "properties": {
        "elements_found": {
          "type": "array",
          "description": "Concatenated evidence elements from multiple methods (assembly_rules target)",
          "items": {
            "type": "object",
            "properties": {
              "element_id": {
                "type": "string",
                "example": "E-001"
              },
              "type": {
                "type": "string",
                "enum": [
                  "fuentes_oficiales",
                  "indicadores_cuantitativos",
                  "series_temporales_años",
                  "cobertura_territorial_especificada",
                  "financial_amounts",
                  "policy_goals",
                  "causal_links"
                ]
              },
              "value": {
                "type": "string",
                "example": "DANE"
              },
              "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "source_method": {
                "type": "string",
                "example": "IndustrialPolicyProcessor._extract_point_evidence"
              },
              "sentence_id": {
                "type": "integer"
              },
              "context": {
                "type": "string"
              }
            }
          },
          "example_count": "Expected 15-50 elements for a complete diagnostic"
        },
        "elements_summary": {
          "type": "object",
          "properties": {
            "total_count": {
              "type": "integer"
            },
            "by_type": {
              "type": "object",
              "properties": {
                "fuentes_oficiales": {
                  "type": "integer",
                  "minimum_expected": 2
                },
                "indicadores_cuantitativos": {
                  "type": "integer",
                  "minimum_expected": 3
                },
                "series_temporales_años": {
                  "type": "integer",
                  "minimum_expected": 3
                },
                "cobertura_territorial_especificada": {
                  "type": "integer",
                  "minimum_expected": 1
                }
              }
            }
          }
        },
        "confidence_scores": {
          "type": "object",
          "description": "Aggregated confidence metrics (weighted_mean strategy)",
          "properties": {
            "mean": {
              "type": "number"
            },
            "std": {
              "type": "number"
            },
            "min": {
              "type": "number"
            },
            "max": {
              "type": "number"
            },
            "by_method": {
              "type": "object",
              "description": "Average confidence per analyzer class"
            }
          }
        },
        "pattern_matches": {
          "type": "array",
          "description": "Aggregated pattern matches from text mining methods",
          "items": {
            "type": "object",
            "properties": {
              "pattern_id": {
                "type": "string"
              },
              "count": {
                "type": "integer"
              },
              "avg_confidence": {
                "type": "number"
              }
            }
          }
        },
        "critical_links": {
          "type": "array",
          "description": "Causal links extracted by TextMiningEngine",
          "items": {
            "type": "object",
            "properties": {
              "cause": {
                "type": "string"
              },
              "effect": {
                "type": "string"
              },
              "criticality": {
                "type": "number"
              },
              "coherence": {
                "type": "number"
              }
            }
          }
        },
        "financial_summary": {
          "type": "object",
          "description": "Aggregated financial data from FinancialAuditor and PDETMunicipalPlanAnalyzer",
          "properties": {
            "total_budget_cop": {
              "type": "number"
            },
            "amounts_found": {
              "type": "integer"
            },
            "by_category": {
              "type": "object",
              "properties": {
                "SGR": {
                  "type": "number"
                },
                "recursos_propios": {
                  "type": "number"
                },
                "transferencias": {
                  "type": "number"
                }
              }
            }
          }
        },
        "goals_summary": {
          "type": "object",
          "description": "Policy goals extracted by CausalExtractor",
          "properties": {
            "total_goals": {
              "type": "integer"
            },
            "quantified_goals": {
              "type": "integer"
            },
            "goals_with_complete_context": {
              "type": "integer"
            }
          }
        },
        "contradictions": {
          "type": "object",
          "description": "Results from PolicyContradictionDetector",
          "properties": {
            "found": {
              "type": "integer"
            },
            "tests_performed": {
              "type": "integer"
            },
            "interpretation": {
              "type": "string"
            }
          }
        },
        "bayesian_insights": {
          "type": "object",
          "description": "Results from BayesianNumericalAnalyzer",
          "properties": {
            "metrics_with_high_uncertainty": {
              "type": "array"
            },
            "significant_comparisons": {
              "type": "integer"
            }
          }
        },
        "semantic_processing": {
          "type": "object",
          "description": "Results from SemanticProcessor",
          "properties": {
            "chunks_created": {
              "type": "integer"
            },
            "embeddings_generated": {
              "type": "integer"
            },
            "avg_semantic_similarity_to_query": {
              "type": "number"
            }
          }
        },
        "metadata": {
          "type": "object",
          "properties": {
            "methods_executed": {
              "type": "integer",
              "const": 8
            },
            "execution_time_ms": {
              "type": "number"
            },
            "document_length": {
              "type": "integer"
            },
            "analysis_timestamp": {
              "type": "string",
              "format": "date-time"
            }
          }
        }
      }
    },
    "concrete_example": {
      "elements_found": [
        {
          "element_id": "E-001",
          "type": "fuentes_oficiales",
          "value": "DANE",
          "confidence": 0.95,
          "source_method": "IndustrialPolicyProcessor._extract_point_evidence",
          "source_sentence": "según datos de DANE para el año 2022",
          "sentence_id": 45,
          "position": {
            "start": 123,
            "end": 145
          }
        },
        {
          "element_id": "E-002",
          "type": "indicadores_cuantitativos",
          "value": "tasa de VBG: 12.3%",
          "normalized_value": 12.3,
          "unit": "%",
          "confidence": 0.89,
          "source_method": "PolicyContradictionDetector._extract_quantitative_claims",
          "bayesian_posterior": {
            "mean": 0.123,
            "ci_95": [
              0.11,
              0.145
            ]
          },
          "sentence_id": 45
        },
        {
          "element_id": "E-003",
          "type": "series_temporales_años",
          "years": [
            2020,
            2021,
            2022
          ],
          "confidence": 0.92,
          "source_method": "TextMiningEngine.diagnose_critical_links"
        },
        {
          "element_id": "E-004",
          "type": "cobertura_territorial_especificada",
          "coverage": "municipal - zona rural y urbana",
          "confidence": 0.88,
          "source_method": "CausalExtractor._parse_goal_context"
        }
      ],
      "elements_summary": {
        "total_count": 38,
        "by_type": {
          "fuentes_oficiales": 5,
          "indicadores_cuantitativos": 12,
          "series_temporales_años": 4,
          "cobertura_territorial_especificada": 1,
          "financial_amounts": 8,
          "policy_goals": 7,
          "causal_links": 5
        }
      },
      "confidence_scores": {
        "mean": 0.876,
        "std": 0.089,
        "min": 0.72,
        "max": 0.98,
        "by_method": {
          "TextMiningEngine": 0.83,
          "IndustrialPolicyProcessor": 0.91,
          "CausalExtractor": 0.79,
          "FinancialAuditor": 0.94,
          "PDETMunicipalPlanAnalyzer": 0.88,
          "PolicyContradictionDetector": 0.9,
          "BayesianNumericalAnalyzer": 0.92,
          "SemanticProcessor": 0.85
        }
      },
      "pattern_matches": [
        {
          "pattern_id": "PAT-Q001-000",
          "count": 3,
          "avg_confidence": 0.87
        },
        {
          "pattern_id": "PAT-Q001-002",
          "count": 5,
          "avg_confidence": 0.95
        }
      ],
      "critical_links": [
        {
          "cause": "alta tasa de VBG",
          "effect": "baja autonomía económica",
          "criticality": 0.87,
          "coherence": 0.82
        }
      ],
      "financial_summary": {
        "total_budget_cop": 850000000.0,
        "amounts_found": 12,
        "by_category": {
          "SGR": 250000000.0,
          "recursos_propios": 180000000.0
        }
      },
      "goals_summary": {
        "total_goals": 7,
        "quantified_goals": 5,
        "goals_with_complete_context": 4
      },
      "contradictions": {
        "found": 0,
        "tests_performed": 15,
        "interpretation": "No statistical contradictions in quantitative claims"
      },
      "bayesian_insights": {
        "metrics_with_high_uncertainty": [],
        "significant_comparisons": 1
      },
      "semantic_processing": {
        "chunks_created": 45,
        "embeddings_generated": 45,
        "avg_semantic_similarity_to_query": 0.78
      },
      "metadata": {
        "methods_executed": 8,
        "execution_time_ms": 2845,
        "document_length": 15230,
        "analysis_timestamp": "2025-11-26T12:34:56Z"
      }
    },
    "validation_against_expected_elements": {
      "cobertura_territorial_especificada": {
        "required": true,
        "found_in_example": true,
        "example_element_id": "E-004"
      },
      "fuentes_oficiales": {
        "minimum": 2,
        "found_in_example": 5,
        "status": "PASS"
      },
      "indicadores_cuantitativos": {
        "minimum": 3,
        "found_in_example": 12,
        "status": "PASS"
      },
      "series_temporales_años": {
        "minimum": 3,
        "found_in_example": 4,
        "status": "PASS"
      },
      "overall_validation_result": "PASS - All required and minimum elements present"
    },
    "template_variable_bindings": {
      "description": "These variables are available for human_readable_output template",
      "variables": {
        "{evidence.elements_found_count}": 38,
        "{score}": "Calculated by scorer based on elements",
        "{quality_level}": "ALTO",
        "{evidence.confidence_scores.mean}": "87.6%",
        "{evidence.pattern_matches_count}": 14,
        "{evidence.official_sources_count}": 5,
        "{evidence.quantitative_indicators_count}": 12,
        "{evidence.temporal_series_count}": 4,
        "{evidence.territorial_coverage}": "municipal - zona rural y urbana"
      }
    },
    "usage_notes": {
      "for_developers": "This structure shows the expected evidence dict after BaseExecutorWithContract._execute_v3() completes all 17 method executions and evidence assembly.",
      "for_validators": "Use this to verify that actual execution output matches expected structure.",
      "for_auditors": "This provides traceability from raw method outputs to final assembled evidence."
    }
  }
}
