{
  "identity": {
    "base_slot": "D4-Q2",
    "question_id": "Q017",
    "dimension_id": "DIM04",
    "policy_area_id": "PA01",
    "contract_version": "3.0.0",
    "contract_hash": "11cf2fb50ef486642d678364f6fa695d64c618c865ed782ae0b221a8283368f3",
    "created_at": "2025-11-28T03:49:29.842799+00:00",
    "validated_against_schema": "executor_contract.v3.schema.json",
    "cluster_id": "CL02",
    "question_global": 17
  },
  "executor_binding": {
    "executor_class": "D4_Q2_Executor",
    "executor_module": "farfan_core.core.orchestrator.executors"
  },
  "method_binding": {
    "orchestration_mode": "multi_method_pipeline",
    "method_count": 8,
    "methods": [
      {
        "class_name": "TeoriaCambio",
        "method_name": "_encontrar_caminos_completos",
        "priority": 1,
        "provides": "teoriacambio.encontrar_caminos_completos",
        "role": "_encontrar_caminos_completos_execution",
        "description": "TeoriaCambio._encontrar_caminos_completos"
      },
      {
        "class_name": "TeoriaCambio",
        "method_name": "validacion_completa",
        "priority": 2,
        "provides": "teoriacambio.validacion_completa",
        "role": "validacion_completa_execution",
        "description": "TeoriaCambio.validacion_completa"
      },
      {
        "class_name": "CausalExtractor",
        "method_name": "extract_causal_hierarchy",
        "priority": 3,
        "provides": "causal_extraction.extract_causal_hierarchy",
        "role": "extract_causal_hierarchy_extraction",
        "description": "CausalExtractor.extract_causal_hierarchy"
      },
      {
        "class_name": "HierarchicalGenerativeModel",
        "method_name": "verify_conditional_independence",
        "priority": 4,
        "provides": "hierarchicalgenerativemodel.verify_conditional_independence",
        "role": "verify_conditional_independence_execution",
        "description": "HierarchicalGenerativeModel.verify_conditional_independence"
      },
      {
        "class_name": "HierarchicalGenerativeModel",
        "method_name": "_generate_independence_tests",
        "priority": 5,
        "provides": "hierarchicalgenerativemodel.generate_independence_tests",
        "role": "_generate_independence_tests_execution",
        "description": "HierarchicalGenerativeModel._generate_independence_tests"
      },
      {
        "class_name": "BayesianCounterfactualAuditor",
        "method_name": "construct_scm",
        "priority": 6,
        "provides": "bayesiancounterfactualauditor.construct_scm",
        "role": "construct_scm_execution",
        "description": "BayesianCounterfactualAuditor.construct_scm"
      },
      {
        "class_name": "AdvancedDAGValidator",
        "method_name": "_perform_sensitivity_analysis_internal",
        "priority": 7,
        "provides": "advanceddagvalidator.perform_sensitivity_analysis_internal",
        "role": "_perform_sensitivity_analysis_internal_execution",
        "description": "AdvancedDAGValidator._perform_sensitivity_analysis_internal"
      },
      {
        "class_name": "BayesFactorTable",
        "method_name": "get_bayes_factor",
        "priority": 8,
        "provides": "bayesfactortable.get_bayes_factor",
        "role": "get_bayes_factor_execution",
        "description": "BayesFactorTable.get_bayes_factor"
      }
    ],
    "note": "All 8 methods extracted from D4_Q2_Executor in executors.py"
  },
  "question_context": {
    "question_text": "¿Se explicita la cadena causal que lleva a los resultados de género, mencionando los 'supuestos' clave (ej. 'si las mujeres denuncian') o las 'condiciones habilitantes' para que funcione?",
    "question_type": "micro",
    "scoring_modality": "TYPE_A",
    "modality": "count_and_scale",
    "expected_output_type": "score",
    "patterns": [
      {
        "category": "CAUSAL_CHAIN",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-000",
        "match_type": "REGEX",
        "pattern": "cadena causal|lógica de intervención|si... entonces..."
      },
      {
        "category": "ASSUMPTION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-001",
        "match_type": "REGEX",
        "pattern": "el resultado se logrará siempre y cuando|asumiendo que"
      },
      {
        "category": "ASSUMPTION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-002",
        "match_type": "REGEX",
        "pattern": "supuesto clave|premisa fundamental"
      },
      {
        "category": "ENABLING_CONDITION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-003",
        "match_type": "REGEX",
        "pattern": "condición habilitante|factor crítico|requiere de"
      },
      {
        "category": "ENABLING_CONDITION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-004",
        "match_type": "REGEX",
        "pattern": "depende de la articulación con|necesita de la participación de"
      },
      {
        "category": "ASSUMPTION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-005",
        "match_type": "REGEX",
        "pattern": "un supuesto es que las mujeres se apropien de las herramientas"
      },
      {
        "category": "ENABLING_CONDITION",
        "confidence_weight": 0.85,
        "flags": "i",
        "id": "PAT-Q017-006",
        "match_type": "LITERAL",
        "pattern": "se requiere un cambio cultural para que"
      }
    ],
    "expected_elements": [
      {
        "required": true,
        "type": "cadena_causal_explicita"
      },
      {
        "required": true,
        "type": "condiciones_habilitantes"
      },
      {
        "required": true,
        "type": "supuestos_identificados"
      }
    ],
    "validations": {}
  },
  "signal_requirements": {
    "mandatory_signals": [
      "gender_baseline_data",
      "measurement_validity",
      "outcome_indicators",
      "policy_coverage",
      "vbg_statistics"
    ],
    "optional_signals": [
      "composite_metrics",
      "source_validation",
      "temporal_series",
      "territorial_scope",
      "verification_sources"
    ],
    "signal_aggregation": "weighted_mean",
    "minimum_signal_threshold": 0.5,
    "note": "Signal requirements enforce minimum quality threshold of 0.5. Mandatory signals must be present with sufficient strength for execution to proceed."
  },
  "evidence_assembly": {
    "module": "farfan_core.core.orchestrator.evidence_assembler",
    "class_name": "EvidenceAssembler",
    "method_name": "assemble",
    "output_schema": {
      "type": "object",
      "required": [
        "elements",
        "raw_results"
      ],
      "properties": {
        "elements": {
          "type": "array",
          "description": "Lista de elementos de evidencia encontrados para esta micro-pregunta."
        },
        "raw_results": {
          "type": "object",
          "properties": {
            "confidence_scores": {
              "type": "array",
              "description": "Scores de confianza usados por el scorer."
            },
            "semantic_similarity": {
              "description": "Métrica de similitud semántica (si aplica)."
            },
            "pattern_matches": {
              "type": "object",
              "description": "Matches de patrones esperados vs texto."
            },
            "metadata": {
              "type": "object",
              "description": "Metadatos arbitrarios pasados al scorer."
            }
          },
          "additionalProperties": true
        }
      },
      "additionalProperties": true
    },
    "assembly_rules": [
      {
        "target": "elements_found",
        "sources": [
          "teoriacambio.encontrar_caminos_completos",
          "teoriacambio.validacion_completa",
          "causal_extraction.extract_causal_hierarchy",
          "hierarchicalgenerativemodel.verify_conditional_independence",
          "hierarchicalgenerativemodel.generate_independence_tests",
          "bayesiancounterfactualauditor.construct_scm",
          "advanceddagvalidator.perform_sensitivity_analysis_internal",
          "bayesfactortable.get_bayes_factor"
        ],
        "merge_strategy": "concat",
        "description": "Combine all evidence elements from 8 method invocations"
      },
      {
        "target": "confidence_scores",
        "sources": [
          "*.confidence",
          "*.bayesian_posterior"
        ],
        "merge_strategy": "weighted_mean",
        "default": [],
        "description": "Aggregate confidence scores across all methods"
      },
      {
        "target": "pattern_matches",
        "sources": [
          "teoriacambio.patterns",
          "causal_extraction.patterns"
        ],
        "merge_strategy": "concat",
        "default": {},
        "description": "Combine pattern matches from causal analysis methods"
      },
      {
        "target": "metadata",
        "sources": [
          "*.metadata"
        ],
        "merge_strategy": "concat",
        "description": "Combine metadata from all 8 methods for full traceability"
      }
    ]
  },
  "output_contract": {
    "result_type": "Phase2QuestionResult",
    "schema": {
      "type": "object",
      "required": [
        "base_slot",
        "question_id",
        "question_global",
        "evidence",
        "validation"
      ],
      "properties": {
        "base_slot": {
          "type": "string",
          "description": "Debe coincidir con identity.base_slot.",
          "const": "D4-Q2"
        },
        "question_id": {
          "type": "string",
          "description": "Debe coincidir con identity.question_id.",
          "const": "Q017"
        },
        "question_global": {
          "type": "integer",
          "description": "Índice global de la pregunta (de questionnaire_monolith).",
          "const": 17
        },
        "policy_area_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "PA canónica, debe ser coherente con identity.policy_area_id.",
          "const": "PA01"
        },
        "dimension_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Dimensión canónica, coherente con identity.dimension_id.",
          "const": "DIM04"
        },
        "cluster_id": {
          "type": [
            "string",
            "null"
          ],
          "description": "Cluster de análisis según el monolith, si aplica.",
          "const": "CL02"
        },
        "evidence": {
          "type": [
            "object",
            "null"
          ],
          "description": "Objeto de evidencia ensamblado por el EvidenceAssembler; debe cumplir evidence_assembly.output_schema.",
          "additionalProperties": true
        },
        "validation": {
          "type": [
            "object",
            "null"
          ],
          "description": "Resultado de validaciones lógicas de la respuesta (coherencia, integridad, etc.).",
          "additionalProperties": true
        },
        "trace": {
          "type": [
            "object",
            "null"
          ],
          "description": "Información de trazabilidad (provenance, logs) específica de la ejecución.",
          "additionalProperties": true
        },
        "metadata": {
          "type": [
            "object",
            "null"
          ],
          "description": "Metadatos adicionales de la pregunta para consumo posterior.",
          "additionalProperties": true
        }
      },
      "additionalProperties": false
    },
    "consumer_modules": [
      "src.farfan_core.core.phases.phase2_types.validate_phase2_result",
      "src.farfan_core.core.orchestrator.core.Orchestrator._score_micro_results_async",
      "src.farfan_core.analysis.scoring.MicroQuestionScorer"
    ],
    "human_readable_output": {
      "format": "markdown",
      "template": {
        "title": "## Análisis D4-Q2 (Q017): Cadena Causal y Supuestos en Intervenciones de Género",
        "summary": "### Resumen Ejecutivo\n\nSe analizó la explicitación de **{evidence.elements_found_count}** elementos de la cadena causal relacionados con resultados de género, incluyendo supuestos clave y condiciones habilitantes.\n\n**Puntaje**: {score}/3.0 | **Calidad**: {quality_level}",
        "score_section": "### Evaluación Cuantitativa\n\n- **Puntaje bruto**: {score}/3.0\n- **Nivel de calidad**: {quality_level}\n- **Confianza promedio**: {evidence.confidence_scores.mean}%\n- **Cobertura de patrones**: {evidence.pattern_matches_count}/7 patrones detectados",
        "elements_section": "### Elementos de Evidencia Identificados\n\n{evidence.elements_found_list}\n\n**Elementos críticos faltantes**: {evidence.missing_required_elements}",
        "details": [
          "**Cadenas causales explícitas**: {evidence.causal_chains_count}",
          "**Supuestos identificados**: {evidence.assumptions_count}",
          "**Condiciones habilitantes**: {evidence.enabling_conditions_count}",
          "**Coherencia lógica**: {evidence.logical_coherence}"
        ],
        "interpretation": "### Interpretación de Resultados\n\n{methodological_interpretation}",
        "recommendations": "### Recomendaciones\n\n{evidence.recommendations}"
      },
      "methodological_depth": {
        "methods": [
          {
            "method_name": "_encontrar_caminos_completos",
            "class_name": "TeoriaCambio",
            "priority": 1,
            "role": "causal_pathway_discovery",
            "epistemological_foundation": {
              "paradigm": "Theory of Change Reconstruction",
              "ontological_basis": "Causal pathways in policy documents represent logical chains from interventions to outcomes, mediated by assumptions and enabling conditions",
              "epistemological_stance": "Constructivist-analytical: Knowledge of causal mechanisms emerges from structured analysis of intervention logic and implicit assumptions",
              "theoretical_framework": [
                "Theory of Change methodology (Weiss, 1995)",
                "Causal pathway analysis (Pearl, 2009)",
                "Logic model reconstruction (W.K. Kellogg Foundation, 2004)",
                "Critical assumption identification theory (Rogers, 2008)"
              ],
              "justification": "Identifying complete causal pathways reveals whether policymakers understand the full chain from interventions to gender outcomes, including critical mediating factors and contingencies"
            },
            "technical_approach": {
              "method_type": "graph_traversal_analysis",
              "algorithm": "Breadth-first search with assumption node detection in intervention logic graphs",
              "steps": [
                {
                  "step": 1,
                  "description": "Parse document to extract action verbs, target populations, and outcome statements related to gender equality"
                },
                {
                  "step": 2,
                  "description": "Construct directed graph where nodes are interventions/outcomes and edges represent causal claims (marked by 'si...entonces', 'para que', 'con el fin de')"
                },
                {
                  "step": 3,
                  "description": "Traverse graph from intervention nodes to outcome nodes, identifying complete vs incomplete pathways"
                },
                {
                  "step": 4,
                  "description": "Extract assumption nodes (conditional statements using 'asumiendo que', 'siempre y cuando') along each pathway"
                },
                {
                  "step": 5,
                  "description": "Score completeness based on pathway length, assumption density, and terminal node (outcome) specificity"
                }
              ],
              "assumptions": [
                "Causal language uses standard Spanish connectors ('si', 'entonces', 'para que', 'con el fin de')",
                "Complete pathways have 3+ nodes (intervention → intermediate outcome → final gender outcome)",
                "Explicit assumptions use conditional markers ('asumiendo', 'siempre y cuando', 'si y solo si')"
              ],
              "limitations": [
                "Cannot detect implicit causal assumptions not stated in text",
                "May miss causal pathways expressed across distant document sections",
                "Assumes linear causality; may undercount feedback loops and reciprocal causation"
              ],
              "complexity": "O(V + E) where V=intervention/outcome nodes, E=causal edges in logic graph"
            },
            "output_interpretation": {
              "output_structure": {
                "complete_pathways": "Array of {intervention, intermediates, outcome, assumptions} objects",
                "incomplete_pathways": "Array of truncated pathways missing outcomes or assumptions",
                "pathway_completeness_score": "Ratio of complete to total pathways (0-1)"
              },
              "interpretation_guide": {
                "high_completeness": "≥0.7: Strong intervention logic with explicit causal chains and assumptions",
                "medium_completeness": "0.4-0.69: Partial logic; some pathways complete, others implicit",
                "low_completeness": "<0.4: Weak causal reasoning; interventions disconnected from outcomes"
              },
              "actionable_insights": [
                "Pathways with missing assumptions indicate areas where implementation may fail due to unexamined contingencies",
                "High assumption density (>3 per pathway) suggests complex interventions requiring careful monitoring",
                "Incomplete pathways to gender outcomes reveal gaps in theory of change"
              ]
            }
          },
          {
            "method_name": "validacion_completa",
            "class_name": "TeoriaCambio",
            "priority": 2,
            "role": "theory_of_change_validation",
            "epistemological_foundation": {
              "paradigm": "Logical coherence validation in causal models",
              "ontological_basis": "Valid theories of change must satisfy internal consistency (no contradictory causal claims), completeness (all paths lead to outcomes), and empirical grounding (assumptions are testable)",
              "epistemological_stance": "Falsificationist: Theories of change can be invalidated by detecting logical contradictions or empirically implausible assumptions",
              "theoretical_framework": [
                "Logical consistency theory (Popper, 1959)",
                "Causal model validation (Pearl, 2009)",
                "Program theory evaluation (Chen, 1990)",
                "Assumption testing in impact evaluation (White, 2009)"
              ],
              "justification": "Even explicit causal chains are insufficient if internally contradictory or based on implausible assumptions; validation ensures theory of change is actionable"
            },
            "technical_approach": {
              "method_type": "constraint_satisfaction_validation",
              "algorithm": "Multi-criteria validation checking logical consistency, assumption plausibility, and outcome alignment",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract all causal claims from pathways (format: intervention X causes outcome Y)"
                },
                {
                  "step": 2,
                  "description": "Check for contradictory claims (X→Y and X→¬Y) using semantic similarity on outcome statements"
                },
                {
                  "step": 3,
                  "description": "Validate assumption plausibility against external knowledge base (gender policy best practices)"
                },
                {
                  "step": 4,
                  "description": "Verify outcome alignment: all pathways terminate in gender equality outcomes (not generic outcomes)"
                },
                {
                  "step": 5,
                  "description": "Calculate validation score combining consistency, plausibility, and alignment metrics"
                }
              ],
              "assumptions": [
                "Contradictory causal claims occur within same document (not across documents)",
                "Plausibility can be assessed using heuristics (e.g., assumptions requiring >5 years are implausible for 4-year policies)",
                "Gender outcomes are identifiable by keyword matching ('igualdad de género', 'empoderamiento de mujeres', 'reducción VBG')"
              ],
              "limitations": [
                "Cannot validate causal claims against empirical evidence (requires RCT data)",
                "Plausibility scoring is heuristic-based, not scientifically validated",
                "May miss subtle contradictions expressed through implication rather than direct negation"
              ],
              "complexity": "O(C²) where C=number of causal claims (pairwise consistency check)"
            },
            "output_interpretation": {
              "output_structure": {
                "validation_status": "Boolean (true if theory of change passes all validation checks)",
                "contradictions_found": "Array of {claim_A, claim_B, conflict_type} for each inconsistency",
                "implausible_assumptions": "Array of {assumption, plausibility_score, reason}",
                "outcome_alignment_score": "Ratio of gender-specific outcomes to total outcomes (0-1)"
              },
              "interpretation_guide": {
                "validated": "validation_status=true and outcome_alignment≥0.8: Theory of change is coherent and gender-focused",
                "partially_validated": "Minor issues (1-2 contradictions or <3 implausible assumptions): Theory salvageable with revisions",
                "invalidated": "Major issues (≥3 contradictions or outcome_alignment<0.5): Theory requires fundamental reformulation"
              },
              "actionable_insights": [
                "Contradictions indicate conflicting intervention strategies that will undermine each other",
                "Implausible assumptions are implementation risks that should be monitored",
                "Low outcome alignment suggests policy is not genuinely gender-focused despite gender language"
              ]
            }
          },
          {
            "method_name": "extract_causal_hierarchy",
            "class_name": "CausalExtractor",
            "priority": 3,
            "role": "hierarchical_causal_structure_extraction",
            "epistemological_foundation": {
              "paradigm": "Hierarchical causality in policy interventions",
              "ontological_basis": "Gender policy causality operates at multiple levels: proximate causes (direct interventions), intermediate causes (enabling conditions), and distal causes (structural factors)",
              "epistemological_stance": "Structural-functionalist: Outcomes result from nested causal levels, with higher levels constraining lower levels",
              "theoretical_framework": [
                "Hierarchical causal models (Judea Pearl, 2009)",
                "Structural equation modeling (Bollen, 1989)",
                "Multi-level causation in social policy (Pawson & Tilley, 1997)",
                "Gender mainstreaming theory (Walby, 2005)"
              ],
              "justification": "Flat causal models miss critical enabling conditions and structural constraints; hierarchical extraction reveals full dependency structure"
            },
            "technical_approach": {
              "method_type": "dependency_parsing_with_hierarchical_clustering",
              "algorithm": "spaCy dependency parsing to extract causal clauses, followed by hierarchical clustering based on causal distance",
              "steps": [
                {
                  "step": 1,
                  "description": "Apply spaCy dependency parsing to identify causal clause patterns (nsubj→verb→dobj with causal verb)"
                },
                {
                  "step": 2,
                  "description": "Extract causal triples (subject, causal_verb, object) for each sentence"
                },
                {
                  "step": 3,
                  "description": "Calculate causal distance: proximate causes mention specific interventions, intermediate causes mention 'condiciones' or 'factores', distal causes mention 'estructuras' or 'normas'"
                },
                {
                  "step": 4,
                  "description": "Apply hierarchical agglomerative clustering to group causes by distance level"
                },
                {
                  "step": 5,
                  "description": "Construct hierarchy tree with distal→intermediate→proximate levels"
                }
              ],
              "assumptions": [
                "Causal verbs are identifiable by lexicon ('causa', 'genera', 'produce', 'conduce a', 'permite')",
                "Causal distance correlates with linguistic markers ('directamente', 'mediante', 'a través de estructuras')",
                "Hierarchy has max 3 levels (distal, intermediate, proximate)"
              ],
              "limitations": [
                "Dependency parsing fails on long, complex sentences (>50 words)",
                "Causal distance heuristic may misclassify ambiguous language",
                "Cannot extract implicit hierarchies (e.g., structural causes mentioned only in introduction)"
              ],
              "complexity": "O(n*p + k²) where n=sentences, p=causal patterns, k=causal clauses (for clustering)"
            },
            "output_interpretation": {
              "output_structure": {
                "hierarchy_tree": "Nested dict with levels {distal: [causes], intermediate: [causes], proximate: [causes]}",
                "causal_triples": "Array of {subject, verb, object, level} for all extracted causality",
                "hierarchy_completeness": "Boolean flags {has_distal, has_intermediate, has_proximate}"
              },
              "interpretation_guide": {
                "complete_hierarchy": "All 3 levels present: Policy has sophisticated causal understanding",
                "partial_hierarchy": "Only proximate+intermediate: Policy addresses enabling conditions but ignores structures",
                "flat_hierarchy": "Only proximate: Policy has shallow causal model, likely to fail"
              },
              "actionable_insights": [
                "Missing distal causes suggests policy will not address root structural inequalities",
                "Rich intermediate level indicates policy recognizes importance of enabling conditions (institutions, norms)",
                "Proximate-only causality reveals technocratic approach that ignores systemic constraints"
              ]
            }
          },
          {
            "method_name": "verify_conditional_independence",
            "class_name": "HierarchicalGenerativeModel",
            "priority": 4,
            "role": "causal_assumption_verification",
            "epistemological_foundation": {
              "paradigm": "Bayesian causal inference with conditional independence",
              "ontological_basis": "Causal assumptions encode conditional independence relations: outcome Y is independent of intervention X given mediator M implies M fully mediates X→Y relationship",
              "epistemological_stance": "Probabilistic: Causality is captured by conditional probability distributions P(Y|X,M) with independence constraints",
              "theoretical_framework": [
                "Causal Bayesian networks (Pearl, 2000; Spirtes et al., 2000)",
                "Conditional independence testing (Dawid, 1979)",
                "d-separation criterion (Pearl, 1988)",
                "Markov condition in causal models (Lauritzen, 1996)"
              ],
              "justification": "Stated causal assumptions imply testable conditional independence relations; violations indicate flawed theory of change"
            },
            "technical_approach": {
              "method_type": "independence_test_generation_from_causal_graph",
              "algorithm": "Convert causal pathways to Bayesian network, apply d-separation to generate independence tests",
              "steps": [
                {
                  "step": 1,
                  "description": "Convert extracted causal pathways to directed acyclic graph (DAG) with nodes=variables, edges=causal relations"
                },
                {
                  "step": 2,
                  "description": "Identify mediator nodes (nodes with incoming and outgoing edges on pathway to outcome)"
                },
                {
                  "step": 3,
                  "description": "For each intervention→mediator→outcome chain, generate conditional independence test: intervention ⊥ outcome | mediator"
                },
                {
                  "step": 4,
                  "description": "Check whether document states independence assumption explicitly (using 'independiente de', 'solo a través de')"
                },
                {
                  "step": 5,
                  "description": "Flag mismatches: DAG implies independence but document does not state it (or vice versa)"
                }
              ],
              "assumptions": [
                "Causal graph is a DAG (no feedback loops)",
                "Mediators are correctly identified (nodes with indegree≥1 and outdegree≥1 on path)",
                "Independence language uses standard markers ('independiente', 'solo a través de', 'únicamente mediante')"
              ],
              "limitations": [
                "Cannot test independence empirically (requires data, not just document analysis)",
                "Assumes perfect mediation; does not detect partial mediation",
                "May generate false positives if causal graph is incomplete"
              ],
              "complexity": "O(V * E) where V=nodes, E=edges (d-separation check per node pair)"
            },
            "output_interpretation": {
              "output_structure": {
                "independence_tests": "Array of {X, Y, Z, expected_independent, stated_independent} for each mediator test",
                "mismatches": "Array of tests where expected_independent ≠ stated_independent",
                "verification_score": "Ratio of matching tests to total tests (0-1)"
              },
              "interpretation_guide": {
                "verified": "verification_score≥0.9: Causal assumptions align with implied independence structure",
                "partial_verification": "0.6-0.89: Some independence assumptions missing or inconsistent",
                "unverified": "<0.6: Major misalignment between stated assumptions and causal graph"
              },
              "actionable_insights": [
                "Missing independence assumptions indicate unexamined mediation paths (risk: confounding)",
                "Stated independence contradicting graph structure suggests misunderstanding of causal mechanism",
                "Low verification score flags need for theory of change workshop to clarify causal logic"
              ]
            }
          },
          {
            "method_name": "_generate_independence_tests",
            "class_name": "HierarchicalGenerativeModel",
            "priority": 5,
            "role": "conditional_independence_test_generation",
            "epistemological_foundation": {
              "paradigm": "Automated hypothesis generation from causal structures",
              "ontological_basis": "Every causal structure implies a set of testable independence hypotheses via the Markov condition and d-separation",
              "epistemological_stance": "Hypothetico-deductive: Causal models are falsifiable via their independence implications",
              "theoretical_framework": [
                "Markov condition (Lauritzen, 1996)",
                "d-separation algorithm (Geiger et al., 1990)",
                "Independence testing in causal discovery (Spirtes & Glymour, 1991)",
                "Testable implications of causal models (Pearl, 2009, Ch. 3)"
              ],
              "justification": "Generating full set of independence tests enables comprehensive validation of stated causal assumptions against model structure"
            },
            "technical_approach": {
              "method_type": "d-separation_enumeration",
              "algorithm": "Enumerate all node triples (X,Y,Z) in causal DAG, apply d-separation criterion to determine X ⊥ Y | Z",
              "steps": [
                {
                  "step": 1,
                  "description": "Enumerate all triples (X,Y,Z) where X≠Y, Z is a set of conditioning nodes"
                },
                {
                  "step": 2,
                  "description": "For each triple, check d-separation: X ⊥ Y | Z iff every path from X to Y is blocked by Z"
                },
                {
                  "step": 3,
                  "description": "Path is blocked if: (i) contains chain X→Z→Y and Z is in conditioning set, or (ii) contains fork X←Z→Y and Z is in conditioning set, or (iii) contains collider X→Z←Y and neither Z nor its descendants are in conditioning set"
                },
                {
                  "step": 4,
                  "description": "Generate test specification for each d-separated triple: 'Test: X ⊥ Y | Z'"
                },
                {
                  "step": 5,
                  "description": "Prioritize tests involving outcome variables and policy intervention variables"
                }
              ],
              "assumptions": [
                "Causal DAG is complete (all relevant variables included)",
                "d-separation correctly captures conditional independence (faithfulness assumption)",
                "Tests are prioritized correctly (interventions and outcomes most important)"
              ],
              "limitations": [
                "Combinatorial explosion: O(V³) tests for V variables (mitigated by prioritization)",
                "Cannot execute tests (document analysis cannot test statistical independence)",
                "Faithfulness assumption may fail (independence holds in data but not implied by graph)"
              ],
              "complexity": "O(V³ * E) where V=variables, E=edges (d-separation check per triple)"
            },
            "output_interpretation": {
              "output_structure": {
                "all_tests": "Array of {X, Y, Z, priority} where X ⊥ Y | Z is implied by causal graph",
                "priority_tests": "Subset of tests involving intervention or outcome variables",
                "test_count": "Total number of testable independence relations"
              },
              "interpretation_guide": {
                "high_test_count": ">20 tests: Complex causal model with many testable implications",
                "medium_test_count": "10-20 tests: Moderate complexity, reasonable to validate",
                "low_test_count": "<10 tests: Simple causal model, may be underspecified"
              },
              "actionable_insights": [
                "High-priority tests should be checked against stated assumptions in document",
                "Tests not stated in document represent hidden assumptions (risk: unexamined)",
                "Test count indicates model complexity; very high counts may signal overparameterization"
              ]
            }
          },
          {
            "method_name": "construct_scm",
            "class_name": "BayesianCounterfactualAuditor",
            "priority": 6,
            "role": "structural_causal_model_construction",
            "epistemological_foundation": {
              "paradigm": "Structural causal modeling for policy counterfactuals",
              "ontological_basis": "Causal effects are defined via interventions in structural causal models (SCMs): effect of X on Y = Y(do(X=1)) - Y(do(X=0))",
              "epistemological_stance": "Interventionist: Causality is defined by the results of hypothetical interventions, not mere correlation",
              "theoretical_framework": [
                "Structural causal models (Pearl, 2009)",
                "Counterfactual theory of causation (Lewis, 1973; Pearl, 2009)",
                "do-calculus for causal effect identification (Pearl, 1995)",
                "Potential outcomes framework (Rubin, 1974; Pearl, 2009 Ch. 7)"
              ],
              "justification": "SCMs enable counterfactual queries ('What if intervention X were not implemented?') essential for policy evaluation and understanding causal assumptions"
            },
            "technical_approach": {
              "method_type": "scm_construction_from_causal_graph",
              "algorithm": "Convert causal DAG to SCM by assigning structural equations to each node based on parents",
              "steps": [
                {
                  "step": 1,
                  "description": "Take causal DAG from previous methods (nodes=variables, edges=causal relations)"
                },
                {
                  "step": 2,
                  "description": "For each node Y with parents X1,...,Xk, construct structural equation: Y = f_Y(X1,...,Xk, U_Y) where U_Y is unobserved noise"
                },
                {
                  "step": 3,
                  "description": "Assign functional forms: linear f_Y(X) = β0 + Σ β_i*X_i + U_Y for quantifiable variables, categorical for qualitative"
                },
                {
                  "step": 4,
                  "description": "Extract parameter values from document when stated (e.g., 'reducción de 20% en VBG' → β=-0.2)"
                },
                {
                  "step": 5,
                  "description": "For unstated parameters, assign non-informative priors (uniform or weakly informative)"
                }
              ],
              "assumptions": [
                "Functional forms are linear or log-linear (sufficient for policy analysis)",
                "Unobserved confounders U_Y are independent across equations (no unmeasured common causes)",
                "Parameter values stated in document are reliable (not aspirational)"
              ],
              "limitations": [
                "Cannot learn functional forms or parameters from data (document analysis only)",
                "Linear functional form may miss nonlinearities (e.g., threshold effects)",
                "Independence of U_Y may fail if document omits confounders"
              ],
              "complexity": "O(V * k) where V=variables, k=average parent set size"
            },
            "output_interpretation": {
              "output_structure": {
                "scm": "Dict mapping each variable Y to {parents: [X1,...,Xk], function: f_Y, parameters: {β0, β1,...}}",
                "identified_parameters": "List of parameters with values extracted from document",
                "unidentified_parameters": "List of parameters with prior distributions only"
              },
              "interpretation_guide": {
                "well_specified": "≥80% parameters identified: Document provides quantitative causal model",
                "partially_specified": "40-79% parameters identified: Model has some quantitative detail but gaps remain",
                "underspecified": "<40% parameters identified: Document lacks quantitative causal structure"
              },
              "actionable_insights": [
                "Unidentified parameters indicate areas where policy lacks quantitative targets",
                "Well-specified SCM enables counterfactual simulation (e.g., 'What if budget reduced by 30%?')",
                "Parameter extraction from document reveals whether policy is evidence-based (citing studies) or aspirational"
              ]
            }
          },
          {
            "method_name": "_perform_sensitivity_analysis_internal",
            "class_name": "AdvancedDAGValidator",
            "priority": 7,
            "role": "causal_model_sensitivity_analysis",
            "epistemological_foundation": {
              "paradigm": "Robustness analysis for causal conclusions",
              "ontological_basis": "Causal conclusions depend on model assumptions; sensitivity analysis quantifies how much conclusions change if assumptions are violated",
              "epistemological_stance": "Critical realist: Causal claims are fallible; sensitivity analysis reveals their fragility or robustness",
              "theoretical_framework": [
                "Sensitivity analysis in causal inference (Rosenbaum, 2002; Imbens, 2003)",
                "Bounds under confounding (Manski, 1990)",
                "E-value for unmeasured confounding (VanderWeele & Ding, 2017)",
                "Stability analysis in causal models (Cinelli & Hazlett, 2020)"
              ],
              "justification": "Stated causal assumptions may be wrong; sensitivity analysis identifies which assumptions are critical (small violation → large conclusion change) vs robust"
            },
            "technical_approach": {
              "method_type": "perturbation_analysis_on_causal_graph",
              "algorithm": "Systematically perturb causal graph (add/remove edges) and check if causal conclusions change",
              "steps": [
                {
                  "step": 1,
                  "description": "Extract primary causal claim from document (e.g., 'Intervention X reduces VBG by 20%')"
                },
                {
                  "step": 2,
                  "description": "Enumerate potential confounders: variables that could affect both X and outcome Y"
                },
                {
                  "step": 3,
                  "description": "For each potential confounder C, add edge C→X and C→Y to causal graph"
                },
                {
                  "step": 4,
                  "description": "Recompute causal effect of X on Y using backdoor adjustment (adjust for C)"
                },
                {
                  "step": 5,
                  "description": "Calculate sensitivity: |effect_with_C - effect_without_C| / effect_without_C"
                },
                {
                  "step": 6,
                  "description": "Rank confounders by sensitivity; flag high-sensitivity confounders (>50% change)"
                }
              ],
              "assumptions": [
                "Potential confounders are identifiable from domain knowledge (gender policy expertise)",
                "Confounding effect is linear (sensitivity scales with confounder strength)",
                "Backdoor adjustment is sufficient (no other biases like selection or measurement error)"
              ],
              "limitations": [
                "Cannot quantify confounder strength from document (requires data)",
                "Sensitivity is pessimistic: assumes worst-case confounding",
                "Enumerating all potential confounders is intractable; uses heuristic subset"
              ],
              "complexity": "O(C * V * E) where C=candidate confounders, V=variables, E=edges (backdoor adjustment per confounder)"
            },
            "output_interpretation": {
              "output_structure": {
                "sensitivity_results": "Array of {confounder, sensitivity_pct, critical_threshold} for each tested confounder",
                "high_sensitivity_confounders": "Subset where sensitivity_pct > 50%",
                "robustness_score": "1 - (# high-sensitivity confounders / # tested confounders)"
              },
              "interpretation_guide": {
                "robust": "robustness_score ≥ 0.8: Causal conclusions resilient to unmeasured confounding",
                "moderately_robust": "0.5-0.79: Conclusions hold unless major confounders omitted",
                "fragile": "<0.5: Conclusions highly sensitive; small confounding invalidates claims"
              },
              "actionable_insights": [
                "High-sensitivity confounders are critical threats to validity; should be measured if possible",
                "Fragile conclusions indicate need for robustness checks (e.g., propensity score sensitivity analysis)",
                "Robust conclusions justify stronger causal language in policy documents"
              ]
            }
          },
          {
            "method_name": "get_bayes_factor",
            "class_name": "BayesFactorTable",
            "priority": 8,
            "role": "bayesian_hypothesis_comparison",
            "epistemological_foundation": {
              "paradigm": "Bayesian model comparison and evidence accumulation",
              "ontological_basis": "Alternative causal hypotheses have prior probabilities; evidence updates these via Bayes' rule; Bayes factor quantifies relative evidence for H1 vs H0",
              "epistemological_stance": "Bayesian epistemology: Knowledge is probabilistic; evidence shifts degrees of belief, not binary acceptance/rejection",
              "theoretical_framework": [
                "Bayes factors for hypothesis testing (Kass & Raftery, 1995)",
                "Bayesian model selection (Jeffreys, 1961)",
                "Evidence accumulation theory (Lee & Wagenmakers, 2013)",
                "Likelihood principle (Berger & Wolpert, 1988)"
              ],
              "justification": "Multiple causal explanations may be consistent with stated evidence; Bayes factors quantify which explanation is better supported"
            },
            "technical_approach": {
              "method_type": "bayes_factor_calculation_from_document_statements",
              "algorithm": "Extract competing hypotheses and evidence statements, calculate Bayes factor BF = P(E|H1)/P(E|H0)",
              "steps": [
                {
                  "step": 1,
                  "description": "Identify competing causal hypotheses in document (e.g., 'VBG reduction due to economic empowerment' vs 'due to justice system reform')"
                },
                {
                  "step": 2,
                  "description": "Extract evidence statements supporting each hypothesis (e.g., 'women with income are 30% less likely to experience VBG')"
                },
                {
                  "step": 3,
                  "description": "Assign likelihoods: P(E|H1) = how well evidence E supports H1, estimated from strength of association"
                },
                {
                  "step": 4,
                  "description": "Calculate Bayes factor: BF = P(E|H1) / P(E|H0) for each hypothesis pair"
                },
                {
                  "step": 5,
                  "description": "Interpret using Jeffreys' scale: BF>10 is strong evidence for H1, 3-10 is moderate, 1-3 is weak"
                }
              ],
              "assumptions": [
                "Competing hypotheses are explicitly stated in document (not implicit)",
                "Evidence strength can be quantified from language ('fuertemente asociado'=high likelihood, 'posiblemente relacionado'=low likelihood)",
                "Priors are equal (P(H1)=P(H0)) unless document states prior belief"
              ],
              "limitations": [
                "Likelihood assignment is heuristic, not data-driven",
                "Cannot calculate exact Bayes factors (requires full probability models)",
                "Assumes hypotheses are mutually exclusive (may both be partially true)"
              ],
              "complexity": "O(H²) where H=number of hypotheses (pairwise comparisons)"
            },
            "output_interpretation": {
              "output_structure": {
                "hypothesis_pairs": "Array of {H1, H0, bayes_factor, interpretation} for each comparison",
                "strongest_hypothesis": "Hypothesis with highest average BF across all comparisons",
                "evidence_quality": "Average BF across all pairs (1=no discrimination, >10=strong discrimination)"
              },
              "interpretation_guide": {
                "decisive_evidence": "BF>100: Overwhelming support for one causal hypothesis",
                "strong_evidence": "BF 10-100: Strong support, hypothesis well-justified",
                "moderate_evidence": "BF 3-10: Moderate support, hypothesis plausible",
                "weak_evidence": "BF 1-3: Weak support, competing hypotheses equally viable"
              },
              "actionable_insights": [
                "Low BF (<3) indicates competing causal explanations not adequately differentiated by evidence",
                "High BF (>10) justifies focusing policy on best-supported causal mechanism",
                "Evidence quality score reveals overall rigor of causal reasoning in document"
              ]
            }
          }
        ],
        "method_combination_logic": {
          "combination_strategy": "Sequential causal analysis pipeline: pathway extraction → validation → hierarchical structuring → independence verification → SCM construction → sensitivity analysis → hypothesis comparison",
          "rationale": "Q017 requires comprehensive analysis of causal reasoning quality in gender policy documents. The 8 methods cover complementary aspects: causal pathway discovery (methods 1-2), structural analysis (method 3), formal validation (methods 4-5), quantitative modeling (method 6), robustness checking (method 7), and hypothesis testing (method 8). This pipeline moves from descriptive (what causal claims exist?) to normative (are causal claims valid and robust?).",
          "evidence_fusion": "Evidence from all 8 methods is aggregated by EvidenceAssembler. Causal pathways (method 1) are validated (method 2), structured hierarchically (method 3), checked for independence implications (methods 4-5), formalized as SCM (method 6), tested for robustness (method 7), and compared via Bayesian model comparison (method 8). Final score combines pathway completeness, validation status, hierarchy depth, independence verification, SCM specification, robustness, and hypothesis differentiation.",
          "confidence_aggregation": "Final confidence per evidence element = weighted_mean([confidence_method1, ..., confidence_method8]) where weights reflect method reliability: formal methods (4-5, 6) have higher weight (0.9) than heuristic methods (1-3) (0.7). Bayesian methods (6, 8) have highest weight (1.0) due to probabilistic rigor.",
          "execution_order": "Methods execute in strict priority order (1→8). Methods 4-5 depend on causal graph from method 3; method 6 depends on validated pathways from method 2; method 7 depends on SCM from method 6; method 8 depends on alternative hypotheses identified in methods 1-3.",
          "trade_offs": [
            "Completeness vs. Computational Cost: 8 methods ensure thorough causal analysis but increase execution time (~5-10 seconds per document). Justified by complexity of causal reasoning validation.",
            "Formal Rigor vs. Interpretability: Methods 4-8 use formal causal inference techniques (d-separation, SCMs, Bayes factors) which are mathematically rigorous but less interpretable than methods 1-3. Trade-off acceptable for Q017 which assesses technical causal reasoning quality.",
            "Depth vs. Breadth: Pipeline deeply analyzes causal reasoning (8 complementary methods) but focuses narrowly on explicit causal statements. May miss implicit causal assumptions expressed through narrative. Acceptable given Q017 focus on explicit causal chains."
          ]
        }
      }
    }
  },
  "validation_rules": {
    "na_policy": "abort_on_critical",
    "rules": [
      {
        "field": "elements_found",
        "type": "array",
        "must_contain": {
          "count": 1,
          "elements": [
            "cadena_causal_explicita",
            "condiciones_habilitantes",
            "supuestos_identificados"
          ]
        },
        "description": "All three critical elements must be present: explicit causal chain, enabling conditions, and identified assumptions"
      },
      {
        "field": "elements_found",
        "type": "array",
        "should_contain": [
          {
            "elements": [
              "complete_pathways"
            ],
            "minimum": 2
          },
          {
            "elements": [
              "validated_assumptions"
            ],
            "minimum": 3
          },
          {
            "elements": [
              "hierarchical_levels"
            ],
            "minimum": 2
          }
        ],
        "description": "Desirable elements for high-quality causal analysis"
      }
    ]
  },
  "traceability": {
    "source_file": "data/questionnaire_monolith.json",
    "json_path": "blocks.micro_questions[16]",
    "method_source": "src/farfan_core/core/orchestrator/executors.py:D4_Q2_Executor",
    "method_mapping_source": "executor_methods_mapping.json",
    "ontology_source": "config/canonical_ontologies/policy_areas_and_dimensions.json",
    "source_hash": "TODO_SHA256_HASH_OF_QUESTIONNAIRE_MONOLITH",
    "contract_generation_method": "automated_specialization_from_monolith",
    "contract_author": "F.A.R.F.A.N Mechanistic Policy Pipeline",
    "provenance_note": "This contract was generated with full multi-method orchestration support. The method_binding.methods array contains all 8 methods from D4_Q2_Executor, with enhanced epistemological documentation and substantive technical approaches for comprehensive causal reasoning analysis.",
    "source_question_id": "Q017",
    "specialized_from_base_slot": "D4-Q2",
    "specialization_timestamp": "2025-11-28T03:49:29.842841+00:00"
  },
  "error_handling": {
    "on_method_not_found": "raise",
    "on_method_failure": "propagate_with_trace",
    "on_assembly_failure": "propagate_with_trace",
    "failure_contract": {
      "abort_if": [
        "missing_required_element",
        "incomplete_text"
      ],
      "emit_code": "ABORT-Q017-REQ"
    }
  },
  "fallback_strategy": {
    "use_llm_direct": false,
    "use_heuristics": false,
    "note": "No fallback strategies enabled. All failures propagate according to error_handling configuration."
  },
  "test_configuration": {
    "test_files": [
      "tests/core/orchestrator/test_executors_contract.py",
      "tests/core/phases/test_phase2.py"
    ],
    "test_document_fixtures": [
      "tests/fixtures/preprocessed_documents/sample_pdet_plan.json"
    ],
    "expected_test_coverage": ">=90%",
    "integration_test_required": true
  },
  "compatibility": {
    "orchestrator_min_version": "TODO_VERSION",
    "signal_registry_min_version": "TODO_VERSION",
    "method_executor_min_version": "TODO_VERSION",
    "questionnaire_monolith_version": "3.0.0",
    "phase2_types_version": "TODO_VERSION"
  },
  "calibration": {
    "status": "placeholder",
    "note": "Contract does not embed calibration scores. Actual calibration managed via src/farfan_core/core/calibration/ + config/intrinsic_calibration.json + config/fusion_specification.json",
    "source": {
      "intrinsic_calibration": "config/intrinsic_calibration.json",
      "fusion_specification": "config/fusion_specification.json",
      "layer_calibrations_dir": "config/layer_calibrations/",
      "canonical_spec": "canonic_calibration_methods.md"
    }
  },
  "human_answer_structure": {
    "description": "Expected structure of evidence dict after all 8 methods execute and evidence is assembled according to assembly_rules",
    "assembly_flow": {
      "step_1_method_execution": "8 methods execute in priority order, outputs stored with dot-notation keys",
      "step_2_evidence_assembly": "EvidenceAssembler merges outputs according to assembly_rules",
      "step_3_validation": "EvidenceValidator checks against validation_rules",
      "step_4_output_generation": "Phase2QuestionResult constructed with evidence, validation, trace"
    },
    "evidence_structure_schema": {
      "type": "object",
      "description": "Assembled evidence after all methods complete",
      "properties": {
        "elements_found": {
          "type": "array",
          "description": "Concatenated evidence elements from 8 causal analysis methods",
          "items": {
            "type": "object",
            "properties": {
              "element_id": {
                "type": "string",
                "example": "E-001"
              },
              "type": {
                "type": "string",
                "enum": [
                  "cadena_causal_explicita",
                  "condiciones_habilitantes",
                  "supuestos_identificados",
                  "complete_pathways",
                  "validated_assumptions",
                  "hierarchical_levels",
                  "independence_tests",
                  "scm_parameters"
                ]
              },
              "value": {
                "type": "string",
                "example": "Intervención X → Condición habilitante Y → Resultado de género Z"
              },
              "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "source_method": {
                "type": "string",
                "example": "TeoriaCambio._encontrar_caminos_completos"
              },
              "context": {
                "type": "string"
              }
            }
          },
          "example_count": "Expected 10-30 elements for a well-reasoned causal chain"
        },
        "causal_pathways": {
          "type": "object",
          "properties": {
            "complete_pathways_count": {
              "type": "integer"
            },
            "incomplete_pathways_count": {
              "type": "integer"
            },
            "pathway_completeness_score": {
              "type": "number"
            }
          }
        },
        "validation_status": {
          "type": "object",
          "properties": {
            "theory_validated": {
              "type": "boolean"
            },
            "contradictions_found": {
              "type": "integer"
            },
            "implausible_assumptions": {
              "type": "integer"
            }
          }
        },
        "hierarchical_structure": {
          "type": "object",
          "properties": {
            "has_distal_causes": {
              "type": "boolean"
            },
            "has_intermediate_causes": {
              "type": "boolean"
            },
            "has_proximate_causes": {
              "type": "boolean"
            },
            "hierarchy_completeness": {
              "type": "string",
              "enum": [
                "complete",
                "partial",
                "flat"
              ]
            }
          }
        },
        "independence_verification": {
          "type": "object",
          "properties": {
            "tests_generated": {
              "type": "integer"
            },
            "tests_matched": {
              "type": "integer"
            },
            "verification_score": {
              "type": "number"
            }
          }
        },
        "scm_specification": {
          "type": "object",
          "properties": {
            "parameters_identified": {
              "type": "integer"
            },
            "parameters_total": {
              "type": "integer"
            },
            "specification_completeness": {
              "type": "number"
            }
          }
        },
        "robustness_analysis": {
          "type": "object",
          "properties": {
            "high_sensitivity_confounders": {
              "type": "integer"
            },
            "robustness_score": {
              "type": "number"
            }
          }
        },
        "hypothesis_comparison": {
          "type": "object",
          "properties": {
            "competing_hypotheses": {
              "type": "integer"
            },
            "strongest_hypothesis": {
              "type": "string"
            },
            "evidence_quality": {
              "type": "number"
            }
          }
        },
        "confidence_scores": {
          "type": "object",
          "properties": {
            "mean": {
              "type": "number"
            },
            "by_method": {
              "type": "object"
            }
          }
        },
        "metadata": {
          "type": "object",
          "properties": {
            "methods_executed": {
              "type": "integer",
              "const": 8
            },
            "analysis_timestamp": {
              "type": "string",
              "format": "date-time"
            }
          }
        }
      }
    }
  }
}
